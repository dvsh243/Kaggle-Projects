{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i didnt feel humiliated;sadness\\n',\n",
       " 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake;sadness\\n',\n",
       " 'im grabbing a minute to post i feel greedy wrong;anger\\n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('train.txt') as f:\n",
    "    raw_lines_train = f.readlines()\n",
    "\n",
    "raw_lines_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['im feeling quite sad and sorry for myself but ill snap out of it soon;sadness\\n',\n",
       " 'i feel like i am still looking at a blank canvas blank pieces of paper;sadness\\n',\n",
       " 'i feel like a faithful servant;love\\n']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('val.txt') as f:\n",
    "    raw_lines_val = f.readlines()\n",
    "\n",
    "raw_lines_val[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i didnt feel humiliated : sadness\n",
      "i feel incredibly lucky just to be able to talk to her : joy\n"
     ]
    }
   ],
   "source": [
    "def replace_text_and_labels(array):\n",
    "\n",
    "    line_text = []\n",
    "    line_label = []\n",
    "\n",
    "    for line in array:\n",
    "        line = line.replace('\\n','').split(';')\n",
    "        line_text.append(line[0])\n",
    "        line_label.append(line[1])\n",
    "        # print(line)\n",
    "\n",
    "    return line_text, line_label\n",
    "\n",
    "train_text, train_label = replace_text_and_labels(raw_lines_train)\n",
    "val_text, val_label = replace_text_and_labels(raw_lines_val)\n",
    "\n",
    "print(train_text[0], end=' : ')\n",
    "print(train_label[0])\n",
    "\n",
    "print(val_text[7], end=' : ')\n",
    "print(val_label[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.8458125"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_array = []\n",
    "for line in train_text:\n",
    "    len_array.append(len(line))\n",
    "\n",
    "sum(len_array) / len(len_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "max_vocab = 10000 # 15214 max for this data\n",
    "max_seq_length = 100 # max length our sequences will be \n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens = max_vocab,\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    output_mode = \"int\",\n",
    "    output_sequence_length = max_seq_length\n",
    ")\n",
    "\n",
    "text_vectorizer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 100)\n",
      "(2000, 100)\n"
     ]
    }
   ],
   "source": [
    "train_token = text_vectorizer(train_text)\n",
    "val_token = text_vectorizer(val_text)\n",
    "\n",
    "print( train_token.shape )\n",
    "print( val_token.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
       "array([   2,   21,   32,   48, 5340,  128, 2818, 5040,    4,  259,   27,\n",
       "         23,   61,    6,  179,   52,   12,    7,  187,    8,    2,   93,\n",
       "        547,   36,  143,    1, 2304, 5651, 3162,    1,   90,  153,    2,\n",
       "         21,  433,   15,   86,   52,   25,   11,  173,  151,   18,    3,\n",
       "        284,  618,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0], dtype=int64)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_token[5126]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 unique values in label\n",
      "['surprise', 'sadness', 'anger', 'joy', 'fear', 'love']\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(list(set(train_label)))} unique values in label\")\n",
    "print(list(set(train_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joy': 1, 'sadness': 2, 'anger': 3, 'fear': 4, 'love': 5, 'surprise': 6}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_label)\n",
    "\n",
    "token_train_label = tokenizer.texts_to_sequences(train_label)\n",
    "token_val_label = tokenizer.texts_to_sequences(val_label)\n",
    "\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 7)\n",
      "(2000, 7)\n",
      "[[0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "cat_train_labels = to_categorical(token_train_label)\n",
    "cat_val_labels = to_categorical(token_val_label)\n",
    "\n",
    "# the 0th value is always going to be 0 because word index doesnt have anything in dictionary for '0'\n",
    "# so we can remove it from the arrays\n",
    "# cat_train_labels = temp_cat_train_labels[ : , 1:]\n",
    "# cat_val_labels = temp_cat_val_labels[ : , 1:]\n",
    "\n",
    "print(cat_train_labels.shape)\n",
    "print(cat_val_labels.shape)\n",
    "\n",
    "print(cat_train_labels[:5])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 320)          3200000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 256)              459776    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,676,679\n",
      "Trainable params: 3,676,679\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "\n",
    "    layers.Embedding(\n",
    "        input_dim = max_vocab,\n",
    "        output_dim = 320,\n",
    "        input_length = max_seq_length\n",
    "    ),\n",
    "\n",
    "    layers.Bidirectional( layers.LSTM(128) ),\n",
    "\n",
    "    layers.Dense(64, activation='relu'),\n",
    "\n",
    "    layers.Dense(7, activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = 'adam',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "63/63 [==============================] - 29s 388ms/step - loss: 1.4957 - accuracy: 0.4350 - val_loss: 1.3662 - val_accuracy: 0.5100\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 23s 371ms/step - loss: 1.0574 - accuracy: 0.6135 - val_loss: 1.2456 - val_accuracy: 0.5420\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 23s 365ms/step - loss: 0.7007 - accuracy: 0.7195 - val_loss: 1.1426 - val_accuracy: 0.5940\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 23s 365ms/step - loss: 0.4197 - accuracy: 0.8420 - val_loss: 1.1511 - val_accuracy: 0.6500\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 24s 378ms/step - loss: 0.2155 - accuracy: 0.9305 - val_loss: 1.0637 - val_accuracy: 0.6680\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_token[:2000], cat_train_labels[:2000],\n",
    "    epochs = 5,\n",
    "    validation_data = (val_token[:500], cat_val_labels[:500])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 100), dtype=int64, numpy=\n",
       "array([[  2,  88,  67,   5, 811,  74,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"i dont want to lose him\"]\n",
    "vect_test = text_vectorizer(test)\n",
    "\n",
    "vect_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % its nan\n",
      "27.0 % its joy\n",
      "0.0 % its sadness\n",
      "0.0 % its anger\n",
      "0.0 % its fear\n",
      "69.0 % its love\n",
      "2.0 % its surprise\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(vect_test)\n",
    "\n",
    "test_labels = ['nan', 'joy', 'sadness', 'anger', 'fear', 'love', 'surprise']\n",
    "\n",
    "for i in range(len(prediction[0])):\n",
    "    print(f\"{(prediction[0][i]*100)//1.00} % its {test_labels[i]}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf6ab032c8d0f1ddf2ea4dd4e609e6e6dfd5e53c8a42a3a69958aaabf5715049"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
