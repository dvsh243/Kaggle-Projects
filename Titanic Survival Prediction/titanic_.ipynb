{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 total entries\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "print(f\"{len(train_df)} total entries\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_imputer(raw_array, debug=False):\n",
    "\n",
    "    def namestr(obj, namespace):\n",
    "        return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "    null_count = 0\n",
    "    sum = 0\n",
    "    mean = 0\n",
    "    imputed_array = []\n",
    "\n",
    "    for item in raw_array:\n",
    "        if str(item) == 'nan':\n",
    "            # print(item, end=', ')\n",
    "            null_count = null_count + 1\n",
    "        else: sum = sum + item\n",
    "    \n",
    "    mean = ( sum / len(raw_array) ) // 1\n",
    "\n",
    "    if debug == True:\n",
    "        print(f\"\\nimputing array --> {namestr(raw_array, globals())[0]}\")\n",
    "        print(f\"{null_count} null values\")\n",
    "        print(f\"{len(raw_array) - null_count} numeric values\")\n",
    "        print(f\"{len(raw_array)} total values\")\n",
    "        print(f\"mean = { mean }\")\n",
    "        print(f\"replaced all missing values with mean {mean}\\n\")\n",
    "\n",
    "    for item in raw_array:\n",
    "        if str(item) == 'nan':\n",
    "            item = mean\n",
    "        imputed_array.append(item)\n",
    "        # print(item, end=', ')\n",
    "\n",
    "    return imputed_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "imputing array --> raw_age\n",
      "177 null values\n",
      "714 numeric values\n",
      "891 total values\n",
      "mean = 23.0\n",
      "replaced all missing values with mean 23.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_age = list(train_df['Age'])         # missing values\n",
    "imputed_age = mean_imputer(raw_age, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def categorical(raw_array, tokenizer, debug=False):\n",
    "\n",
    "    def namestr(obj, namespace):\n",
    "        return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "\n",
    "    seq_array = tokenizer.texts_to_sequences(raw_array)\n",
    "\n",
    "    cat_array = tf.keras.utils.to_categorical(seq_array)\n",
    "    cat_array = cat_array[:, 1:]   # cause the [0] value doesnt have anything in the word index\n",
    "\n",
    "\n",
    "    if debug == True:\n",
    "        print(f\"\\ncategorising array --> {namestr(raw_array, globals())[0]}\")\n",
    "        print(f\"unique values --> {tokenizer.word_index}\")\n",
    "        for i in range(5):\n",
    "            print(f\"{raw_array[i]} --> { cat_array[i] }\")\n",
    "        print()\n",
    "        \n",
    "    return cat_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "categorising array --> raw_sex\n",
      "unique values --> {'male': 1, 'female': 2}\n",
      "male --> [1. 0.]\n",
      "female --> [0. 1.]\n",
      "female --> [0. 1.]\n",
      "female --> [0. 1.]\n",
      "male --> [1. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_sex = list(train_df['Sex'])         # categorical\n",
    "\n",
    "sex_tokenizer = tf.keras.preprocessing.text.Tokenizer( lower=False )\n",
    "sex_tokenizer.fit_on_texts(raw_sex)\n",
    "\n",
    "cat_sex = categorical(raw_sex, sex_tokenizer, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_imputer(array, debug=False):\n",
    "\n",
    "    most_common = max(array, key = array.count)\n",
    "    missing_values = 0\n",
    "\n",
    "    for i in range(len(array)):\n",
    "        if str( array[i] ) == 'nan':\n",
    "            missing_values = missing_values + 1\n",
    "            array[i] = most_common\n",
    "\n",
    "    if debug == True:\n",
    "        print(f\"missing values --> {missing_values} out of {len(array)}\")\n",
    "        print(f\"most common value --> {most_common}\")\n",
    "        print(f\"replaced all 'nan' values with '{most_common}'\")\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values --> 2 out of 891\n",
      "most common value --> S\n",
      "replaced all 'nan' values with 'S'\n",
      "\n",
      "categorising array --> raw_region\n",
      "unique values --> {'S': 1, 'C': 2, 'Q': 3}\n",
      "S --> [1. 0. 0.]\n",
      "C --> [0. 1. 0.]\n",
      "S --> [1. 0. 0.]\n",
      "S --> [1. 0. 0.]\n",
      "S --> [1. 0. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_region = list(train_df['Embarked'])     # categorical + missing values\n",
    "raw_region = most_common_imputer(raw_region, debug=True)\n",
    "\n",
    "region_tokenizer = tf.keras.preprocessing.text.Tokenizer( lower=False )\n",
    "region_tokenizer.fit_on_texts(raw_region)\n",
    "\n",
    "cat_region = categorical(raw_region, region_tokenizer, debug=True)\n",
    "\n",
    "# for i in range(8):\n",
    "#     print(f\"{raw_region[i]} --> {cat_region[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived --> [0, 1] \n",
      "passenger class --> [1, 2, 3] \n",
      "siblings --> [0, 1, 2, 3, 4, 5, 8] \n",
      "parents & children --> [0, 1, 2, 3, 4, 5, 6] \n",
      "sex --> ['female', 'male'] \n",
      "region --> ['C', 'Q', 'S'] \n"
     ]
    }
   ],
   "source": [
    "# dropped 'Name', 'Ticket'\n",
    "# 'Cabin' --> Cabin present or not? \n",
    "\n",
    "survived = list(train_df['Survived'])\n",
    "\n",
    "p_class = list(train_df['Pclass'])\n",
    "\n",
    "siblings = list(train_df['SibSp'])\n",
    "parents = list(train_df['Parch'])\n",
    "\n",
    "fare = list(train_df['Fare'])\n",
    "\n",
    "print(f\"survived --> {list(set(survived))} \")\n",
    "print(f\"passenger class --> {list(set(p_class))} \")\n",
    "print(f\"siblings --> {list(set(siblings))} \")\n",
    "print(f\"parents & children --> {list(set(parents))} \")\n",
    "print(f\"sex --> {list(set(raw_sex))} \")\n",
    "print(f\"region --> {list(set(raw_region))} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_categorical(array, debug=False):\n",
    "\n",
    "    cat_array = []\n",
    "\n",
    "    for i in range(len(array)):\n",
    "        if str(array[i]) == 'nan':\n",
    "            cat_array.append(0)\n",
    "        else:\n",
    "            cat_array.append(1)\n",
    "\n",
    "    if debug == True:\n",
    "        for i in range(5):\n",
    "            print(f\"{array[i]} --> {cat_array[i]}\")\n",
    "        print(cat_cabin[:10])\n",
    "\n",
    "    return cat_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan --> 0\n",
      "C85 --> 1\n",
      "nan --> 0\n",
      "C123 --> 1\n",
      "nan --> 0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "cabin_present = list(train_df['Cabin'])\n",
    "cat_cabin = binary_categorical(cabin_present, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --> Mrs. --> count = 125\n",
      "1 --> Miss. --> count = 182\n",
      "2 --> Rev. --> count = 6\n",
      "3 --> Mr. --> count = 531\n",
      "4 --> Master. --> count = 40\n",
      "5 --> Dr. --> count = 7\n",
      "['Mr.', 'Mrs.', 'Miss.', 'Mrs.', 'Mr.', 'Mr.', 'Mr.', 'Master.', 'Mrs.', 'Mrs.']\n"
     ]
    }
   ],
   "source": [
    "raw_names = list(train_df['Name'])\n",
    "\n",
    "proc_names = []\n",
    "positions = ['Mrs.', 'Miss.', 'Rev.', 'Mr.', 'Master.', 'Dr.']\n",
    "\n",
    "for i in range( len(raw_names) ):\n",
    "    name_array = raw_names[i].split(' ')\n",
    "    # print(i, name_array, sep=\" --> \")\n",
    "\n",
    "    token_found = 0\n",
    "    for token in name_array:\n",
    "        if token in positions:\n",
    "            token_found = 1\n",
    "            # print(f\"{token} --> {positions.index(token)}\\n\")\n",
    "            # proc_names.append( positions.index(token) )\n",
    "            proc_names.append( token )\n",
    "    if token_found == 0:\n",
    "        proc_names.append( 'Mr.' )\n",
    "\n",
    "for i in range(len(positions)):\n",
    "    print(f\"{i} --> {positions[i]} --> count = {proc_names.count(positions[i])}\")\n",
    "\n",
    "print(proc_names[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "categorising array --> proc_names\n",
      "unique values --> {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Dr': 5, 'Rev': 6}\n",
      "Mr. --> [1. 0. 0. 0. 0. 0.]\n",
      "Mrs. --> [0. 0. 1. 0. 0. 0.]\n",
      "Miss. --> [0. 1. 0. 0. 0. 0.]\n",
      "Mrs. --> [0. 0. 1. 0. 0. 0.]\n",
      "Mr. --> [1. 0. 0. 0. 0. 0.]\n",
      "\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "name_tokenizer = tf.keras.preprocessing.text.Tokenizer( lower=False )\n",
    "name_tokenizer.fit_on_texts(proc_names)\n",
    "\n",
    "cat_names = categorical(proc_names, name_tokenizer, debug=True)\n",
    "\n",
    "print(cat_names[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 22.0, 1, 0, 7.25, 0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[1, 38.0, 1, 0, 71.2833, 1, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[3, 26.0, 0, 0, 7.925, 0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[1, 35.0, 1, 0, 53.1, 1, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[3, 35.0, 0, 0, 8.05, 0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[3, 23.0, 0, 0, 8.4583, 0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "train_x = []\n",
    "\n",
    "for i in range(len(raw_sex)):\n",
    "    temp = [\n",
    "        p_class[i], imputed_age[i],\n",
    "        siblings[i], parents[i], \n",
    "        fare[i], cat_cabin[i]\n",
    "    ]\n",
    "    temp.extend(cat_sex[i])\n",
    "    temp.extend(cat_region[i])\n",
    "    temp.extend(cat_names[i])\n",
    "    train_x.append(temp)\n",
    "    if i < 6: print(temp)  # printing a sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 17)\n",
      "input shape for model = 17\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "survived = list(train_df['Survived'])\n",
    "\n",
    "train_y = np.array(survived)\n",
    "train_x = np.array(train_x)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(\"input shape for model =\", train_x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "visible = layers.Input( shape=[ train_x.shape[1] ] )\n",
    "x = layers.Dense(64, activation='relu')(visible)\n",
    "# x = layers.Dropout(0.3)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "# x = layers.Dropout(0.3)(x)\n",
    "output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001,\n",
    "    patience=40,\n",
    "    restore_best_weights=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "26/26 - 2s - loss: 0.6366 - accuracy: 0.6392 - val_loss: 0.5503 - val_accuracy: 0.7333 - 2s/epoch - 64ms/step\n",
      "Epoch 2/250\n",
      "26/26 - 0s - loss: 0.5799 - accuracy: 0.7129 - val_loss: 0.5054 - val_accuracy: 0.7778 - 101ms/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "26/26 - 0s - loss: 0.5153 - accuracy: 0.7441 - val_loss: 0.4772 - val_accuracy: 0.8444 - 92ms/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "26/26 - 0s - loss: 0.4692 - accuracy: 0.7965 - val_loss: 0.4549 - val_accuracy: 0.8333 - 111ms/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "26/26 - 0s - loss: 0.4630 - accuracy: 0.8065 - val_loss: 0.4326 - val_accuracy: 0.8111 - 118ms/epoch - 5ms/step\n",
      "Epoch 6/250\n",
      "26/26 - 0s - loss: 0.4525 - accuracy: 0.8065 - val_loss: 0.4234 - val_accuracy: 0.8333 - 94ms/epoch - 4ms/step\n",
      "Epoch 7/250\n",
      "26/26 - 0s - loss: 0.4532 - accuracy: 0.7928 - val_loss: 0.4099 - val_accuracy: 0.8333 - 101ms/epoch - 4ms/step\n",
      "Epoch 8/250\n",
      "26/26 - 0s - loss: 0.4363 - accuracy: 0.7940 - val_loss: 0.3801 - val_accuracy: 0.8444 - 112ms/epoch - 4ms/step\n",
      "Epoch 9/250\n",
      "26/26 - 0s - loss: 0.4233 - accuracy: 0.8202 - val_loss: 0.3698 - val_accuracy: 0.8444 - 87ms/epoch - 3ms/step\n",
      "Epoch 10/250\n",
      "26/26 - 0s - loss: 0.4211 - accuracy: 0.8102 - val_loss: 0.3722 - val_accuracy: 0.8667 - 100ms/epoch - 4ms/step\n",
      "Epoch 11/250\n",
      "26/26 - 0s - loss: 0.4184 - accuracy: 0.8315 - val_loss: 0.3635 - val_accuracy: 0.8889 - 116ms/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "26/26 - 0s - loss: 0.4251 - accuracy: 0.8227 - val_loss: 0.3389 - val_accuracy: 0.8667 - 113ms/epoch - 4ms/step\n",
      "Epoch 13/250\n",
      "26/26 - 0s - loss: 0.4033 - accuracy: 0.8140 - val_loss: 0.3568 - val_accuracy: 0.8778 - 92ms/epoch - 4ms/step\n",
      "Epoch 14/250\n",
      "26/26 - 0s - loss: 0.4165 - accuracy: 0.8227 - val_loss: 0.3264 - val_accuracy: 0.9000 - 102ms/epoch - 4ms/step\n",
      "Epoch 15/250\n",
      "26/26 - 0s - loss: 0.4055 - accuracy: 0.8265 - val_loss: 0.3287 - val_accuracy: 0.8667 - 111ms/epoch - 4ms/step\n",
      "Epoch 16/250\n",
      "26/26 - 0s - loss: 0.3919 - accuracy: 0.8252 - val_loss: 0.3249 - val_accuracy: 0.8778 - 93ms/epoch - 4ms/step\n",
      "Epoch 17/250\n",
      "26/26 - 0s - loss: 0.3922 - accuracy: 0.8340 - val_loss: 0.3275 - val_accuracy: 0.8556 - 86ms/epoch - 3ms/step\n",
      "Epoch 18/250\n",
      "26/26 - 0s - loss: 0.4011 - accuracy: 0.8327 - val_loss: 0.3213 - val_accuracy: 0.8667 - 100ms/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "26/26 - 0s - loss: 0.3975 - accuracy: 0.8202 - val_loss: 0.3339 - val_accuracy: 0.8556 - 123ms/epoch - 5ms/step\n",
      "Epoch 20/250\n",
      "26/26 - 0s - loss: 0.4164 - accuracy: 0.8215 - val_loss: 0.3217 - val_accuracy: 0.8667 - 112ms/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "26/26 - 0s - loss: 0.4004 - accuracy: 0.8227 - val_loss: 0.3425 - val_accuracy: 0.8556 - 128ms/epoch - 5ms/step\n",
      "Epoch 22/250\n",
      "26/26 - 0s - loss: 0.4096 - accuracy: 0.8227 - val_loss: 0.3307 - val_accuracy: 0.8556 - 104ms/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "26/26 - 0s - loss: 0.4143 - accuracy: 0.8202 - val_loss: 0.3143 - val_accuracy: 0.8667 - 103ms/epoch - 4ms/step\n",
      "Epoch 24/250\n",
      "26/26 - 0s - loss: 0.3804 - accuracy: 0.8452 - val_loss: 0.3249 - val_accuracy: 0.8667 - 112ms/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "26/26 - 0s - loss: 0.3906 - accuracy: 0.8340 - val_loss: 0.3148 - val_accuracy: 0.8778 - 119ms/epoch - 5ms/step\n",
      "Epoch 26/250\n",
      "26/26 - 0s - loss: 0.3900 - accuracy: 0.8340 - val_loss: 0.3206 - val_accuracy: 0.8556 - 105ms/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "26/26 - 0s - loss: 0.3846 - accuracy: 0.8327 - val_loss: 0.3243 - val_accuracy: 0.8667 - 140ms/epoch - 5ms/step\n",
      "Epoch 28/250\n",
      "26/26 - 0s - loss: 0.3940 - accuracy: 0.8352 - val_loss: 0.3175 - val_accuracy: 0.8778 - 102ms/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "26/26 - 0s - loss: 0.3967 - accuracy: 0.8327 - val_loss: 0.3269 - val_accuracy: 0.8556 - 121ms/epoch - 5ms/step\n",
      "Epoch 30/250\n",
      "26/26 - 0s - loss: 0.3929 - accuracy: 0.8352 - val_loss: 0.3148 - val_accuracy: 0.8667 - 125ms/epoch - 5ms/step\n",
      "Epoch 31/250\n",
      "26/26 - 0s - loss: 0.3917 - accuracy: 0.8277 - val_loss: 0.3165 - val_accuracy: 0.8667 - 105ms/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "26/26 - 0s - loss: 0.3902 - accuracy: 0.8327 - val_loss: 0.3105 - val_accuracy: 0.8778 - 106ms/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "26/26 - 0s - loss: 0.3734 - accuracy: 0.8352 - val_loss: 0.3205 - val_accuracy: 0.8444 - 103ms/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "26/26 - 0s - loss: 0.3779 - accuracy: 0.8402 - val_loss: 0.3083 - val_accuracy: 0.8667 - 124ms/epoch - 5ms/step\n",
      "Epoch 35/250\n",
      "26/26 - 0s - loss: 0.3848 - accuracy: 0.8340 - val_loss: 0.3222 - val_accuracy: 0.8444 - 123ms/epoch - 5ms/step\n",
      "Epoch 36/250\n",
      "26/26 - 0s - loss: 0.3759 - accuracy: 0.8352 - val_loss: 0.3036 - val_accuracy: 0.8778 - 107ms/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "26/26 - 0s - loss: 0.4036 - accuracy: 0.8090 - val_loss: 0.2989 - val_accuracy: 0.8778 - 133ms/epoch - 5ms/step\n",
      "Epoch 38/250\n",
      "26/26 - 0s - loss: 0.3927 - accuracy: 0.8414 - val_loss: 0.3236 - val_accuracy: 0.8778 - 98ms/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "26/26 - 0s - loss: 0.3947 - accuracy: 0.8302 - val_loss: 0.3122 - val_accuracy: 0.8556 - 94ms/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "26/26 - 0s - loss: 0.3854 - accuracy: 0.8340 - val_loss: 0.3137 - val_accuracy: 0.8778 - 90ms/epoch - 3ms/step\n",
      "Epoch 41/250\n",
      "26/26 - 0s - loss: 0.3813 - accuracy: 0.8427 - val_loss: 0.3156 - val_accuracy: 0.8778 - 96ms/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "26/26 - 0s - loss: 0.3810 - accuracy: 0.8340 - val_loss: 0.3152 - val_accuracy: 0.8556 - 92ms/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "26/26 - 0s - loss: 0.3765 - accuracy: 0.8290 - val_loss: 0.3095 - val_accuracy: 0.8778 - 93ms/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "26/26 - 0s - loss: 0.3798 - accuracy: 0.8439 - val_loss: 0.3118 - val_accuracy: 0.8556 - 97ms/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "26/26 - 0s - loss: 0.3817 - accuracy: 0.8365 - val_loss: 0.3069 - val_accuracy: 0.8778 - 93ms/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "26/26 - 0s - loss: 0.3829 - accuracy: 0.8477 - val_loss: 0.3055 - val_accuracy: 0.8667 - 96ms/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "26/26 - 0s - loss: 0.3794 - accuracy: 0.8302 - val_loss: 0.3211 - val_accuracy: 0.8444 - 98ms/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "26/26 - 0s - loss: 0.3903 - accuracy: 0.8327 - val_loss: 0.3142 - val_accuracy: 0.8667 - 91ms/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "26/26 - 0s - loss: 0.3719 - accuracy: 0.8539 - val_loss: 0.3019 - val_accuracy: 0.9111 - 91ms/epoch - 3ms/step\n",
      "Epoch 50/250\n",
      "26/26 - 0s - loss: 0.3951 - accuracy: 0.8439 - val_loss: 0.3117 - val_accuracy: 0.9111 - 94ms/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "26/26 - 0s - loss: 0.3804 - accuracy: 0.8414 - val_loss: 0.3079 - val_accuracy: 0.9000 - 95ms/epoch - 4ms/step\n",
      "Epoch 52/250\n",
      "26/26 - 0s - loss: 0.3640 - accuracy: 0.8427 - val_loss: 0.3069 - val_accuracy: 0.8667 - 97ms/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "26/26 - 0s - loss: 0.3768 - accuracy: 0.8327 - val_loss: 0.3030 - val_accuracy: 0.8889 - 92ms/epoch - 4ms/step\n",
      "Epoch 54/250\n",
      "26/26 - 0s - loss: 0.3841 - accuracy: 0.8277 - val_loss: 0.3222 - val_accuracy: 0.8778 - 98ms/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "26/26 - 0s - loss: 0.3858 - accuracy: 0.8377 - val_loss: 0.3065 - val_accuracy: 0.8889 - 92ms/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "26/26 - 0s - loss: 0.3548 - accuracy: 0.8514 - val_loss: 0.3057 - val_accuracy: 0.8667 - 95ms/epoch - 4ms/step\n",
      "Epoch 57/250\n",
      "26/26 - 0s - loss: 0.3613 - accuracy: 0.8489 - val_loss: 0.3073 - val_accuracy: 0.8667 - 96ms/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "26/26 - 0s - loss: 0.3682 - accuracy: 0.8439 - val_loss: 0.3003 - val_accuracy: 0.8889 - 96ms/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "26/26 - 0s - loss: 0.3783 - accuracy: 0.8290 - val_loss: 0.3066 - val_accuracy: 0.8889 - 91ms/epoch - 3ms/step\n",
      "Epoch 60/250\n",
      "26/26 - 0s - loss: 0.3670 - accuracy: 0.8452 - val_loss: 0.3058 - val_accuracy: 0.9000 - 95ms/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "26/26 - 0s - loss: 0.3635 - accuracy: 0.8527 - val_loss: 0.3128 - val_accuracy: 0.9000 - 94ms/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "26/26 - 0s - loss: 0.3695 - accuracy: 0.8277 - val_loss: 0.3247 - val_accuracy: 0.8667 - 92ms/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "26/26 - 0s - loss: 0.3759 - accuracy: 0.8327 - val_loss: 0.3040 - val_accuracy: 0.8778 - 92ms/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "26/26 - 0s - loss: 0.3626 - accuracy: 0.8427 - val_loss: 0.3049 - val_accuracy: 0.9000 - 95ms/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "26/26 - 0s - loss: 0.3588 - accuracy: 0.8464 - val_loss: 0.3019 - val_accuracy: 0.8667 - 92ms/epoch - 4ms/step\n",
      "Epoch 66/250\n",
      "26/26 - 0s - loss: 0.3743 - accuracy: 0.8427 - val_loss: 0.3083 - val_accuracy: 0.8778 - 96ms/epoch - 4ms/step\n",
      "Epoch 67/250\n",
      "26/26 - 0s - loss: 0.3668 - accuracy: 0.8464 - val_loss: 0.2975 - val_accuracy: 0.8889 - 95ms/epoch - 4ms/step\n",
      "Epoch 68/250\n",
      "26/26 - 0s - loss: 0.3588 - accuracy: 0.8502 - val_loss: 0.3073 - val_accuracy: 0.8778 - 94ms/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "26/26 - 0s - loss: 0.3619 - accuracy: 0.8402 - val_loss: 0.2986 - val_accuracy: 0.8889 - 92ms/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "26/26 - 0s - loss: 0.3558 - accuracy: 0.8502 - val_loss: 0.3005 - val_accuracy: 0.8667 - 98ms/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "26/26 - 0s - loss: 0.3654 - accuracy: 0.8377 - val_loss: 0.3029 - val_accuracy: 0.8889 - 91ms/epoch - 3ms/step\n",
      "Epoch 72/250\n",
      "26/26 - 0s - loss: 0.3781 - accuracy: 0.8452 - val_loss: 0.3018 - val_accuracy: 0.8889 - 92ms/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "26/26 - 0s - loss: 0.3674 - accuracy: 0.8439 - val_loss: 0.3108 - val_accuracy: 0.8778 - 94ms/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "26/26 - 0s - loss: 0.3565 - accuracy: 0.8527 - val_loss: 0.2936 - val_accuracy: 0.8889 - 93ms/epoch - 4ms/step\n",
      "Epoch 75/250\n",
      "26/26 - 0s - loss: 0.3679 - accuracy: 0.8452 - val_loss: 0.2968 - val_accuracy: 0.8778 - 92ms/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "26/26 - 0s - loss: 0.3512 - accuracy: 0.8377 - val_loss: 0.2918 - val_accuracy: 0.8889 - 97ms/epoch - 4ms/step\n",
      "Epoch 77/250\n",
      "26/26 - 0s - loss: 0.3572 - accuracy: 0.8477 - val_loss: 0.2856 - val_accuracy: 0.9000 - 101ms/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "26/26 - 0s - loss: 0.3589 - accuracy: 0.8552 - val_loss: 0.2927 - val_accuracy: 0.9000 - 96ms/epoch - 4ms/step\n",
      "Epoch 79/250\n",
      "26/26 - 0s - loss: 0.3525 - accuracy: 0.8365 - val_loss: 0.3036 - val_accuracy: 0.8556 - 99ms/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "26/26 - 0s - loss: 0.3591 - accuracy: 0.8527 - val_loss: 0.3009 - val_accuracy: 0.8778 - 96ms/epoch - 4ms/step\n",
      "Epoch 81/250\n",
      "26/26 - 0s - loss: 0.3412 - accuracy: 0.8564 - val_loss: 0.2914 - val_accuracy: 0.9000 - 93ms/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "26/26 - 0s - loss: 0.3598 - accuracy: 0.8502 - val_loss: 0.2970 - val_accuracy: 0.8667 - 93ms/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "26/26 - 0s - loss: 0.3677 - accuracy: 0.8539 - val_loss: 0.2930 - val_accuracy: 0.9000 - 95ms/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "26/26 - 0s - loss: 0.3671 - accuracy: 0.8427 - val_loss: 0.3053 - val_accuracy: 0.8778 - 96ms/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "26/26 - 0s - loss: 0.3453 - accuracy: 0.8552 - val_loss: 0.2940 - val_accuracy: 0.9000 - 92ms/epoch - 4ms/step\n",
      "Epoch 86/250\n",
      "26/26 - 0s - loss: 0.3461 - accuracy: 0.8452 - val_loss: 0.3040 - val_accuracy: 0.8556 - 97ms/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "26/26 - 0s - loss: 0.3603 - accuracy: 0.8514 - val_loss: 0.3102 - val_accuracy: 0.8556 - 98ms/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "26/26 - 0s - loss: 0.3512 - accuracy: 0.8489 - val_loss: 0.3034 - val_accuracy: 0.8667 - 93ms/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "26/26 - 0s - loss: 0.3418 - accuracy: 0.8614 - val_loss: 0.2989 - val_accuracy: 0.8889 - 97ms/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "26/26 - 0s - loss: 0.3526 - accuracy: 0.8564 - val_loss: 0.3000 - val_accuracy: 0.8778 - 96ms/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "26/26 - 0s - loss: 0.3520 - accuracy: 0.8514 - val_loss: 0.2946 - val_accuracy: 0.8667 - 94ms/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "26/26 - 0s - loss: 0.3464 - accuracy: 0.8377 - val_loss: 0.2956 - val_accuracy: 0.8778 - 93ms/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "26/26 - 0s - loss: 0.3594 - accuracy: 0.8477 - val_loss: 0.2999 - val_accuracy: 0.9000 - 97ms/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "26/26 - 0s - loss: 0.3520 - accuracy: 0.8452 - val_loss: 0.2885 - val_accuracy: 0.8778 - 93ms/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "26/26 - 0s - loss: 0.3568 - accuracy: 0.8452 - val_loss: 0.3051 - val_accuracy: 0.8778 - 93ms/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "26/26 - 0s - loss: 0.3403 - accuracy: 0.8527 - val_loss: 0.3009 - val_accuracy: 0.9000 - 96ms/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "26/26 - 0s - loss: 0.3460 - accuracy: 0.8614 - val_loss: 0.2943 - val_accuracy: 0.8889 - 104ms/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "26/26 - 0s - loss: 0.3604 - accuracy: 0.8377 - val_loss: 0.2876 - val_accuracy: 0.9000 - 93ms/epoch - 4ms/step\n",
      "Epoch 99/250\n",
      "26/26 - 0s - loss: 0.3547 - accuracy: 0.8439 - val_loss: 0.3032 - val_accuracy: 0.8889 - 98ms/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "26/26 - 0s - loss: 0.3428 - accuracy: 0.8552 - val_loss: 0.3024 - val_accuracy: 0.8556 - 91ms/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "26/26 - 0s - loss: 0.3516 - accuracy: 0.8489 - val_loss: 0.2922 - val_accuracy: 0.9222 - 96ms/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "26/26 - 0s - loss: 0.3487 - accuracy: 0.8502 - val_loss: 0.2796 - val_accuracy: 0.9111 - 97ms/epoch - 4ms/step\n",
      "Epoch 103/250\n",
      "26/26 - 0s - loss: 0.3453 - accuracy: 0.8489 - val_loss: 0.2895 - val_accuracy: 0.8889 - 97ms/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "26/26 - 0s - loss: 0.3426 - accuracy: 0.8577 - val_loss: 0.2846 - val_accuracy: 0.9000 - 92ms/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "26/26 - 0s - loss: 0.3447 - accuracy: 0.8539 - val_loss: 0.3025 - val_accuracy: 0.8667 - 96ms/epoch - 4ms/step\n",
      "Epoch 106/250\n",
      "26/26 - 0s - loss: 0.3386 - accuracy: 0.8489 - val_loss: 0.2876 - val_accuracy: 0.9111 - 97ms/epoch - 4ms/step\n",
      "Epoch 107/250\n",
      "26/26 - 0s - loss: 0.3375 - accuracy: 0.8539 - val_loss: 0.2843 - val_accuracy: 0.9222 - 97ms/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "26/26 - 0s - loss: 0.3466 - accuracy: 0.8477 - val_loss: 0.2959 - val_accuracy: 0.8889 - 93ms/epoch - 4ms/step\n",
      "Epoch 109/250\n",
      "26/26 - 0s - loss: 0.3564 - accuracy: 0.8477 - val_loss: 0.2951 - val_accuracy: 0.8778 - 98ms/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "26/26 - 0s - loss: 0.3449 - accuracy: 0.8489 - val_loss: 0.2880 - val_accuracy: 0.8889 - 90ms/epoch - 3ms/step\n",
      "Epoch 111/250\n",
      "26/26 - 0s - loss: 0.3501 - accuracy: 0.8564 - val_loss: 0.2871 - val_accuracy: 0.9000 - 93ms/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "26/26 - 0s - loss: 0.3487 - accuracy: 0.8602 - val_loss: 0.2925 - val_accuracy: 0.8778 - 96ms/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "26/26 - 0s - loss: 0.3456 - accuracy: 0.8477 - val_loss: 0.3014 - val_accuracy: 0.8889 - 93ms/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "26/26 - 0s - loss: 0.3504 - accuracy: 0.8589 - val_loss: 0.2959 - val_accuracy: 0.9000 - 92ms/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "26/26 - 0s - loss: 0.3290 - accuracy: 0.8614 - val_loss: 0.2834 - val_accuracy: 0.9222 - 96ms/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "26/26 - 0s - loss: 0.3355 - accuracy: 0.8489 - val_loss: 0.2902 - val_accuracy: 0.8889 - 96ms/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "26/26 - 0s - loss: 0.3389 - accuracy: 0.8589 - val_loss: 0.2948 - val_accuracy: 0.8778 - 96ms/epoch - 4ms/step\n",
      "Epoch 118/250\n",
      "26/26 - 0s - loss: 0.3379 - accuracy: 0.8577 - val_loss: 0.2856 - val_accuracy: 0.8889 - 95ms/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "26/26 - 0s - loss: 0.3305 - accuracy: 0.8627 - val_loss: 0.2773 - val_accuracy: 0.9333 - 95ms/epoch - 4ms/step\n",
      "Epoch 120/250\n",
      "26/26 - 0s - loss: 0.3445 - accuracy: 0.8552 - val_loss: 0.2867 - val_accuracy: 0.9111 - 91ms/epoch - 3ms/step\n",
      "Epoch 121/250\n",
      "26/26 - 0s - loss: 0.3337 - accuracy: 0.8639 - val_loss: 0.2795 - val_accuracy: 0.9333 - 91ms/epoch - 3ms/step\n",
      "Epoch 122/250\n",
      "26/26 - 0s - loss: 0.3249 - accuracy: 0.8627 - val_loss: 0.2854 - val_accuracy: 0.9222 - 98ms/epoch - 4ms/step\n",
      "Epoch 123/250\n",
      "26/26 - 0s - loss: 0.3363 - accuracy: 0.8589 - val_loss: 0.2851 - val_accuracy: 0.9111 - 94ms/epoch - 4ms/step\n",
      "Epoch 124/250\n",
      "26/26 - 0s - loss: 0.3252 - accuracy: 0.8627 - val_loss: 0.2984 - val_accuracy: 0.8778 - 94ms/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "26/26 - 0s - loss: 0.3509 - accuracy: 0.8514 - val_loss: 0.2850 - val_accuracy: 0.9000 - 97ms/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "26/26 - 0s - loss: 0.3341 - accuracy: 0.8677 - val_loss: 0.2904 - val_accuracy: 0.9000 - 94ms/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "26/26 - 0s - loss: 0.3326 - accuracy: 0.8589 - val_loss: 0.2929 - val_accuracy: 0.9111 - 96ms/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "26/26 - 0s - loss: 0.3376 - accuracy: 0.8602 - val_loss: 0.2878 - val_accuracy: 0.9000 - 98ms/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "26/26 - 0s - loss: 0.3377 - accuracy: 0.8614 - val_loss: 0.2889 - val_accuracy: 0.9000 - 92ms/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "26/26 - 0s - loss: 0.3394 - accuracy: 0.8602 - val_loss: 0.2942 - val_accuracy: 0.8667 - 92ms/epoch - 4ms/step\n",
      "Epoch 131/250\n",
      "26/26 - 0s - loss: 0.3398 - accuracy: 0.8589 - val_loss: 0.2894 - val_accuracy: 0.8667 - 93ms/epoch - 4ms/step\n",
      "Epoch 132/250\n",
      "26/26 - 0s - loss: 0.3249 - accuracy: 0.8614 - val_loss: 0.2975 - val_accuracy: 0.8667 - 92ms/epoch - 4ms/step\n",
      "Epoch 133/250\n",
      "26/26 - 0s - loss: 0.3305 - accuracy: 0.8677 - val_loss: 0.3049 - val_accuracy: 0.8889 - 93ms/epoch - 4ms/step\n",
      "Epoch 134/250\n",
      "26/26 - 0s - loss: 0.3236 - accuracy: 0.8664 - val_loss: 0.2875 - val_accuracy: 0.8889 - 93ms/epoch - 4ms/step\n",
      "Epoch 135/250\n",
      "26/26 - 0s - loss: 0.3597 - accuracy: 0.8464 - val_loss: 0.3047 - val_accuracy: 0.8889 - 98ms/epoch - 4ms/step\n",
      "Epoch 136/250\n",
      "26/26 - 0s - loss: 0.3379 - accuracy: 0.8564 - val_loss: 0.3148 - val_accuracy: 0.8556 - 95ms/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "26/26 - 0s - loss: 0.3326 - accuracy: 0.8727 - val_loss: 0.2846 - val_accuracy: 0.9111 - 94ms/epoch - 4ms/step\n",
      "Epoch 138/250\n",
      "26/26 - 0s - loss: 0.3379 - accuracy: 0.8614 - val_loss: 0.2815 - val_accuracy: 0.9111 - 102ms/epoch - 4ms/step\n",
      "Epoch 139/250\n",
      "26/26 - 0s - loss: 0.3467 - accuracy: 0.8414 - val_loss: 0.2971 - val_accuracy: 0.9000 - 92ms/epoch - 4ms/step\n",
      "Epoch 140/250\n",
      "26/26 - 0s - loss: 0.3331 - accuracy: 0.8539 - val_loss: 0.2970 - val_accuracy: 0.8889 - 91ms/epoch - 3ms/step\n",
      "Epoch 141/250\n",
      "26/26 - 0s - loss: 0.3336 - accuracy: 0.8477 - val_loss: 0.2982 - val_accuracy: 0.8889 - 94ms/epoch - 4ms/step\n",
      "Epoch 142/250\n",
      "26/26 - 0s - loss: 0.3298 - accuracy: 0.8602 - val_loss: 0.2794 - val_accuracy: 0.8889 - 92ms/epoch - 4ms/step\n",
      "Epoch 143/250\n",
      "26/26 - 0s - loss: 0.3219 - accuracy: 0.8689 - val_loss: 0.2919 - val_accuracy: 0.8889 - 92ms/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "26/26 - 0s - loss: 0.3373 - accuracy: 0.8527 - val_loss: 0.2890 - val_accuracy: 0.8889 - 97ms/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "26/26 - 0s - loss: 0.3276 - accuracy: 0.8702 - val_loss: 0.3018 - val_accuracy: 0.8889 - 94ms/epoch - 4ms/step\n",
      "Epoch 146/250\n",
      "26/26 - 0s - loss: 0.3413 - accuracy: 0.8552 - val_loss: 0.2896 - val_accuracy: 0.8889 - 94ms/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "26/26 - 0s - loss: 0.3336 - accuracy: 0.8514 - val_loss: 0.2885 - val_accuracy: 0.9000 - 92ms/epoch - 4ms/step\n",
      "Epoch 148/250\n",
      "26/26 - 0s - loss: 0.3238 - accuracy: 0.8664 - val_loss: 0.2967 - val_accuracy: 0.9000 - 102ms/epoch - 4ms/step\n",
      "Epoch 149/250\n",
      "26/26 - 0s - loss: 0.3261 - accuracy: 0.8639 - val_loss: 0.2828 - val_accuracy: 0.9000 - 94ms/epoch - 4ms/step\n",
      "Epoch 150/250\n",
      "26/26 - 0s - loss: 0.3376 - accuracy: 0.8577 - val_loss: 0.2895 - val_accuracy: 0.9000 - 94ms/epoch - 4ms/step\n",
      "Epoch 151/250\n",
      "26/26 - 0s - loss: 0.3306 - accuracy: 0.8627 - val_loss: 0.2975 - val_accuracy: 0.8778 - 95ms/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "26/26 - 0s - loss: 0.3354 - accuracy: 0.8527 - val_loss: 0.2871 - val_accuracy: 0.9000 - 92ms/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "26/26 - 0s - loss: 0.3331 - accuracy: 0.8552 - val_loss: 0.2935 - val_accuracy: 0.8889 - 91ms/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "26/26 - 0s - loss: 0.3128 - accuracy: 0.8764 - val_loss: 0.2922 - val_accuracy: 0.9111 - 96ms/epoch - 4ms/step\n",
      "Epoch 155/250\n",
      "26/26 - 0s - loss: 0.3453 - accuracy: 0.8639 - val_loss: 0.2873 - val_accuracy: 0.9111 - 92ms/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "26/26 - 0s - loss: 0.3202 - accuracy: 0.8639 - val_loss: 0.2954 - val_accuracy: 0.8889 - 93ms/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "26/26 - 0s - loss: 0.3270 - accuracy: 0.8677 - val_loss: 0.2883 - val_accuracy: 0.9000 - 93ms/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "26/26 - 0s - loss: 0.3206 - accuracy: 0.8752 - val_loss: 0.2942 - val_accuracy: 0.9000 - 99ms/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "26/26 - 0s - loss: 0.3212 - accuracy: 0.8639 - val_loss: 0.2849 - val_accuracy: 0.9000 - 93ms/epoch - 4ms/step\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3022988438606262, 0.8731762170791626]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stopping],\n",
    "    epochs=250,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "model.evaluate(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot( history.history['accuracy'] )\n",
    "plt.plot( history.history['loss'] )\n",
    "plt.plot( history.history['val_loss'] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions on training dataset :-\n",
      "778 correct predictions out of 891\n",
      "accuracy = 87.31 %\n"
     ]
    }
   ],
   "source": [
    "# predicting on the testing data\n",
    "\n",
    "predictions = model.predict(train_x)\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(predictions)):\n",
    "    # print(f\"{train_y[i]} predicted --> { (predictions[i][0]*100)//1 } %\")\n",
    "\n",
    "    if predictions[i] > 0.500 and train_y[i] == 1:\n",
    "            correct = correct + 1\n",
    "\n",
    "    if predictions[i] < 0.500 and train_y[i] == 0:\n",
    "            correct = correct + 1\n",
    "\n",
    "print(\"predictions on training dataset :-\")\n",
    "print(f\"{correct} correct predictions out of {len(predictions)}\")\n",
    "print(f\"accuracy = { str((correct / len(predictions)) * 100)[:5] } %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "categorising array --> raw_sex\n",
      "unique values --> {'male': 1, 'female': 2}\n",
      "male --> [1. 0.]\n",
      "female --> [0. 1.]\n",
      "male --> [1. 0.]\n",
      "male --> [1. 0.]\n",
      "female --> [0. 1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_sex = list(test_df['Sex'])         # categorical\n",
    "\n",
    "cat_sex = categorical(raw_sex, sex_tokenizer, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values --> 0 out of 418\n",
      "most common value --> S\n",
      "replaced all 'nan' values with 'S'\n",
      "\n",
      "categorising array --> raw_region\n",
      "unique values --> {'S': 1, 'C': 2, 'Q': 3}\n",
      "Q --> [0. 0. 1.]\n",
      "S --> [1. 0. 0.]\n",
      "Q --> [0. 0. 1.]\n",
      "S --> [1. 0. 0.]\n",
      "S --> [1. 0. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_region = list(test_df['Embarked'])     # categorical + missing values\n",
    "raw_region = most_common_imputer(raw_region, debug=True)\n",
    "\n",
    "cat_region = categorical(raw_region, region_tokenizer, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passenger class --> [1, 2, 3] \n",
      "siblings --> [0, 1, 2, 3, 4, 5, 8] \n",
      "parents & children --> [0, 1, 2, 3, 4, 5, 6, 9] \n",
      "sex --> ['female', 'male'] \n",
      "region --> ['Q', 'S', 'C'] \n"
     ]
    }
   ],
   "source": [
    "# dropped 'Name', 'Ticket'\n",
    "# 'Cabin' --> Cabin present or not? \n",
    "\n",
    "p_class = list(test_df['Pclass'])\n",
    "\n",
    "siblings = list(test_df['SibSp'])\n",
    "parents = list(test_df['Parch'])\n",
    "\n",
    "fare = list(test_df['Fare'])\n",
    "\n",
    "print(f\"passenger class --> {list(set(p_class))} \")\n",
    "print(f\"siblings --> {list(set(siblings))} \")\n",
    "print(f\"parents & children --> {list(set(parents))} \")\n",
    "print(f\"sex --> {list(set(raw_sex))} \")\n",
    "print(f\"region --> {list(set(raw_region))} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan --> 0\n",
      "nan --> 0\n",
      "nan --> 0\n",
      "nan --> 0\n",
      "nan --> 0\n",
      "[0, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "cabin_present = list(test_df['Cabin'])\n",
    "cat_cabin = binary_categorical(cabin_present, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --> Mrs. --> count = 72\n",
      "1 --> Miss. --> count = 78\n",
      "2 --> Rev. --> count = 2\n",
      "3 --> Mr. --> count = 244\n",
      "4 --> Master. --> count = 21\n",
      "5 --> Dr. --> count = 1\n",
      "['Mr.', 'Mrs.', 'Mr.', 'Mr.', 'Mrs.', 'Mr.', 'Miss.', 'Mr.', 'Mrs.', 'Mr.']\n"
     ]
    }
   ],
   "source": [
    "raw_names = list(test_df['Name'])\n",
    "\n",
    "proc_names = []\n",
    "positions = ['Mrs.', 'Miss.', 'Rev.', 'Mr.', 'Master.', 'Dr.']\n",
    "\n",
    "for i in range( len(raw_names) ):\n",
    "    name_array = raw_names[i].split(' ')\n",
    "    # print(i, name_array, sep=\" --> \")\n",
    "\n",
    "    token_found = 0\n",
    "    for token in name_array:\n",
    "        if token in positions:\n",
    "            token_found = 1\n",
    "            # print(f\"{token} --> {positions.index(token)}\\n\")\n",
    "            # proc_names.append( positions.index(token) )\n",
    "            proc_names.append( token )\n",
    "    if token_found == 0:\n",
    "        proc_names.append( 'Mr.' )\n",
    "\n",
    "for i in range(len(positions)):\n",
    "    print(f\"{i} --> {positions[i]} --> count = {proc_names.count(positions[i])}\")\n",
    "\n",
    "print(proc_names[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "categorising array --> proc_names\n",
      "unique values --> {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Dr': 5, 'Rev': 6}\n",
      "Mr. --> [1. 0. 0. 0. 0. 0.]\n",
      "Mrs. --> [0. 0. 1. 0. 0. 0.]\n",
      "Mr. --> [1. 0. 0. 0. 0. 0.]\n",
      "Mr. --> [1. 0. 0. 0. 0. 0.]\n",
      "Mrs. --> [0. 0. 1. 0. 0. 0.]\n",
      "\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "cat_names = categorical(proc_names, name_tokenizer, debug=True)\n",
    "\n",
    "print(cat_names[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 22.0, 0, 0, 7.8292, 0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[3, 38.0, 1, 0, 7.0, 0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[2, 26.0, 0, 0, 9.6875, 0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[3, 35.0, 0, 0, 8.6625, 0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[3, 35.0, 1, 1, 12.2875, 0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[3, 23.0, 0, 0, 9.225, 0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "test_x = []\n",
    "\n",
    "for i in range(len(raw_sex)):\n",
    "    temp = [\n",
    "        p_class[i], imputed_age[i],\n",
    "        siblings[i], parents[i], \n",
    "        fare[i], cat_cabin[i]\n",
    "    ]\n",
    "    temp.extend(cat_sex[i])\n",
    "    temp.extend(cat_region[i])\n",
    "    temp.extend(cat_names[i])\n",
    "    test_x.append(temp)\n",
    "    if i < 6: print(temp)\n",
    "    \n",
    "test_x = np.array(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 17)\n",
      "input shape for test_x = 17\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(\"input shape for test_x =\", train_x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_x)\n",
    "\n",
    "csv_pred = []\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i][0] > 0.500: \n",
    "        csv_pred.append(1)\n",
    "    else:\n",
    "        csv_pred.append(0)\n",
    "\n",
    "print(csv_pred[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_id = list(test_df['PassengerId'])\n",
    "\n",
    "submit_dict = {\n",
    "    'PassengerId': passenger_id,\n",
    "    'Survived': csv_pred\n",
    "}\n",
    "\n",
    "submit_df = pd.DataFrame(submit_dict)\n",
    "submit_df.head()\n",
    "\n",
    "submit_df.to_csv('submit.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf6ab032c8d0f1ddf2ea4dd4e609e6e6dfd5e53c8a42a3a69958aaabf5715049"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
