{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 total entries\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "print(f\"{len(train_df)} total entries\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_imputer(raw_array, debug=False):\n",
    "\n",
    "    def namestr(obj, namespace):\n",
    "        return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "    null_count = 0\n",
    "    sum = 0\n",
    "    mean = 0\n",
    "    imputed_array = []\n",
    "\n",
    "    for item in raw_array:\n",
    "        if str(item) == 'nan':\n",
    "            # print(item, end=', ')\n",
    "            null_count = null_count + 1\n",
    "        else: sum = sum + item\n",
    "    \n",
    "    mean = ( sum / len(raw_array) ) // 1\n",
    "\n",
    "    if debug == True:\n",
    "        print(f\"\\nimputing array --> {namestr(raw_array, globals())[0]}\")\n",
    "        print(f\"{null_count} null values\")\n",
    "        print(f\"{len(raw_array) - null_count} numeric values\")\n",
    "        print(f\"{len(raw_array)} total values\")\n",
    "        print(f\"mean = { mean }\")\n",
    "        print(f\"replaced all missing values with mean {mean}\\n\")\n",
    "\n",
    "    for item in raw_array:\n",
    "        if str(item) == 'nan':\n",
    "            item = mean\n",
    "        imputed_array.append(item)\n",
    "        # print(item, end=', ')\n",
    "\n",
    "    return imputed_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "imputing array --> raw_age\n",
      "177 null values\n",
      "714 numeric values\n",
      "891 total values\n",
      "mean = 23.0\n",
      "replaced all missing values with mean 23.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_age = list(train_df['Age'])         # missing values\n",
    "imputed_age = mean_imputer(raw_age, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def categorical(raw_array, tokenizer, debug=False):\n",
    "\n",
    "    def namestr(obj, namespace):\n",
    "        return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "\n",
    "    seq_array = tokenizer.texts_to_sequences(raw_array)\n",
    "\n",
    "    cat_array = tf.keras.utils.to_categorical(seq_array)\n",
    "    cat_array = cat_array[:, 1:]   # cause the [0] value doesnt have anything in the word index\n",
    "\n",
    "\n",
    "    if debug == True:\n",
    "        print(f\"\\ncategorising array --> {namestr(raw_array, globals())[0]}\")\n",
    "        print(f\"unique values --> {tokenizer.word_index}\")\n",
    "        for i in range(5):\n",
    "            print(f\"{raw_array[i]} --> { cat_array[i] }\")\n",
    "        print()\n",
    "        \n",
    "    return cat_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "categorising array --> raw_sex\n",
      "unique values --> {'male': 1, 'female': 2}\n",
      "male --> [1. 0.]\n",
      "female --> [0. 1.]\n",
      "female --> [0. 1.]\n",
      "female --> [0. 1.]\n",
      "male --> [1. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_sex = list(train_df['Sex'])         # categorical\n",
    "\n",
    "sex_tokenizer = tf.keras.preprocessing.text.Tokenizer( lower=False )\n",
    "sex_tokenizer.fit_on_texts(raw_sex)\n",
    "\n",
    "cat_sex = categorical(raw_sex, sex_tokenizer, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_imputer(array, debug=False):\n",
    "\n",
    "    most_common = max(array, key = array.count)\n",
    "    missing_values = 0\n",
    "\n",
    "    for i in range(len(array)):\n",
    "        if str( array[i] ) == 'nan':\n",
    "            missing_values = missing_values + 1\n",
    "            array[i] = most_common\n",
    "\n",
    "    if debug == True:\n",
    "        print(f\"missing values --> {missing_values} out of {len(array)}\")\n",
    "        print(f\"most common value --> {most_common}\")\n",
    "        print(f\"replaced all 'nan' values with '{most_common}'\")\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values --> 2 out of 891\n",
      "most common value --> S\n",
      "replaced all 'nan' values with 'S'\n",
      "\n",
      "categorising array --> raw_region\n",
      "unique values --> {'S': 1, 'C': 2, 'Q': 3}\n",
      "S --> [1. 0. 0.]\n",
      "C --> [0. 1. 0.]\n",
      "S --> [1. 0. 0.]\n",
      "S --> [1. 0. 0.]\n",
      "S --> [1. 0. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_region = list(train_df['Embarked'])     # categorical + missing values\n",
    "raw_region = most_common_imputer(raw_region, debug=True)\n",
    "\n",
    "region_tokenizer = tf.keras.preprocessing.text.Tokenizer( lower=False )\n",
    "region_tokenizer.fit_on_texts(raw_region)\n",
    "\n",
    "cat_region = categorical(raw_region, region_tokenizer, debug=True)\n",
    "\n",
    "# for i in range(8):\n",
    "#     print(f\"{raw_region[i]} --> {cat_region[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived --> [0, 1] \n",
      "passenger class --> [1, 2, 3] \n",
      "siblings --> [0, 1, 2, 3, 4, 5, 8] \n",
      "parents & children --> [0, 1, 2, 3, 4, 5, 6] \n",
      "sex --> ['male', 'female'] \n",
      "region --> ['Q', 'S', 'C'] \n"
     ]
    }
   ],
   "source": [
    "# dropped 'Name', 'Ticket'\n",
    "# 'Cabin' --> Cabin present or not? \n",
    "\n",
    "survived = list(train_df['Survived'])\n",
    "\n",
    "p_class = list(train_df['Pclass'])\n",
    "\n",
    "siblings = list(train_df['SibSp'])\n",
    "parents = list(train_df['Parch'])\n",
    "\n",
    "fare = list(train_df['Fare'])\n",
    "\n",
    "print(f\"survived --> {list(set(survived))} \")\n",
    "print(f\"passenger class --> {list(set(p_class))} \")\n",
    "print(f\"siblings --> {list(set(siblings))} \")\n",
    "print(f\"parents & children --> {list(set(parents))} \")\n",
    "print(f\"sex --> {list(set(raw_sex))} \")\n",
    "print(f\"region --> {list(set(raw_region))} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_categorical(array, debug=False):\n",
    "\n",
    "    cat_array = []\n",
    "\n",
    "    for i in range(len(array)):\n",
    "        if str(array[i]) == 'nan':\n",
    "            cat_array.append(0)\n",
    "        else:\n",
    "            cat_array.append(1)\n",
    "\n",
    "    if debug == True:\n",
    "        for i in range(5):\n",
    "            print(f\"{array[i]} --> {cat_array[i]}\")\n",
    "        print(cat_array[:10])\n",
    "\n",
    "    return cat_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan --> 0\n",
      "C85 --> 1\n",
      "nan --> 0\n",
      "C123 --> 1\n",
      "nan --> 0\n",
      "[0, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "cabin_present = list(train_df['Cabin'])\n",
    "cat_cabin = binary_categorical(cabin_present, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --> Mrs. --> count = 125\n",
      "1 --> Miss. --> count = 182\n",
      "2 --> Rev. --> count = 6\n",
      "3 --> Mr. --> count = 531\n",
      "4 --> Master. --> count = 40\n",
      "5 --> Dr. --> count = 7\n",
      "['Mr.', 'Mrs.', 'Miss.', 'Mrs.', 'Mr.', 'Mr.', 'Mr.', 'Master.', 'Mrs.', 'Mrs.']\n"
     ]
    }
   ],
   "source": [
    "raw_names = list(train_df['Name'])\n",
    "\n",
    "proc_names = []\n",
    "positions = ['Mrs.', 'Miss.', 'Rev.', 'Mr.', 'Master.', 'Dr.']\n",
    "\n",
    "for i in range( len(raw_names) ):\n",
    "    name_array = raw_names[i].split(' ')\n",
    "    # print(i, name_array, sep=\" --> \")\n",
    "\n",
    "    token_found = 0\n",
    "    for token in name_array:\n",
    "        if token in positions:\n",
    "            token_found = 1\n",
    "            # print(f\"{token} --> {positions.index(token)}\\n\")\n",
    "            # proc_names.append( positions.index(token) )\n",
    "            proc_names.append( token )\n",
    "    if token_found == 0:\n",
    "        proc_names.append( 'Mr.' )\n",
    "\n",
    "for i in range(len(positions)):\n",
    "    print(f\"{i} --> {positions[i]} --> count = {proc_names.count(positions[i])}\")\n",
    "\n",
    "print(proc_names[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "categorising array --> proc_names\n",
      "unique values --> {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Dr': 5, 'Rev': 6}\n",
      "Mr. --> [1. 0. 0. 0. 0. 0.]\n",
      "Mrs. --> [0. 0. 1. 0. 0. 0.]\n",
      "Miss. --> [0. 1. 0. 0. 0. 0.]\n",
      "Mrs. --> [0. 0. 1. 0. 0. 0.]\n",
      "Mr. --> [1. 0. 0. 0. 0. 0.]\n",
      "\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "name_tokenizer = tf.keras.preprocessing.text.Tokenizer( lower=False )\n",
    "name_tokenizer.fit_on_texts(proc_names)\n",
    "\n",
    "cat_names = categorical(proc_names, name_tokenizer, debug=True)\n",
    "\n",
    "print(cat_names[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 22.0, 1, 0, 7.25, 0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[1, 38.0, 1, 0, 71.2833, 1, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[3, 26.0, 0, 0, 7.925, 0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[1, 35.0, 1, 0, 53.1, 1, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[3, 35.0, 0, 0, 8.05, 0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[3, 23.0, 0, 0, 8.4583, 0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "train_x = []\n",
    "\n",
    "for i in range(len(raw_sex)):\n",
    "    temp = [\n",
    "        p_class[i], imputed_age[i],\n",
    "        siblings[i], parents[i], \n",
    "        fare[i], cat_cabin[i]\n",
    "    ]\n",
    "    temp.extend(cat_sex[i])\n",
    "    temp.extend(cat_region[i])\n",
    "    temp.extend(cat_names[i])\n",
    "    train_x.append(temp)\n",
    "    if i < 6: print(temp)  # printing a sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 17)\n",
      "input shape for model = 17\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "survived = list(train_df['Survived'])\n",
    "\n",
    "train_y = np.array(survived)\n",
    "train_x = np.array(train_x)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(\"input shape for model =\", train_x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "visible = layers.Input( shape=[ train_x.shape[1] ] )\n",
    "x = layers.Dense(64, activation='relu')(visible)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0006,\n",
    "    patience=40,\n",
    "    restore_best_weights=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "26/26 - 2s - loss: 1.9609 - accuracy: 0.5418 - val_loss: 0.7602 - val_accuracy: 0.7222 - 2s/epoch - 77ms/step\n",
      "Epoch 2/250\n",
      "26/26 - 0s - loss: 1.5797 - accuracy: 0.5780 - val_loss: 0.7094 - val_accuracy: 0.6556 - 124ms/epoch - 5ms/step\n",
      "Epoch 3/250\n",
      "26/26 - 0s - loss: 1.3265 - accuracy: 0.5780 - val_loss: 0.5975 - val_accuracy: 0.6556 - 113ms/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "26/26 - 0s - loss: 1.0784 - accuracy: 0.6192 - val_loss: 0.5922 - val_accuracy: 0.6444 - 158ms/epoch - 6ms/step\n",
      "Epoch 5/250\n",
      "26/26 - 0s - loss: 1.1183 - accuracy: 0.5830 - val_loss: 0.5838 - val_accuracy: 0.7000 - 142ms/epoch - 5ms/step\n",
      "Epoch 6/250\n",
      "26/26 - 0s - loss: 0.9408 - accuracy: 0.6155 - val_loss: 0.5843 - val_accuracy: 0.6667 - 124ms/epoch - 5ms/step\n",
      "Epoch 7/250\n",
      "26/26 - 0s - loss: 0.8054 - accuracy: 0.6417 - val_loss: 0.5918 - val_accuracy: 0.6889 - 129ms/epoch - 5ms/step\n",
      "Epoch 8/250\n",
      "26/26 - 0s - loss: 0.7913 - accuracy: 0.6567 - val_loss: 0.5784 - val_accuracy: 0.7111 - 138ms/epoch - 5ms/step\n",
      "Epoch 9/250\n",
      "26/26 - 0s - loss: 0.7541 - accuracy: 0.6504 - val_loss: 0.5615 - val_accuracy: 0.7222 - 131ms/epoch - 5ms/step\n",
      "Epoch 10/250\n",
      "26/26 - 0s - loss: 0.7698 - accuracy: 0.6155 - val_loss: 0.5788 - val_accuracy: 0.7222 - 126ms/epoch - 5ms/step\n",
      "Epoch 11/250\n",
      "26/26 - 0s - loss: 0.7111 - accuracy: 0.6567 - val_loss: 0.5835 - val_accuracy: 0.7000 - 143ms/epoch - 5ms/step\n",
      "Epoch 12/250\n",
      "26/26 - 0s - loss: 0.7770 - accuracy: 0.6404 - val_loss: 0.5726 - val_accuracy: 0.7000 - 156ms/epoch - 6ms/step\n",
      "Epoch 13/250\n",
      "26/26 - 0s - loss: 0.7109 - accuracy: 0.6492 - val_loss: 0.5593 - val_accuracy: 0.6889 - 159ms/epoch - 6ms/step\n",
      "Epoch 14/250\n",
      "26/26 - 0s - loss: 0.7063 - accuracy: 0.6604 - val_loss: 0.5851 - val_accuracy: 0.7222 - 121ms/epoch - 5ms/step\n",
      "Epoch 15/250\n",
      "26/26 - 0s - loss: 0.6497 - accuracy: 0.6916 - val_loss: 0.5783 - val_accuracy: 0.7111 - 134ms/epoch - 5ms/step\n",
      "Epoch 16/250\n",
      "26/26 - 0s - loss: 0.6732 - accuracy: 0.6767 - val_loss: 0.5820 - val_accuracy: 0.6222 - 132ms/epoch - 5ms/step\n",
      "Epoch 17/250\n",
      "26/26 - 0s - loss: 0.6946 - accuracy: 0.6417 - val_loss: 0.5823 - val_accuracy: 0.6778 - 163ms/epoch - 6ms/step\n",
      "Epoch 18/250\n",
      "26/26 - 0s - loss: 0.6387 - accuracy: 0.6792 - val_loss: 0.5541 - val_accuracy: 0.7222 - 153ms/epoch - 6ms/step\n",
      "Epoch 19/250\n",
      "26/26 - 0s - loss: 0.6211 - accuracy: 0.6754 - val_loss: 0.5466 - val_accuracy: 0.6889 - 129ms/epoch - 5ms/step\n",
      "Epoch 20/250\n",
      "26/26 - 0s - loss: 0.6120 - accuracy: 0.6792 - val_loss: 0.5426 - val_accuracy: 0.7111 - 142ms/epoch - 5ms/step\n",
      "Epoch 21/250\n",
      "26/26 - 0s - loss: 0.6031 - accuracy: 0.7141 - val_loss: 0.5215 - val_accuracy: 0.7111 - 95ms/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "26/26 - 0s - loss: 0.6078 - accuracy: 0.6991 - val_loss: 0.5096 - val_accuracy: 0.7667 - 108ms/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "26/26 - 0s - loss: 0.6002 - accuracy: 0.7166 - val_loss: 0.5202 - val_accuracy: 0.7444 - 131ms/epoch - 5ms/step\n",
      "Epoch 24/250\n",
      "26/26 - 0s - loss: 0.5923 - accuracy: 0.6854 - val_loss: 0.5310 - val_accuracy: 0.7556 - 97ms/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "26/26 - 0s - loss: 0.6040 - accuracy: 0.6929 - val_loss: 0.5160 - val_accuracy: 0.7889 - 116ms/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "26/26 - 0s - loss: 0.5766 - accuracy: 0.7091 - val_loss: 0.4919 - val_accuracy: 0.8000 - 165ms/epoch - 6ms/step\n",
      "Epoch 27/250\n",
      "26/26 - 0s - loss: 0.5707 - accuracy: 0.7203 - val_loss: 0.4928 - val_accuracy: 0.8222 - 123ms/epoch - 5ms/step\n",
      "Epoch 28/250\n",
      "26/26 - 0s - loss: 0.5642 - accuracy: 0.7391 - val_loss: 0.4951 - val_accuracy: 0.8000 - 133ms/epoch - 5ms/step\n",
      "Epoch 29/250\n",
      "26/26 - 0s - loss: 0.5601 - accuracy: 0.7104 - val_loss: 0.5019 - val_accuracy: 0.7778 - 106ms/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "26/26 - 0s - loss: 0.5457 - accuracy: 0.7366 - val_loss: 0.4802 - val_accuracy: 0.8222 - 137ms/epoch - 5ms/step\n",
      "Epoch 31/250\n",
      "26/26 - 0s - loss: 0.5596 - accuracy: 0.7516 - val_loss: 0.4774 - val_accuracy: 0.8111 - 116ms/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "26/26 - 0s - loss: 0.5747 - accuracy: 0.7129 - val_loss: 0.4656 - val_accuracy: 0.8000 - 125ms/epoch - 5ms/step\n",
      "Epoch 33/250\n",
      "26/26 - 0s - loss: 0.5244 - accuracy: 0.7466 - val_loss: 0.4657 - val_accuracy: 0.7889 - 132ms/epoch - 5ms/step\n",
      "Epoch 34/250\n",
      "26/26 - 0s - loss: 0.5250 - accuracy: 0.7640 - val_loss: 0.4649 - val_accuracy: 0.7889 - 103ms/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "26/26 - 0s - loss: 0.5548 - accuracy: 0.7428 - val_loss: 0.4561 - val_accuracy: 0.7889 - 109ms/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "26/26 - 0s - loss: 0.5453 - accuracy: 0.7428 - val_loss: 0.4572 - val_accuracy: 0.7889 - 103ms/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "26/26 - 0s - loss: 0.5371 - accuracy: 0.7653 - val_loss: 0.4487 - val_accuracy: 0.8000 - 95ms/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "26/26 - 0s - loss: 0.5376 - accuracy: 0.7453 - val_loss: 0.4529 - val_accuracy: 0.8000 - 105ms/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "26/26 - 0s - loss: 0.5048 - accuracy: 0.7665 - val_loss: 0.4493 - val_accuracy: 0.7889 - 91ms/epoch - 3ms/step\n",
      "Epoch 40/250\n",
      "26/26 - 0s - loss: 0.5476 - accuracy: 0.7541 - val_loss: 0.4797 - val_accuracy: 0.7889 - 97ms/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "26/26 - 0s - loss: 0.5227 - accuracy: 0.7628 - val_loss: 0.4558 - val_accuracy: 0.7889 - 97ms/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "26/26 - 0s - loss: 0.5153 - accuracy: 0.7591 - val_loss: 0.4493 - val_accuracy: 0.8000 - 92ms/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "26/26 - 0s - loss: 0.5237 - accuracy: 0.7640 - val_loss: 0.4424 - val_accuracy: 0.8000 - 94ms/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "26/26 - 0s - loss: 0.5155 - accuracy: 0.7591 - val_loss: 0.4481 - val_accuracy: 0.7889 - 100ms/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "26/26 - 0s - loss: 0.4967 - accuracy: 0.7640 - val_loss: 0.4344 - val_accuracy: 0.7889 - 97ms/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "26/26 - 0s - loss: 0.4938 - accuracy: 0.7728 - val_loss: 0.4355 - val_accuracy: 0.7889 - 114ms/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "26/26 - 0s - loss: 0.5280 - accuracy: 0.7541 - val_loss: 0.4466 - val_accuracy: 0.7778 - 175ms/epoch - 7ms/step\n",
      "Epoch 48/250\n",
      "26/26 - 0s - loss: 0.5215 - accuracy: 0.7678 - val_loss: 0.4357 - val_accuracy: 0.7889 - 127ms/epoch - 5ms/step\n",
      "Epoch 49/250\n",
      "26/26 - 0s - loss: 0.4989 - accuracy: 0.7740 - val_loss: 0.4300 - val_accuracy: 0.7889 - 98ms/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "26/26 - 0s - loss: 0.5296 - accuracy: 0.7553 - val_loss: 0.4318 - val_accuracy: 0.7889 - 103ms/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "26/26 - 0s - loss: 0.5178 - accuracy: 0.7778 - val_loss: 0.4325 - val_accuracy: 0.7889 - 118ms/epoch - 5ms/step\n",
      "Epoch 52/250\n",
      "26/26 - 0s - loss: 0.5050 - accuracy: 0.7678 - val_loss: 0.4269 - val_accuracy: 0.7889 - 114ms/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "26/26 - 0s - loss: 0.4881 - accuracy: 0.7765 - val_loss: 0.4181 - val_accuracy: 0.8000 - 90ms/epoch - 3ms/step\n",
      "Epoch 54/250\n",
      "26/26 - 0s - loss: 0.4889 - accuracy: 0.7853 - val_loss: 0.4212 - val_accuracy: 0.8000 - 91ms/epoch - 3ms/step\n",
      "Epoch 55/250\n",
      "26/26 - 0s - loss: 0.4986 - accuracy: 0.7828 - val_loss: 0.4145 - val_accuracy: 0.8000 - 121ms/epoch - 5ms/step\n",
      "Epoch 56/250\n",
      "26/26 - 0s - loss: 0.4869 - accuracy: 0.7978 - val_loss: 0.4190 - val_accuracy: 0.7889 - 121ms/epoch - 5ms/step\n",
      "Epoch 57/250\n",
      "26/26 - 0s - loss: 0.4971 - accuracy: 0.7728 - val_loss: 0.4143 - val_accuracy: 0.8000 - 91ms/epoch - 3ms/step\n",
      "Epoch 58/250\n",
      "26/26 - 0s - loss: 0.4964 - accuracy: 0.7778 - val_loss: 0.4170 - val_accuracy: 0.7889 - 92ms/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "26/26 - 0s - loss: 0.4907 - accuracy: 0.7715 - val_loss: 0.4191 - val_accuracy: 0.8000 - 91ms/epoch - 3ms/step\n",
      "Epoch 60/250\n",
      "26/26 - 0s - loss: 0.4849 - accuracy: 0.7790 - val_loss: 0.4261 - val_accuracy: 0.8000 - 109ms/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "26/26 - 0s - loss: 0.5003 - accuracy: 0.7778 - val_loss: 0.4378 - val_accuracy: 0.8111 - 149ms/epoch - 6ms/step\n",
      "Epoch 62/250\n",
      "26/26 - 0s - loss: 0.4933 - accuracy: 0.7853 - val_loss: 0.4193 - val_accuracy: 0.8000 - 99ms/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "26/26 - 0s - loss: 0.4767 - accuracy: 0.7840 - val_loss: 0.4152 - val_accuracy: 0.8111 - 93ms/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "26/26 - 0s - loss: 0.4852 - accuracy: 0.7803 - val_loss: 0.4095 - val_accuracy: 0.8111 - 93ms/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "26/26 - 0s - loss: 0.5071 - accuracy: 0.7778 - val_loss: 0.4194 - val_accuracy: 0.7889 - 105ms/epoch - 4ms/step\n",
      "Epoch 66/250\n",
      "26/26 - 0s - loss: 0.4847 - accuracy: 0.7728 - val_loss: 0.4108 - val_accuracy: 0.7889 - 117ms/epoch - 5ms/step\n",
      "Epoch 67/250\n",
      "26/26 - 0s - loss: 0.4734 - accuracy: 0.7890 - val_loss: 0.4085 - val_accuracy: 0.8000 - 120ms/epoch - 5ms/step\n",
      "Epoch 68/250\n",
      "26/26 - 0s - loss: 0.4905 - accuracy: 0.7690 - val_loss: 0.4329 - val_accuracy: 0.8111 - 91ms/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "26/26 - 0s - loss: 0.4831 - accuracy: 0.7828 - val_loss: 0.4138 - val_accuracy: 0.8111 - 93ms/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "26/26 - 0s - loss: 0.4749 - accuracy: 0.7728 - val_loss: 0.4073 - val_accuracy: 0.8111 - 89ms/epoch - 3ms/step\n",
      "Epoch 71/250\n",
      "26/26 - 0s - loss: 0.4784 - accuracy: 0.7715 - val_loss: 0.4070 - val_accuracy: 0.8111 - 89ms/epoch - 3ms/step\n",
      "Epoch 72/250\n",
      "26/26 - 0s - loss: 0.4788 - accuracy: 0.7765 - val_loss: 0.4022 - val_accuracy: 0.8222 - 121ms/epoch - 5ms/step\n",
      "Epoch 73/250\n",
      "26/26 - 0s - loss: 0.4722 - accuracy: 0.7890 - val_loss: 0.4018 - val_accuracy: 0.8333 - 116ms/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "26/26 - 0s - loss: 0.4551 - accuracy: 0.8015 - val_loss: 0.3952 - val_accuracy: 0.8333 - 93ms/epoch - 4ms/step\n",
      "Epoch 75/250\n",
      "26/26 - 0s - loss: 0.4795 - accuracy: 0.7903 - val_loss: 0.3970 - val_accuracy: 0.8222 - 112ms/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "26/26 - 0s - loss: 0.5037 - accuracy: 0.7828 - val_loss: 0.4038 - val_accuracy: 0.8333 - 132ms/epoch - 5ms/step\n",
      "Epoch 77/250\n",
      "26/26 - 0s - loss: 0.4902 - accuracy: 0.7865 - val_loss: 0.4027 - val_accuracy: 0.8333 - 102ms/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "26/26 - 0s - loss: 0.4717 - accuracy: 0.7990 - val_loss: 0.3972 - val_accuracy: 0.8333 - 93ms/epoch - 4ms/step\n",
      "Epoch 79/250\n",
      "26/26 - 0s - loss: 0.4851 - accuracy: 0.7890 - val_loss: 0.3955 - val_accuracy: 0.8333 - 95ms/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "26/26 - 0s - loss: 0.4893 - accuracy: 0.7840 - val_loss: 0.4136 - val_accuracy: 0.8444 - 92ms/epoch - 4ms/step\n",
      "Epoch 81/250\n",
      "26/26 - 0s - loss: 0.4567 - accuracy: 0.7878 - val_loss: 0.3931 - val_accuracy: 0.8333 - 88ms/epoch - 3ms/step\n",
      "Epoch 82/250\n",
      "26/26 - 0s - loss: 0.4756 - accuracy: 0.7728 - val_loss: 0.3912 - val_accuracy: 0.8222 - 92ms/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "26/26 - 0s - loss: 0.4647 - accuracy: 0.7965 - val_loss: 0.3878 - val_accuracy: 0.8444 - 91ms/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "26/26 - 0s - loss: 0.4499 - accuracy: 0.8002 - val_loss: 0.3899 - val_accuracy: 0.8222 - 102ms/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "26/26 - 0s - loss: 0.4643 - accuracy: 0.7803 - val_loss: 0.3851 - val_accuracy: 0.8333 - 119ms/epoch - 5ms/step\n",
      "Epoch 86/250\n",
      "26/26 - 0s - loss: 0.4630 - accuracy: 0.7853 - val_loss: 0.3827 - val_accuracy: 0.8333 - 127ms/epoch - 5ms/step\n",
      "Epoch 87/250\n",
      "26/26 - 0s - loss: 0.4529 - accuracy: 0.7903 - val_loss: 0.3855 - val_accuracy: 0.8333 - 96ms/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "26/26 - 0s - loss: 0.4710 - accuracy: 0.8002 - val_loss: 0.4044 - val_accuracy: 0.8333 - 92ms/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "26/26 - 0s - loss: 0.4630 - accuracy: 0.8115 - val_loss: 0.3858 - val_accuracy: 0.8444 - 94ms/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "26/26 - 0s - loss: 0.4612 - accuracy: 0.7990 - val_loss: 0.3840 - val_accuracy: 0.8444 - 90ms/epoch - 3ms/step\n",
      "Epoch 91/250\n",
      "26/26 - 0s - loss: 0.4591 - accuracy: 0.7978 - val_loss: 0.3923 - val_accuracy: 0.8444 - 93ms/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "26/26 - 0s - loss: 0.4542 - accuracy: 0.7928 - val_loss: 0.3840 - val_accuracy: 0.8444 - 89ms/epoch - 3ms/step\n",
      "Epoch 93/250\n",
      "26/26 - 0s - loss: 0.4627 - accuracy: 0.8015 - val_loss: 0.3834 - val_accuracy: 0.8444 - 97ms/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "26/26 - 0s - loss: 0.4561 - accuracy: 0.8002 - val_loss: 0.3843 - val_accuracy: 0.8444 - 86ms/epoch - 3ms/step\n",
      "Epoch 95/250\n",
      "26/26 - 0s - loss: 0.4640 - accuracy: 0.7990 - val_loss: 0.3738 - val_accuracy: 0.8444 - 91ms/epoch - 3ms/step\n",
      "Epoch 96/250\n",
      "26/26 - 0s - loss: 0.4638 - accuracy: 0.7965 - val_loss: 0.3773 - val_accuracy: 0.8444 - 97ms/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "26/26 - 0s - loss: 0.4529 - accuracy: 0.7978 - val_loss: 0.3736 - val_accuracy: 0.8444 - 95ms/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "26/26 - 0s - loss: 0.4413 - accuracy: 0.8027 - val_loss: 0.3723 - val_accuracy: 0.8444 - 89ms/epoch - 3ms/step\n",
      "Epoch 99/250\n",
      "26/26 - 0s - loss: 0.4488 - accuracy: 0.7978 - val_loss: 0.3767 - val_accuracy: 0.8444 - 90ms/epoch - 3ms/step\n",
      "Epoch 100/250\n",
      "26/26 - 0s - loss: 0.4479 - accuracy: 0.8065 - val_loss: 0.3803 - val_accuracy: 0.8444 - 92ms/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "26/26 - 0s - loss: 0.4594 - accuracy: 0.8002 - val_loss: 0.3764 - val_accuracy: 0.8444 - 94ms/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "26/26 - 0s - loss: 0.4632 - accuracy: 0.8102 - val_loss: 0.3757 - val_accuracy: 0.8444 - 89ms/epoch - 3ms/step\n",
      "Epoch 103/250\n",
      "26/26 - 0s - loss: 0.4583 - accuracy: 0.8002 - val_loss: 0.3928 - val_accuracy: 0.8444 - 90ms/epoch - 3ms/step\n",
      "Epoch 104/250\n",
      "26/26 - 0s - loss: 0.4498 - accuracy: 0.8177 - val_loss: 0.3732 - val_accuracy: 0.8444 - 91ms/epoch - 3ms/step\n",
      "Epoch 105/250\n",
      "26/26 - 0s - loss: 0.4591 - accuracy: 0.8090 - val_loss: 0.3751 - val_accuracy: 0.8444 - 89ms/epoch - 3ms/step\n",
      "Epoch 106/250\n",
      "26/26 - 0s - loss: 0.4444 - accuracy: 0.7953 - val_loss: 0.3706 - val_accuracy: 0.8444 - 85ms/epoch - 3ms/step\n",
      "Epoch 107/250\n",
      "26/26 - 0s - loss: 0.4562 - accuracy: 0.8002 - val_loss: 0.3764 - val_accuracy: 0.8333 - 97ms/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "26/26 - 0s - loss: 0.4487 - accuracy: 0.8002 - val_loss: 0.3667 - val_accuracy: 0.8444 - 86ms/epoch - 3ms/step\n",
      "Epoch 109/250\n",
      "26/26 - 0s - loss: 0.4440 - accuracy: 0.8015 - val_loss: 0.3619 - val_accuracy: 0.8444 - 90ms/epoch - 3ms/step\n",
      "Epoch 110/250\n",
      "26/26 - 0s - loss: 0.4570 - accuracy: 0.8015 - val_loss: 0.3682 - val_accuracy: 0.8444 - 91ms/epoch - 3ms/step\n",
      "Epoch 111/250\n",
      "26/26 - 0s - loss: 0.4444 - accuracy: 0.8077 - val_loss: 0.3639 - val_accuracy: 0.8444 - 94ms/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "26/26 - 0s - loss: 0.4468 - accuracy: 0.8065 - val_loss: 0.3572 - val_accuracy: 0.8556 - 99ms/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "26/26 - 0s - loss: 0.4642 - accuracy: 0.8040 - val_loss: 0.3547 - val_accuracy: 0.8444 - 90ms/epoch - 3ms/step\n",
      "Epoch 114/250\n",
      "26/26 - 0s - loss: 0.4410 - accuracy: 0.8127 - val_loss: 0.3706 - val_accuracy: 0.8444 - 89ms/epoch - 3ms/step\n",
      "Epoch 115/250\n",
      "26/26 - 0s - loss: 0.4499 - accuracy: 0.8177 - val_loss: 0.3665 - val_accuracy: 0.8444 - 90ms/epoch - 3ms/step\n",
      "Epoch 116/250\n",
      "26/26 - 0s - loss: 0.4524 - accuracy: 0.8065 - val_loss: 0.3746 - val_accuracy: 0.8556 - 85ms/epoch - 3ms/step\n",
      "Epoch 117/250\n",
      "26/26 - 0s - loss: 0.4487 - accuracy: 0.8065 - val_loss: 0.3600 - val_accuracy: 0.8444 - 86ms/epoch - 3ms/step\n",
      "Epoch 118/250\n",
      "26/26 - 0s - loss: 0.4407 - accuracy: 0.8202 - val_loss: 0.3591 - val_accuracy: 0.8444 - 100ms/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "26/26 - 0s - loss: 0.4550 - accuracy: 0.8140 - val_loss: 0.3607 - val_accuracy: 0.8444 - 90ms/epoch - 3ms/step\n",
      "Epoch 120/250\n",
      "26/26 - 0s - loss: 0.4361 - accuracy: 0.8202 - val_loss: 0.3541 - val_accuracy: 0.8778 - 92ms/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "26/26 - 0s - loss: 0.4373 - accuracy: 0.8152 - val_loss: 0.3533 - val_accuracy: 0.8556 - 89ms/epoch - 3ms/step\n",
      "Epoch 122/250\n",
      "26/26 - 0s - loss: 0.4572 - accuracy: 0.8227 - val_loss: 0.3618 - val_accuracy: 0.8556 - 96ms/epoch - 4ms/step\n",
      "Epoch 123/250\n",
      "26/26 - 0s - loss: 0.4370 - accuracy: 0.8190 - val_loss: 0.3567 - val_accuracy: 0.8778 - 94ms/epoch - 4ms/step\n",
      "Epoch 124/250\n",
      "26/26 - 0s - loss: 0.4488 - accuracy: 0.8115 - val_loss: 0.3556 - val_accuracy: 0.8778 - 89ms/epoch - 3ms/step\n",
      "Epoch 125/250\n",
      "26/26 - 0s - loss: 0.4491 - accuracy: 0.8027 - val_loss: 0.3530 - val_accuracy: 0.8778 - 90ms/epoch - 3ms/step\n",
      "Epoch 126/250\n",
      "26/26 - 0s - loss: 0.4351 - accuracy: 0.8115 - val_loss: 0.3522 - val_accuracy: 0.8667 - 93ms/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "26/26 - 0s - loss: 0.4479 - accuracy: 0.8090 - val_loss: 0.3492 - val_accuracy: 0.8778 - 89ms/epoch - 3ms/step\n",
      "Epoch 128/250\n",
      "26/26 - 0s - loss: 0.4407 - accuracy: 0.8115 - val_loss: 0.3490 - val_accuracy: 0.8778 - 93ms/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "26/26 - 0s - loss: 0.4544 - accuracy: 0.8102 - val_loss: 0.3696 - val_accuracy: 0.8778 - 93ms/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "26/26 - 0s - loss: 0.4367 - accuracy: 0.8240 - val_loss: 0.3426 - val_accuracy: 0.8778 - 87ms/epoch - 3ms/step\n",
      "Epoch 131/250\n",
      "26/26 - 0s - loss: 0.4223 - accuracy: 0.8265 - val_loss: 0.3392 - val_accuracy: 0.8778 - 89ms/epoch - 3ms/step\n",
      "Epoch 132/250\n",
      "26/26 - 0s - loss: 0.4342 - accuracy: 0.8252 - val_loss: 0.3414 - val_accuracy: 0.8667 - 91ms/epoch - 3ms/step\n",
      "Epoch 133/250\n",
      "26/26 - 0s - loss: 0.4270 - accuracy: 0.8302 - val_loss: 0.3401 - val_accuracy: 0.8778 - 95ms/epoch - 4ms/step\n",
      "Epoch 134/250\n",
      "26/26 - 0s - loss: 0.4427 - accuracy: 0.8052 - val_loss: 0.3434 - val_accuracy: 0.8889 - 91ms/epoch - 3ms/step\n",
      "Epoch 135/250\n",
      "26/26 - 0s - loss: 0.4234 - accuracy: 0.8190 - val_loss: 0.3456 - val_accuracy: 0.8778 - 89ms/epoch - 3ms/step\n",
      "Epoch 136/250\n",
      "26/26 - 0s - loss: 0.4300 - accuracy: 0.8177 - val_loss: 0.3418 - val_accuracy: 0.8667 - 91ms/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "26/26 - 0s - loss: 0.4289 - accuracy: 0.8240 - val_loss: 0.3403 - val_accuracy: 0.8778 - 99ms/epoch - 4ms/step\n",
      "Epoch 138/250\n",
      "26/26 - 0s - loss: 0.4252 - accuracy: 0.8252 - val_loss: 0.3389 - val_accuracy: 0.8778 - 86ms/epoch - 3ms/step\n",
      "Epoch 139/250\n",
      "26/26 - 0s - loss: 0.4241 - accuracy: 0.8252 - val_loss: 0.3435 - val_accuracy: 0.8778 - 93ms/epoch - 4ms/step\n",
      "Epoch 140/250\n",
      "26/26 - 0s - loss: 0.4319 - accuracy: 0.8177 - val_loss: 0.3400 - val_accuracy: 0.8667 - 93ms/epoch - 4ms/step\n",
      "Epoch 141/250\n",
      "26/26 - 0s - loss: 0.4333 - accuracy: 0.8215 - val_loss: 0.3482 - val_accuracy: 0.8778 - 86ms/epoch - 3ms/step\n",
      "Epoch 142/250\n",
      "26/26 - 0s - loss: 0.4297 - accuracy: 0.8215 - val_loss: 0.3470 - val_accuracy: 0.8667 - 86ms/epoch - 3ms/step\n",
      "Epoch 143/250\n",
      "26/26 - 0s - loss: 0.4214 - accuracy: 0.8215 - val_loss: 0.3396 - val_accuracy: 0.8778 - 88ms/epoch - 3ms/step\n",
      "Epoch 144/250\n",
      "26/26 - 0s - loss: 0.4233 - accuracy: 0.8140 - val_loss: 0.3375 - val_accuracy: 0.8778 - 96ms/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "26/26 - 0s - loss: 0.4373 - accuracy: 0.8077 - val_loss: 0.3502 - val_accuracy: 0.8778 - 94ms/epoch - 4ms/step\n",
      "Epoch 146/250\n",
      "26/26 - 0s - loss: 0.4388 - accuracy: 0.7990 - val_loss: 0.3414 - val_accuracy: 0.8667 - 92ms/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "26/26 - 0s - loss: 0.4327 - accuracy: 0.8052 - val_loss: 0.3327 - val_accuracy: 0.8667 - 89ms/epoch - 3ms/step\n",
      "Epoch 148/250\n",
      "26/26 - 0s - loss: 0.4310 - accuracy: 0.8127 - val_loss: 0.3477 - val_accuracy: 0.8778 - 93ms/epoch - 4ms/step\n",
      "Epoch 149/250\n",
      "26/26 - 0s - loss: 0.4322 - accuracy: 0.8190 - val_loss: 0.3494 - val_accuracy: 0.8556 - 93ms/epoch - 4ms/step\n",
      "Epoch 150/250\n",
      "26/26 - 0s - loss: 0.4253 - accuracy: 0.8165 - val_loss: 0.3436 - val_accuracy: 0.8556 - 90ms/epoch - 3ms/step\n",
      "Epoch 151/250\n",
      "26/26 - 0s - loss: 0.4234 - accuracy: 0.8190 - val_loss: 0.3350 - val_accuracy: 0.8667 - 97ms/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "26/26 - 0s - loss: 0.4250 - accuracy: 0.8202 - val_loss: 0.3330 - val_accuracy: 0.8667 - 95ms/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "26/26 - 0s - loss: 0.4267 - accuracy: 0.8165 - val_loss: 0.3420 - val_accuracy: 0.8667 - 95ms/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "26/26 - 0s - loss: 0.4197 - accuracy: 0.8252 - val_loss: 0.3349 - val_accuracy: 0.8667 - 93ms/epoch - 4ms/step\n",
      "Epoch 155/250\n",
      "26/26 - 0s - loss: 0.4256 - accuracy: 0.8327 - val_loss: 0.3391 - val_accuracy: 0.8667 - 98ms/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "26/26 - 0s - loss: 0.4177 - accuracy: 0.8227 - val_loss: 0.3355 - val_accuracy: 0.8667 - 93ms/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "26/26 - 0s - loss: 0.4157 - accuracy: 0.8252 - val_loss: 0.3335 - val_accuracy: 0.8667 - 94ms/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "26/26 - 0s - loss: 0.4226 - accuracy: 0.8165 - val_loss: 0.3323 - val_accuracy: 0.8667 - 106ms/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "26/26 - 0s - loss: 0.4193 - accuracy: 0.8252 - val_loss: 0.3338 - val_accuracy: 0.8667 - 170ms/epoch - 7ms/step\n",
      "Epoch 160/250\n",
      "26/26 - 0s - loss: 0.4237 - accuracy: 0.8202 - val_loss: 0.3325 - val_accuracy: 0.8778 - 119ms/epoch - 5ms/step\n",
      "Epoch 161/250\n",
      "26/26 - 0s - loss: 0.4264 - accuracy: 0.8277 - val_loss: 0.3351 - val_accuracy: 0.8667 - 133ms/epoch - 5ms/step\n",
      "Epoch 162/250\n",
      "26/26 - 0s - loss: 0.4125 - accuracy: 0.8240 - val_loss: 0.3391 - val_accuracy: 0.8667 - 188ms/epoch - 7ms/step\n",
      "Epoch 163/250\n",
      "26/26 - 0s - loss: 0.4208 - accuracy: 0.8290 - val_loss: 0.3321 - val_accuracy: 0.8889 - 110ms/epoch - 4ms/step\n",
      "Epoch 164/250\n",
      "26/26 - 0s - loss: 0.4187 - accuracy: 0.8090 - val_loss: 0.3272 - val_accuracy: 0.8889 - 99ms/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "26/26 - 0s - loss: 0.4350 - accuracy: 0.8202 - val_loss: 0.3329 - val_accuracy: 0.8667 - 101ms/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "26/26 - 0s - loss: 0.4259 - accuracy: 0.8265 - val_loss: 0.3401 - val_accuracy: 0.8667 - 103ms/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "26/26 - 0s - loss: 0.4252 - accuracy: 0.8202 - val_loss: 0.3270 - val_accuracy: 0.8889 - 109ms/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "26/26 - 0s - loss: 0.4094 - accuracy: 0.8390 - val_loss: 0.3290 - val_accuracy: 0.8889 - 114ms/epoch - 4ms/step\n",
      "Epoch 169/250\n",
      "26/26 - 0s - loss: 0.4256 - accuracy: 0.8140 - val_loss: 0.3349 - val_accuracy: 0.8778 - 114ms/epoch - 4ms/step\n",
      "Epoch 170/250\n",
      "26/26 - 0s - loss: 0.4205 - accuracy: 0.8227 - val_loss: 0.3292 - val_accuracy: 0.8778 - 117ms/epoch - 5ms/step\n",
      "Epoch 171/250\n",
      "26/26 - 0s - loss: 0.4156 - accuracy: 0.8177 - val_loss: 0.3316 - val_accuracy: 0.8889 - 114ms/epoch - 4ms/step\n",
      "Epoch 172/250\n",
      "26/26 - 0s - loss: 0.3996 - accuracy: 0.8252 - val_loss: 0.3267 - val_accuracy: 0.8667 - 134ms/epoch - 5ms/step\n",
      "Epoch 173/250\n",
      "26/26 - 0s - loss: 0.4143 - accuracy: 0.8352 - val_loss: 0.3309 - val_accuracy: 0.8889 - 132ms/epoch - 5ms/step\n",
      "Epoch 174/250\n",
      "26/26 - 0s - loss: 0.4451 - accuracy: 0.8202 - val_loss: 0.3671 - val_accuracy: 0.8667 - 139ms/epoch - 5ms/step\n",
      "Epoch 175/250\n",
      "26/26 - 0s - loss: 0.4413 - accuracy: 0.8290 - val_loss: 0.3292 - val_accuracy: 0.8778 - 117ms/epoch - 4ms/step\n",
      "Epoch 176/250\n",
      "26/26 - 0s - loss: 0.4210 - accuracy: 0.8215 - val_loss: 0.3295 - val_accuracy: 0.8889 - 124ms/epoch - 5ms/step\n",
      "Epoch 177/250\n",
      "26/26 - 0s - loss: 0.4134 - accuracy: 0.8265 - val_loss: 0.3251 - val_accuracy: 0.8889 - 150ms/epoch - 6ms/step\n",
      "Epoch 178/250\n",
      "26/26 - 0s - loss: 0.4166 - accuracy: 0.8290 - val_loss: 0.3278 - val_accuracy: 0.8667 - 118ms/epoch - 5ms/step\n",
      "Epoch 179/250\n",
      "26/26 - 0s - loss: 0.4191 - accuracy: 0.8240 - val_loss: 0.3387 - val_accuracy: 0.8667 - 116ms/epoch - 4ms/step\n",
      "Epoch 180/250\n",
      "26/26 - 0s - loss: 0.4141 - accuracy: 0.8240 - val_loss: 0.3204 - val_accuracy: 0.8889 - 132ms/epoch - 5ms/step\n",
      "Epoch 181/250\n",
      "26/26 - 0s - loss: 0.4184 - accuracy: 0.8377 - val_loss: 0.3310 - val_accuracy: 0.8667 - 119ms/epoch - 5ms/step\n",
      "Epoch 182/250\n",
      "26/26 - 0s - loss: 0.4208 - accuracy: 0.8377 - val_loss: 0.3221 - val_accuracy: 0.8667 - 109ms/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "26/26 - 0s - loss: 0.3992 - accuracy: 0.8327 - val_loss: 0.3179 - val_accuracy: 0.8667 - 128ms/epoch - 5ms/step\n",
      "Epoch 184/250\n",
      "26/26 - 0s - loss: 0.4044 - accuracy: 0.8315 - val_loss: 0.3274 - val_accuracy: 0.8667 - 134ms/epoch - 5ms/step\n",
      "Epoch 185/250\n",
      "26/26 - 0s - loss: 0.4105 - accuracy: 0.8277 - val_loss: 0.3291 - val_accuracy: 0.8667 - 137ms/epoch - 5ms/step\n",
      "Epoch 186/250\n",
      "26/26 - 0s - loss: 0.4074 - accuracy: 0.8277 - val_loss: 0.3225 - val_accuracy: 0.8667 - 125ms/epoch - 5ms/step\n",
      "Epoch 187/250\n",
      "26/26 - 0s - loss: 0.4256 - accuracy: 0.8252 - val_loss: 0.3279 - val_accuracy: 0.8667 - 133ms/epoch - 5ms/step\n",
      "Epoch 188/250\n",
      "26/26 - 0s - loss: 0.4168 - accuracy: 0.8277 - val_loss: 0.3337 - val_accuracy: 0.8667 - 153ms/epoch - 6ms/step\n",
      "Epoch 189/250\n",
      "26/26 - 0s - loss: 0.4049 - accuracy: 0.8315 - val_loss: 0.3339 - val_accuracy: 0.8667 - 147ms/epoch - 6ms/step\n",
      "Epoch 190/250\n",
      "26/26 - 0s - loss: 0.4116 - accuracy: 0.8340 - val_loss: 0.3338 - val_accuracy: 0.8667 - 144ms/epoch - 6ms/step\n",
      "Epoch 191/250\n",
      "26/26 - 0s - loss: 0.3963 - accuracy: 0.8277 - val_loss: 0.3239 - val_accuracy: 0.8667 - 121ms/epoch - 5ms/step\n",
      "Epoch 192/250\n",
      "26/26 - 0s - loss: 0.4032 - accuracy: 0.8352 - val_loss: 0.3261 - val_accuracy: 0.8667 - 113ms/epoch - 4ms/step\n",
      "Epoch 193/250\n",
      "26/26 - 0s - loss: 0.4033 - accuracy: 0.8439 - val_loss: 0.3317 - val_accuracy: 0.8889 - 103ms/epoch - 4ms/step\n",
      "Epoch 194/250\n",
      "26/26 - 0s - loss: 0.4149 - accuracy: 0.8202 - val_loss: 0.3330 - val_accuracy: 0.8667 - 96ms/epoch - 4ms/step\n",
      "Epoch 195/250\n",
      "26/26 - 0s - loss: 0.4137 - accuracy: 0.8215 - val_loss: 0.3237 - val_accuracy: 0.8778 - 96ms/epoch - 4ms/step\n",
      "Epoch 196/250\n",
      "26/26 - 0s - loss: 0.4024 - accuracy: 0.8202 - val_loss: 0.3319 - val_accuracy: 0.8667 - 103ms/epoch - 4ms/step\n",
      "Epoch 197/250\n",
      "26/26 - 0s - loss: 0.4042 - accuracy: 0.8265 - val_loss: 0.3311 - val_accuracy: 0.8667 - 97ms/epoch - 4ms/step\n",
      "Epoch 198/250\n",
      "26/26 - 0s - loss: 0.4119 - accuracy: 0.8152 - val_loss: 0.3314 - val_accuracy: 0.8778 - 91ms/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "26/26 - 0s - loss: 0.4072 - accuracy: 0.8277 - val_loss: 0.3268 - val_accuracy: 0.8667 - 106ms/epoch - 4ms/step\n",
      "Epoch 200/250\n",
      "26/26 - 0s - loss: 0.4175 - accuracy: 0.8177 - val_loss: 0.3348 - val_accuracy: 0.8667 - 98ms/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "26/26 - 0s - loss: 0.4390 - accuracy: 0.8277 - val_loss: 0.3673 - val_accuracy: 0.8667 - 95ms/epoch - 4ms/step\n",
      "Epoch 202/250\n",
      "26/26 - 0s - loss: 0.4247 - accuracy: 0.8190 - val_loss: 0.3266 - val_accuracy: 0.8667 - 95ms/epoch - 4ms/step\n",
      "Epoch 203/250\n",
      "26/26 - 0s - loss: 0.4057 - accuracy: 0.8227 - val_loss: 0.3198 - val_accuracy: 0.8889 - 100ms/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "26/26 - 0s - loss: 0.4252 - accuracy: 0.8177 - val_loss: 0.3315 - val_accuracy: 0.8667 - 95ms/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "26/26 - 0s - loss: 0.4151 - accuracy: 0.8302 - val_loss: 0.3289 - val_accuracy: 0.8667 - 97ms/epoch - 4ms/step\n",
      "Epoch 206/250\n",
      "26/26 - 0s - loss: 0.4061 - accuracy: 0.8277 - val_loss: 0.3239 - val_accuracy: 0.8667 - 99ms/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "26/26 - 0s - loss: 0.4053 - accuracy: 0.8352 - val_loss: 0.3216 - val_accuracy: 0.8667 - 94ms/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "26/26 - 0s - loss: 0.4076 - accuracy: 0.8140 - val_loss: 0.3187 - val_accuracy: 0.8667 - 97ms/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "26/26 - 0s - loss: 0.4018 - accuracy: 0.8265 - val_loss: 0.3201 - val_accuracy: 0.8667 - 103ms/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "26/26 - 0s - loss: 0.4108 - accuracy: 0.8290 - val_loss: 0.3276 - val_accuracy: 0.8667 - 102ms/epoch - 4ms/step\n",
      "Epoch 211/250\n",
      "26/26 - 0s - loss: 0.4058 - accuracy: 0.8352 - val_loss: 0.3254 - val_accuracy: 0.8667 - 96ms/epoch - 4ms/step\n",
      "Epoch 212/250\n",
      "26/26 - 0s - loss: 0.4111 - accuracy: 0.8140 - val_loss: 0.3299 - val_accuracy: 0.8778 - 91ms/epoch - 4ms/step\n",
      "Epoch 213/250\n",
      "26/26 - 0s - loss: 0.3993 - accuracy: 0.8265 - val_loss: 0.3255 - val_accuracy: 0.8778 - 97ms/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "26/26 - 0s - loss: 0.4181 - accuracy: 0.8215 - val_loss: 0.3254 - val_accuracy: 0.8667 - 93ms/epoch - 4ms/step\n",
      "Epoch 215/250\n",
      "26/26 - 0s - loss: 0.3999 - accuracy: 0.8377 - val_loss: 0.3224 - val_accuracy: 0.8667 - 94ms/epoch - 4ms/step\n",
      "Epoch 216/250\n",
      "26/26 - 0s - loss: 0.4022 - accuracy: 0.8327 - val_loss: 0.3236 - val_accuracy: 0.8667 - 93ms/epoch - 4ms/step\n",
      "Epoch 217/250\n",
      "26/26 - 0s - loss: 0.4045 - accuracy: 0.8327 - val_loss: 0.3188 - val_accuracy: 0.8778 - 98ms/epoch - 4ms/step\n",
      "Epoch 218/250\n",
      "26/26 - 0s - loss: 0.4017 - accuracy: 0.8290 - val_loss: 0.3199 - val_accuracy: 0.8667 - 98ms/epoch - 4ms/step\n",
      "Epoch 219/250\n",
      "26/26 - 0s - loss: 0.3926 - accuracy: 0.8315 - val_loss: 0.3139 - val_accuracy: 0.8667 - 103ms/epoch - 4ms/step\n",
      "Epoch 220/250\n",
      "26/26 - 0s - loss: 0.4022 - accuracy: 0.8265 - val_loss: 0.3195 - val_accuracy: 0.8889 - 100ms/epoch - 4ms/step\n",
      "Epoch 221/250\n",
      "26/26 - 0s - loss: 0.4001 - accuracy: 0.8302 - val_loss: 0.3224 - val_accuracy: 0.8667 - 97ms/epoch - 4ms/step\n",
      "Epoch 222/250\n",
      "26/26 - 0s - loss: 0.3878 - accuracy: 0.8315 - val_loss: 0.3200 - val_accuracy: 0.8667 - 95ms/epoch - 4ms/step\n",
      "Epoch 223/250\n",
      "26/26 - 0s - loss: 0.3970 - accuracy: 0.8327 - val_loss: 0.3204 - val_accuracy: 0.8667 - 95ms/epoch - 4ms/step\n",
      "Epoch 224/250\n",
      "26/26 - 0s - loss: 0.4033 - accuracy: 0.8402 - val_loss: 0.3193 - val_accuracy: 0.8667 - 98ms/epoch - 4ms/step\n",
      "Epoch 225/250\n",
      "26/26 - 0s - loss: 0.3899 - accuracy: 0.8352 - val_loss: 0.3193 - val_accuracy: 0.8667 - 95ms/epoch - 4ms/step\n",
      "Epoch 226/250\n",
      "26/26 - 0s - loss: 0.4005 - accuracy: 0.8340 - val_loss: 0.3180 - val_accuracy: 0.8667 - 142ms/epoch - 5ms/step\n",
      "Epoch 227/250\n",
      "26/26 - 0s - loss: 0.3828 - accuracy: 0.8327 - val_loss: 0.3158 - val_accuracy: 0.8667 - 109ms/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "26/26 - 0s - loss: 0.3924 - accuracy: 0.8340 - val_loss: 0.3160 - val_accuracy: 0.8667 - 97ms/epoch - 4ms/step\n",
      "Epoch 229/250\n",
      "26/26 - 0s - loss: 0.3847 - accuracy: 0.8327 - val_loss: 0.3196 - val_accuracy: 0.8889 - 92ms/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "26/26 - 0s - loss: 0.3965 - accuracy: 0.8302 - val_loss: 0.3124 - val_accuracy: 0.8667 - 96ms/epoch - 4ms/step\n",
      "Epoch 231/250\n",
      "26/26 - 0s - loss: 0.3988 - accuracy: 0.8277 - val_loss: 0.3134 - val_accuracy: 0.8889 - 95ms/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "26/26 - 0s - loss: 0.4006 - accuracy: 0.8315 - val_loss: 0.3179 - val_accuracy: 0.8667 - 97ms/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "26/26 - 0s - loss: 0.3920 - accuracy: 0.8252 - val_loss: 0.3156 - val_accuracy: 0.8667 - 92ms/epoch - 4ms/step\n",
      "Epoch 234/250\n",
      "26/26 - 0s - loss: 0.3866 - accuracy: 0.8365 - val_loss: 0.3134 - val_accuracy: 0.8556 - 98ms/epoch - 4ms/step\n",
      "Epoch 235/250\n",
      "26/26 - 0s - loss: 0.4024 - accuracy: 0.8452 - val_loss: 0.3247 - val_accuracy: 0.8667 - 94ms/epoch - 4ms/step\n",
      "Epoch 236/250\n",
      "26/26 - 0s - loss: 0.4112 - accuracy: 0.8352 - val_loss: 0.3200 - val_accuracy: 0.8667 - 100ms/epoch - 4ms/step\n",
      "Epoch 237/250\n",
      "26/26 - 0s - loss: 0.3954 - accuracy: 0.8340 - val_loss: 0.3227 - val_accuracy: 0.8889 - 96ms/epoch - 4ms/step\n",
      "Epoch 238/250\n",
      "26/26 - 0s - loss: 0.3979 - accuracy: 0.8352 - val_loss: 0.3113 - val_accuracy: 0.8889 - 100ms/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "26/26 - 0s - loss: 0.3998 - accuracy: 0.8302 - val_loss: 0.3180 - val_accuracy: 0.8667 - 94ms/epoch - 4ms/step\n",
      "Epoch 240/250\n",
      "26/26 - 0s - loss: 0.3868 - accuracy: 0.8390 - val_loss: 0.3127 - val_accuracy: 0.8667 - 96ms/epoch - 4ms/step\n",
      "Epoch 241/250\n",
      "26/26 - 0s - loss: 0.3877 - accuracy: 0.8302 - val_loss: 0.3138 - val_accuracy: 0.8778 - 97ms/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "26/26 - 0s - loss: 0.3944 - accuracy: 0.8365 - val_loss: 0.3131 - val_accuracy: 0.8667 - 96ms/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "26/26 - 0s - loss: 0.3996 - accuracy: 0.8352 - val_loss: 0.3186 - val_accuracy: 0.8778 - 94ms/epoch - 4ms/step\n",
      "Epoch 244/250\n",
      "26/26 - 0s - loss: 0.4005 - accuracy: 0.8227 - val_loss: 0.3161 - val_accuracy: 0.8667 - 97ms/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "26/26 - 0s - loss: 0.3881 - accuracy: 0.8340 - val_loss: 0.3215 - val_accuracy: 0.8667 - 97ms/epoch - 4ms/step\n",
      "Epoch 246/250\n",
      "26/26 - 0s - loss: 0.3968 - accuracy: 0.8202 - val_loss: 0.3178 - val_accuracy: 0.8778 - 94ms/epoch - 4ms/step\n",
      "Epoch 247/250\n",
      "26/26 - 0s - loss: 0.3969 - accuracy: 0.8277 - val_loss: 0.3145 - val_accuracy: 0.8778 - 95ms/epoch - 4ms/step\n",
      "Epoch 248/250\n",
      "26/26 - 0s - loss: 0.3834 - accuracy: 0.8352 - val_loss: 0.3155 - val_accuracy: 0.8778 - 96ms/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "26/26 - 0s - loss: 0.3890 - accuracy: 0.8315 - val_loss: 0.3274 - val_accuracy: 0.8667 - 94ms/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "26/26 - 0s - loss: 0.3942 - accuracy: 0.8227 - val_loss: 0.3151 - val_accuracy: 0.8667 - 96ms/epoch - 4ms/step\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3650702238082886, 0.8529741764068604]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stopping],\n",
    "    epochs=250,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "model.evaluate(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot( history.history['accuracy'] )\n",
    "plt.plot( history.history['loss'] )\n",
    "plt.plot( history.history['val_loss'] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions on training dataset :-\n",
      "760 correct predictions out of 891\n",
      "accuracy = 85.29 %\n"
     ]
    }
   ],
   "source": [
    "# predicting on the testing data\n",
    "\n",
    "predictions = model.predict(train_x)\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(predictions)):\n",
    "    # print(f\"{train_y[i]} predicted --> { (predictions[i][0]*100)//1 } %\")\n",
    "\n",
    "    if predictions[i] > 0.500 and train_y[i] == 1:\n",
    "            correct = correct + 1\n",
    "\n",
    "    if predictions[i] < 0.500 and train_y[i] == 0:\n",
    "            correct = correct + 1\n",
    "\n",
    "print(\"predictions on training dataset :-\")\n",
    "print(f\"{correct} correct predictions out of {len(predictions)}\")\n",
    "print(f\"accuracy = { str((correct / len(predictions)) * 100)[:5] } %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "categorising array --> raw_sex\n",
      "unique values --> {'male': 1, 'female': 2}\n",
      "male --> [1. 0.]\n",
      "female --> [0. 1.]\n",
      "male --> [1. 0.]\n",
      "male --> [1. 0.]\n",
      "female --> [0. 1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_sex = list(test_df['Sex'])         # categorical\n",
    "\n",
    "cat_sex = categorical(raw_sex, sex_tokenizer, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values --> 0 out of 418\n",
      "most common value --> S\n",
      "replaced all 'nan' values with 'S'\n",
      "\n",
      "categorising array --> raw_region\n",
      "unique values --> {'S': 1, 'C': 2, 'Q': 3}\n",
      "Q --> [0. 0. 1.]\n",
      "S --> [1. 0. 0.]\n",
      "Q --> [0. 0. 1.]\n",
      "S --> [1. 0. 0.]\n",
      "S --> [1. 0. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_region = list(test_df['Embarked'])     # categorical + missing values\n",
    "raw_region = most_common_imputer(raw_region, debug=True)\n",
    "\n",
    "cat_region = categorical(raw_region, region_tokenizer, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passenger class --> [1, 2, 3] \n",
      "siblings --> [0, 1, 2, 3, 4, 5, 8] \n",
      "parents & children --> [0, 1, 2, 3, 4, 5, 6, 9] \n",
      "sex --> ['male', 'female'] \n",
      "region --> ['S', 'C', 'Q'] \n"
     ]
    }
   ],
   "source": [
    "# dropped 'Name', 'Ticket'\n",
    "# 'Cabin' --> Cabin present or not? \n",
    "\n",
    "p_class = list(test_df['Pclass'])\n",
    "\n",
    "siblings = list(test_df['SibSp'])\n",
    "parents = list(test_df['Parch'])\n",
    "\n",
    "fare = list(test_df['Fare'])\n",
    "\n",
    "print(f\"passenger class --> {list(set(p_class))} \")\n",
    "print(f\"siblings --> {list(set(siblings))} \")\n",
    "print(f\"parents & children --> {list(set(parents))} \")\n",
    "print(f\"sex --> {list(set(raw_sex))} \")\n",
    "print(f\"region --> {list(set(raw_region))} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan --> 0\n",
      "nan --> 0\n",
      "nan --> 0\n",
      "nan --> 0\n",
      "nan --> 0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "cabin_present = list(test_df['Cabin'])\n",
    "cat_cabin = binary_categorical(cabin_present, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --> Mrs. --> count = 72\n",
      "1 --> Miss. --> count = 78\n",
      "2 --> Rev. --> count = 2\n",
      "3 --> Mr. --> count = 244\n",
      "4 --> Master. --> count = 21\n",
      "5 --> Dr. --> count = 1\n",
      "['Mr.', 'Mrs.', 'Mr.', 'Mr.', 'Mrs.', 'Mr.', 'Miss.', 'Mr.', 'Mrs.', 'Mr.']\n"
     ]
    }
   ],
   "source": [
    "raw_names = list(test_df['Name'])\n",
    "\n",
    "proc_names = []\n",
    "positions = ['Mrs.', 'Miss.', 'Rev.', 'Mr.', 'Master.', 'Dr.']\n",
    "\n",
    "for i in range( len(raw_names) ):\n",
    "    name_array = raw_names[i].split(' ')\n",
    "    # print(i, name_array, sep=\" --> \")\n",
    "\n",
    "    token_found = 0\n",
    "    for token in name_array:\n",
    "        if token in positions:\n",
    "            token_found = 1\n",
    "            # print(f\"{token} --> {positions.index(token)}\\n\")\n",
    "            # proc_names.append( positions.index(token) )\n",
    "            proc_names.append( token )\n",
    "    if token_found == 0:\n",
    "        proc_names.append( 'Mr.' )\n",
    "\n",
    "for i in range(len(positions)):\n",
    "    print(f\"{i} --> {positions[i]} --> count = {proc_names.count(positions[i])}\")\n",
    "\n",
    "print(proc_names[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "categorising array --> proc_names\n",
      "unique values --> {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Dr': 5, 'Rev': 6}\n",
      "Mr. --> [1. 0. 0. 0. 0. 0.]\n",
      "Mrs. --> [0. 0. 1. 0. 0. 0.]\n",
      "Mr. --> [1. 0. 0. 0. 0. 0.]\n",
      "Mr. --> [1. 0. 0. 0. 0. 0.]\n",
      "Mrs. --> [0. 0. 1. 0. 0. 0.]\n",
      "\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "cat_names = categorical(proc_names, name_tokenizer, debug=True)\n",
    "\n",
    "print(cat_names[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 22.0, 0, 0, 7.8292, 0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[3, 38.0, 1, 0, 7.0, 0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[2, 26.0, 0, 0, 9.6875, 0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[3, 35.0, 0, 0, 8.6625, 0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[3, 35.0, 1, 1, 12.2875, 0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[3, 23.0, 0, 0, 9.225, 0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "test_x = []\n",
    "\n",
    "for i in range(len(raw_sex)):\n",
    "    temp = [\n",
    "        p_class[i], imputed_age[i],\n",
    "        siblings[i], parents[i], \n",
    "        fare[i], cat_cabin[i]\n",
    "    ]\n",
    "    temp.extend(cat_sex[i])\n",
    "    temp.extend(cat_region[i])\n",
    "    temp.extend(cat_names[i])\n",
    "    test_x.append(temp)\n",
    "    if i < 6: print(temp)\n",
    "    \n",
    "test_x = np.array(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 17)\n",
      "input shape for test_x = 17\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(\"input shape for test_x =\", train_x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_x)\n",
    "\n",
    "csv_pred = []\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i][0] > 0.500: \n",
    "        csv_pred.append(1)\n",
    "    else:\n",
    "        csv_pred.append(0)\n",
    "\n",
    "print(csv_pred[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_id = list(test_df['PassengerId'])\n",
    "\n",
    "submit_dict = {\n",
    "    'PassengerId': passenger_id,\n",
    "    'Survived': csv_pred\n",
    "}\n",
    "\n",
    "submit_df = pd.DataFrame(submit_dict)\n",
    "submit_df.head()\n",
    "\n",
    "submit_df.to_csv('submit.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf6ab032c8d0f1ddf2ea4dd4e609e6e6dfd5e53c8a42a3a69958aaabf5715049"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
