{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 total entries\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "print(f\"{len(train_df)} total entries\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_imputer(raw_array, debug=False):\n",
    "\n",
    "    def namestr(obj, namespace):\n",
    "        return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "    null_count = 0\n",
    "    sum = 0\n",
    "    mean = 0\n",
    "    imputed_array = []\n",
    "\n",
    "    for item in raw_array:\n",
    "        if str(item) == 'nan':\n",
    "            # print(item, end=', ')\n",
    "            null_count = null_count + 1\n",
    "        else: sum = sum + item\n",
    "    \n",
    "    mean = ( sum / len(raw_array) ) // 1\n",
    "\n",
    "    if debug == True:\n",
    "        print(f\"\\nimputing array --> {namestr(raw_array, globals())[0]}\")\n",
    "        print(f\"{null_count} null values\")\n",
    "        print(f\"{len(raw_array) - null_count} numeric values\")\n",
    "        print(f\"{len(raw_array)} total values\")\n",
    "        print(f\"mean = { mean }\")\n",
    "        print(f\"replaced all missing values with mean {mean}\\n\")\n",
    "\n",
    "    for item in raw_array:\n",
    "        if str(item) == 'nan':\n",
    "            item = mean\n",
    "        imputed_array.append(item)\n",
    "        # print(item, end=', ')\n",
    "\n",
    "    return imputed_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "imputing array --> raw_age\n",
      "177 null values\n",
      "714 numeric values\n",
      "891 total values\n",
      "mean = 23.0\n",
      "replaced all missing values with mean 23.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_age = list(train_df['Age'])         # missing values\n",
    "imputed_age = mean_imputer(raw_age, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def categorical(raw_array, tokenizer, debug=False):\n",
    "\n",
    "    def namestr(obj, namespace):\n",
    "        return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "\n",
    "    seq_array = tokenizer.texts_to_sequences(raw_array)\n",
    "\n",
    "    cat_array = tf.keras.utils.to_categorical(seq_array)\n",
    "    cat_array = cat_array[:, 1:]   # cause the [0] value doesnt have anything in the word index\n",
    "\n",
    "\n",
    "    if debug == True:\n",
    "        print(f\"\\ncategorising array --> {namestr(raw_array, globals())[0]}\")\n",
    "        print(f\"unique values --> {tokenizer.word_index}\")\n",
    "        for i in range(5):\n",
    "            print(f\"{raw_array[i]} --> { cat_array[i] }\")\n",
    "        print()\n",
    "        \n",
    "    return cat_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "categorising array --> raw_sex\n",
      "unique values --> {'male': 1, 'female': 2}\n",
      "male --> [1. 0.]\n",
      "female --> [0. 1.]\n",
      "female --> [0. 1.]\n",
      "female --> [0. 1.]\n",
      "male --> [1. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_sex = list(train_df['Sex'])         # categorical\n",
    "\n",
    "sex_tokenizer = tf.keras.preprocessing.text.Tokenizer( lower=False )\n",
    "sex_tokenizer.fit_on_texts(raw_sex)\n",
    "\n",
    "cat_sex = categorical(raw_sex, sex_tokenizer, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_imputer(array, debug=False):\n",
    "\n",
    "    most_common = max(array, key = array.count)\n",
    "    missing_values = 0\n",
    "\n",
    "    for i in range(len(array)):\n",
    "        if str( array[i] ) == 'nan':\n",
    "            missing_values = missing_values + 1\n",
    "            array[i] = most_common\n",
    "\n",
    "    if debug == True:\n",
    "        print(f\"missing values --> {missing_values} out of {len(array)}\")\n",
    "        print(f\"most common value --> {most_common}\")\n",
    "        print(f\"replaced all 'nan' values with '{most_common}'\")\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values --> 2 out of 891\n",
      "most common value --> S\n",
      "replaced all 'nan' values with 'S'\n",
      "\n",
      "categorising array --> raw_region\n",
      "unique values --> {'S': 1, 'C': 2, 'Q': 3}\n",
      "S --> [1. 0. 0.]\n",
      "C --> [0. 1. 0.]\n",
      "S --> [1. 0. 0.]\n",
      "S --> [1. 0. 0.]\n",
      "S --> [1. 0. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_region = list(train_df['Embarked'])     # categorical + missing values\n",
    "raw_region = most_common_imputer(raw_region, debug=True)\n",
    "\n",
    "region_tokenizer = tf.keras.preprocessing.text.Tokenizer( lower=False )\n",
    "region_tokenizer.fit_on_texts(raw_region)\n",
    "\n",
    "cat_region = categorical(raw_region, region_tokenizer, debug=True)\n",
    "\n",
    "# for i in range(8):\n",
    "#     print(f\"{raw_region[i]} --> {cat_region[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived --> [0, 1] \n",
      "passenger class --> [1, 2, 3] \n",
      "siblings --> [0, 1, 2, 3, 4, 5, 8] \n",
      "parents & children --> [0, 1, 2, 3, 4, 5, 6] \n",
      "sex --> ['female', 'male'] \n",
      "region --> ['S', 'Q', 'C'] \n"
     ]
    }
   ],
   "source": [
    "# dropped 'Name', 'Ticket'\n",
    "# 'Cabin' --> Cabin present or not? \n",
    "\n",
    "survived = list(train_df['Survived'])\n",
    "\n",
    "p_class = list(train_df['Pclass'])\n",
    "\n",
    "siblings = list(train_df['SibSp'])\n",
    "parents = list(train_df['Parch'])\n",
    "\n",
    "fare = list(train_df['Fare'])\n",
    "\n",
    "print(f\"survived --> {list(set(survived))} \")\n",
    "print(f\"passenger class --> {list(set(p_class))} \")\n",
    "print(f\"siblings --> {list(set(siblings))} \")\n",
    "print(f\"parents & children --> {list(set(parents))} \")\n",
    "print(f\"sex --> {list(set(raw_sex))} \")\n",
    "print(f\"region --> {list(set(raw_region))} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_categorical(array, debug=False):\n",
    "\n",
    "    cat_array = []\n",
    "\n",
    "    for i in range(len(array)):\n",
    "        if str(array[i]) == 'nan':\n",
    "            cat_array.append(0)\n",
    "        else:\n",
    "            cat_array.append(1)\n",
    "\n",
    "    if debug == True:\n",
    "        for i in range(5):\n",
    "            print(f\"{array[i]} --> {cat_array[i]}\")\n",
    "        print(cat_array[:10])\n",
    "\n",
    "    return cat_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan --> 0\n",
      "C85 --> 1\n",
      "nan --> 0\n",
      "C123 --> 1\n",
      "nan --> 0\n",
      "[0, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "cabin_present = list(train_df['Cabin'])\n",
    "cat_cabin = binary_categorical(cabin_present, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --> Mrs. --> count = 125\n",
      "1 --> Miss. --> count = 182\n",
      "2 --> Rev. --> count = 6\n",
      "3 --> Mr. --> count = 531\n",
      "4 --> Master. --> count = 40\n",
      "5 --> Dr. --> count = 7\n",
      "['Mr.', 'Mrs.', 'Miss.', 'Mrs.', 'Mr.', 'Mr.', 'Mr.', 'Master.', 'Mrs.', 'Mrs.']\n"
     ]
    }
   ],
   "source": [
    "raw_names = list(train_df['Name'])\n",
    "\n",
    "proc_names = []\n",
    "positions = ['Mrs.', 'Miss.', 'Rev.', 'Mr.', 'Master.', 'Dr.']\n",
    "\n",
    "for i in range( len(raw_names) ):\n",
    "    name_array = raw_names[i].split(' ')\n",
    "    # print(i, name_array, sep=\" --> \")\n",
    "\n",
    "    token_found = 0\n",
    "    for token in name_array:\n",
    "        if token in positions:\n",
    "            token_found = 1\n",
    "            # print(f\"{token} --> {positions.index(token)}\\n\")\n",
    "            # proc_names.append( positions.index(token) )\n",
    "            proc_names.append( token )\n",
    "    if token_found == 0:\n",
    "        proc_names.append( 'Mr.' )\n",
    "\n",
    "for i in range(len(positions)):\n",
    "    print(f\"{i} --> {positions[i]} --> count = {proc_names.count(positions[i])}\")\n",
    "\n",
    "print(proc_names[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "categorising array --> proc_names\n",
      "unique values --> {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Dr': 5, 'Rev': 6}\n",
      "Mr. --> [1. 0. 0. 0. 0. 0.]\n",
      "Mrs. --> [0. 0. 1. 0. 0. 0.]\n",
      "Miss. --> [0. 1. 0. 0. 0. 0.]\n",
      "Mrs. --> [0. 0. 1. 0. 0. 0.]\n",
      "Mr. --> [1. 0. 0. 0. 0. 0.]\n",
      "\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "name_tokenizer = tf.keras.preprocessing.text.Tokenizer( lower=False )\n",
    "name_tokenizer.fit_on_texts(proc_names)\n",
    "\n",
    "cat_names = categorical(proc_names, name_tokenizer, debug=True)\n",
    "\n",
    "print(cat_names[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 22.0, 1, 0, 7.25, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[1, 38.0, 1, 0, 71.2833, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[3, 26.0, 0, 0, 7.925, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[1, 35.0, 1, 0, 53.1, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[3, 35.0, 0, 0, 8.05, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[3, 23.0, 0, 0, 8.4583, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "train_x = []\n",
    "\n",
    "for i in range(len(raw_sex)):\n",
    "    temp = [\n",
    "        p_class[i], imputed_age[i],\n",
    "        siblings[i], parents[i], \n",
    "        fare[i]\n",
    "        # cat_cabin[i]\n",
    "    ]\n",
    "    temp.extend(cat_sex[i])\n",
    "    temp.extend(cat_region[i])\n",
    "    temp.extend(cat_names[i])\n",
    "    train_x.append(temp)\n",
    "    if i < 6: print(temp)  # printing a sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 16)\n",
      "input shape for model = 16\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "survived = list(train_df['Survived'])\n",
    "\n",
    "train_y = np.array(survived)\n",
    "train_x = np.array(train_x)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(\"input shape for model =\", train_x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "visible = layers.Input( shape=[ train_x.shape[1] ] )\n",
    "x = layers.Dense(64, activation='relu')(visible)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001,\n",
    "    patience=15,\n",
    "    restore_best_weights=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "27/27 - 1s - loss: 2.4207 - accuracy: 0.4815 - val_loss: 0.6696 - val_accuracy: 0.6852 - 1s/epoch - 54ms/step\n",
      "Epoch 2/250\n",
      "27/27 - 0s - loss: 1.4040 - accuracy: 0.5771 - val_loss: 0.6207 - val_accuracy: 0.6667 - 151ms/epoch - 6ms/step\n",
      "Epoch 3/250\n",
      "27/27 - 0s - loss: 1.1764 - accuracy: 0.6320 - val_loss: 0.5984 - val_accuracy: 0.6667 - 139ms/epoch - 5ms/step\n",
      "Epoch 4/250\n",
      "27/27 - 0s - loss: 1.0569 - accuracy: 0.6213 - val_loss: 0.5961 - val_accuracy: 0.6667 - 127ms/epoch - 5ms/step\n",
      "Epoch 5/250\n",
      "27/27 - 0s - loss: 0.8453 - accuracy: 0.6476 - val_loss: 0.5889 - val_accuracy: 0.6667 - 146ms/epoch - 5ms/step\n",
      "Epoch 6/250\n",
      "27/27 - 0s - loss: 0.9063 - accuracy: 0.6237 - val_loss: 0.5906 - val_accuracy: 0.6296 - 114ms/epoch - 4ms/step\n",
      "Epoch 7/250\n",
      "27/27 - 0s - loss: 0.8307 - accuracy: 0.6284 - val_loss: 0.6074 - val_accuracy: 0.6481 - 119ms/epoch - 4ms/step\n",
      "Epoch 8/250\n",
      "27/27 - 0s - loss: 0.7595 - accuracy: 0.6583 - val_loss: 0.6173 - val_accuracy: 0.6667 - 131ms/epoch - 5ms/step\n",
      "Epoch 9/250\n",
      "27/27 - 0s - loss: 0.7449 - accuracy: 0.6679 - val_loss: 0.6144 - val_accuracy: 0.6667 - 145ms/epoch - 5ms/step\n",
      "Epoch 10/250\n",
      "27/27 - 0s - loss: 0.7059 - accuracy: 0.6547 - val_loss: 0.6009 - val_accuracy: 0.6852 - 137ms/epoch - 5ms/step\n",
      "Epoch 11/250\n",
      "27/27 - 0s - loss: 0.6884 - accuracy: 0.6726 - val_loss: 0.6041 - val_accuracy: 0.6852 - 119ms/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "27/27 - 0s - loss: 0.6836 - accuracy: 0.6583 - val_loss: 0.5981 - val_accuracy: 0.6852 - 144ms/epoch - 5ms/step\n",
      "Epoch 13/250\n",
      "27/27 - 0s - loss: 0.6967 - accuracy: 0.6798 - val_loss: 0.5951 - val_accuracy: 0.6852 - 130ms/epoch - 5ms/step\n",
      "Epoch 14/250\n",
      "27/27 - 0s - loss: 0.6685 - accuracy: 0.6583 - val_loss: 0.6074 - val_accuracy: 0.6852 - 107ms/epoch - 4ms/step\n",
      "Epoch 15/250\n",
      "27/27 - 0s - loss: 0.6418 - accuracy: 0.6762 - val_loss: 0.6069 - val_accuracy: 0.6852 - 123ms/epoch - 5ms/step\n",
      "Epoch 16/250\n",
      "27/27 - 0s - loss: 0.6407 - accuracy: 0.6798 - val_loss: 0.5929 - val_accuracy: 0.6852 - 132ms/epoch - 5ms/step\n",
      "Epoch 17/250\n",
      "27/27 - 0s - loss: 0.6780 - accuracy: 0.6487 - val_loss: 0.5754 - val_accuracy: 0.6667 - 148ms/epoch - 5ms/step\n",
      "Epoch 18/250\n",
      "27/27 - 0s - loss: 0.6687 - accuracy: 0.6691 - val_loss: 0.6012 - val_accuracy: 0.6667 - 116ms/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "27/27 - 0s - loss: 0.6174 - accuracy: 0.6631 - val_loss: 0.5944 - val_accuracy: 0.6667 - 108ms/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "27/27 - 0s - loss: 0.6012 - accuracy: 0.6810 - val_loss: 0.5785 - val_accuracy: 0.6667 - 100ms/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "27/27 - 0s - loss: 0.6145 - accuracy: 0.6750 - val_loss: 0.5950 - val_accuracy: 0.6481 - 92ms/epoch - 3ms/step\n",
      "Epoch 22/250\n",
      "27/27 - 0s - loss: 0.6347 - accuracy: 0.6774 - val_loss: 0.5793 - val_accuracy: 0.6111 - 101ms/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "27/27 - 0s - loss: 0.6032 - accuracy: 0.6810 - val_loss: 0.5622 - val_accuracy: 0.6481 - 89ms/epoch - 3ms/step\n",
      "Epoch 24/250\n",
      "27/27 - 0s - loss: 0.6249 - accuracy: 0.6738 - val_loss: 0.5584 - val_accuracy: 0.6111 - 90ms/epoch - 3ms/step\n",
      "Epoch 25/250\n",
      "27/27 - 0s - loss: 0.6128 - accuracy: 0.6714 - val_loss: 0.5535 - val_accuracy: 0.6296 - 101ms/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "27/27 - 0s - loss: 0.6068 - accuracy: 0.6762 - val_loss: 0.5648 - val_accuracy: 0.6667 - 101ms/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "27/27 - 0s - loss: 0.6128 - accuracy: 0.6535 - val_loss: 0.5464 - val_accuracy: 0.6296 - 99ms/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "27/27 - 0s - loss: 0.5770 - accuracy: 0.6941 - val_loss: 0.5272 - val_accuracy: 0.6481 - 99ms/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "27/27 - 0s - loss: 0.5743 - accuracy: 0.7001 - val_loss: 0.5072 - val_accuracy: 0.7593 - 95ms/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "27/27 - 0s - loss: 0.5814 - accuracy: 0.7121 - val_loss: 0.5017 - val_accuracy: 0.8148 - 94ms/epoch - 3ms/step\n",
      "Epoch 31/250\n",
      "27/27 - 0s - loss: 0.5825 - accuracy: 0.6941 - val_loss: 0.4995 - val_accuracy: 0.8519 - 92ms/epoch - 3ms/step\n",
      "Epoch 32/250\n",
      "27/27 - 0s - loss: 0.5713 - accuracy: 0.7001 - val_loss: 0.5005 - val_accuracy: 0.7778 - 95ms/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "27/27 - 0s - loss: 0.5561 - accuracy: 0.7121 - val_loss: 0.4882 - val_accuracy: 0.8148 - 97ms/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "27/27 - 0s - loss: 0.5747 - accuracy: 0.7360 - val_loss: 0.4738 - val_accuracy: 0.8148 - 100ms/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "27/27 - 0s - loss: 0.5823 - accuracy: 0.7157 - val_loss: 0.4660 - val_accuracy: 0.8333 - 93ms/epoch - 3ms/step\n",
      "Epoch 36/250\n",
      "27/27 - 0s - loss: 0.5611 - accuracy: 0.7121 - val_loss: 0.4563 - val_accuracy: 0.7963 - 97ms/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "27/27 - 0s - loss: 0.5631 - accuracy: 0.7085 - val_loss: 0.4742 - val_accuracy: 0.7963 - 91ms/epoch - 3ms/step\n",
      "Epoch 38/250\n",
      "27/27 - 0s - loss: 0.5628 - accuracy: 0.7157 - val_loss: 0.4749 - val_accuracy: 0.8148 - 91ms/epoch - 3ms/step\n",
      "Epoch 39/250\n",
      "27/27 - 0s - loss: 0.5769 - accuracy: 0.7180 - val_loss: 0.4762 - val_accuracy: 0.8148 - 91ms/epoch - 3ms/step\n",
      "Epoch 40/250\n",
      "27/27 - 0s - loss: 0.5597 - accuracy: 0.7264 - val_loss: 0.4712 - val_accuracy: 0.8148 - 90ms/epoch - 3ms/step\n",
      "Epoch 41/250\n",
      "27/27 - 0s - loss: 0.5724 - accuracy: 0.7240 - val_loss: 0.4521 - val_accuracy: 0.8148 - 97ms/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "27/27 - 0s - loss: 0.5653 - accuracy: 0.7216 - val_loss: 0.4692 - val_accuracy: 0.8148 - 92ms/epoch - 3ms/step\n",
      "Epoch 43/250\n",
      "27/27 - 0s - loss: 0.5417 - accuracy: 0.7228 - val_loss: 0.4636 - val_accuracy: 0.8148 - 91ms/epoch - 3ms/step\n",
      "Epoch 44/250\n",
      "27/27 - 0s - loss: 0.5395 - accuracy: 0.7395 - val_loss: 0.4484 - val_accuracy: 0.8148 - 91ms/epoch - 3ms/step\n",
      "Epoch 45/250\n",
      "27/27 - 0s - loss: 0.5553 - accuracy: 0.7312 - val_loss: 0.4453 - val_accuracy: 0.8148 - 90ms/epoch - 3ms/step\n",
      "Epoch 46/250\n",
      "27/27 - 0s - loss: 0.5397 - accuracy: 0.7419 - val_loss: 0.4396 - val_accuracy: 0.8148 - 90ms/epoch - 3ms/step\n",
      "Epoch 47/250\n",
      "27/27 - 0s - loss: 0.5378 - accuracy: 0.7503 - val_loss: 0.4406 - val_accuracy: 0.8148 - 95ms/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "27/27 - 0s - loss: 0.5409 - accuracy: 0.7348 - val_loss: 0.4345 - val_accuracy: 0.8148 - 91ms/epoch - 3ms/step\n",
      "Epoch 49/250\n",
      "27/27 - 0s - loss: 0.5268 - accuracy: 0.7563 - val_loss: 0.4131 - val_accuracy: 0.8148 - 91ms/epoch - 3ms/step\n",
      "Epoch 50/250\n",
      "27/27 - 0s - loss: 0.5302 - accuracy: 0.7431 - val_loss: 0.4141 - val_accuracy: 0.8148 - 94ms/epoch - 3ms/step\n",
      "Epoch 51/250\n",
      "27/27 - 0s - loss: 0.5357 - accuracy: 0.7646 - val_loss: 0.4188 - val_accuracy: 0.8148 - 91ms/epoch - 3ms/step\n",
      "Epoch 52/250\n",
      "27/27 - 0s - loss: 0.5227 - accuracy: 0.7563 - val_loss: 0.4317 - val_accuracy: 0.8148 - 90ms/epoch - 3ms/step\n",
      "Epoch 53/250\n",
      "27/27 - 0s - loss: 0.5145 - accuracy: 0.7754 - val_loss: 0.4190 - val_accuracy: 0.8148 - 91ms/epoch - 3ms/step\n",
      "Epoch 54/250\n",
      "27/27 - 0s - loss: 0.5116 - accuracy: 0.7646 - val_loss: 0.4300 - val_accuracy: 0.8148 - 93ms/epoch - 3ms/step\n",
      "Epoch 55/250\n",
      "27/27 - 0s - loss: 0.5249 - accuracy: 0.7622 - val_loss: 0.4059 - val_accuracy: 0.8148 - 89ms/epoch - 3ms/step\n",
      "Epoch 56/250\n",
      "27/27 - 0s - loss: 0.5130 - accuracy: 0.7563 - val_loss: 0.4057 - val_accuracy: 0.8148 - 90ms/epoch - 3ms/step\n",
      "Epoch 57/250\n",
      "27/27 - 0s - loss: 0.5127 - accuracy: 0.7587 - val_loss: 0.4032 - val_accuracy: 0.8148 - 95ms/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "27/27 - 0s - loss: 0.5067 - accuracy: 0.7694 - val_loss: 0.3877 - val_accuracy: 0.8148 - 89ms/epoch - 3ms/step\n",
      "Epoch 59/250\n",
      "27/27 - 0s - loss: 0.5135 - accuracy: 0.7694 - val_loss: 0.3886 - val_accuracy: 0.8148 - 90ms/epoch - 3ms/step\n",
      "Epoch 60/250\n",
      "27/27 - 0s - loss: 0.5166 - accuracy: 0.7670 - val_loss: 0.4054 - val_accuracy: 0.8148 - 93ms/epoch - 3ms/step\n",
      "Epoch 61/250\n",
      "27/27 - 0s - loss: 0.4924 - accuracy: 0.7802 - val_loss: 0.3800 - val_accuracy: 0.8148 - 89ms/epoch - 3ms/step\n",
      "Epoch 62/250\n",
      "27/27 - 0s - loss: 0.4993 - accuracy: 0.7718 - val_loss: 0.3808 - val_accuracy: 0.8148 - 89ms/epoch - 3ms/step\n",
      "Epoch 63/250\n",
      "27/27 - 0s - loss: 0.5132 - accuracy: 0.7670 - val_loss: 0.3939 - val_accuracy: 0.8148 - 95ms/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "27/27 - 0s - loss: 0.5195 - accuracy: 0.7682 - val_loss: 0.3966 - val_accuracy: 0.8148 - 90ms/epoch - 3ms/step\n",
      "Epoch 65/250\n",
      "27/27 - 0s - loss: 0.5214 - accuracy: 0.7515 - val_loss: 0.4189 - val_accuracy: 0.8148 - 90ms/epoch - 3ms/step\n",
      "Epoch 66/250\n",
      "27/27 - 0s - loss: 0.4863 - accuracy: 0.7826 - val_loss: 0.4126 - val_accuracy: 0.8148 - 90ms/epoch - 3ms/step\n",
      "Epoch 67/250\n",
      "27/27 - 0s - loss: 0.4766 - accuracy: 0.7838 - val_loss: 0.3807 - val_accuracy: 0.8148 - 91ms/epoch - 3ms/step\n",
      "Epoch 68/250\n",
      "27/27 - 0s - loss: 0.4997 - accuracy: 0.7802 - val_loss: 0.3947 - val_accuracy: 0.8148 - 94ms/epoch - 3ms/step\n",
      "Epoch 69/250\n",
      "27/27 - 0s - loss: 0.4872 - accuracy: 0.7778 - val_loss: 0.3802 - val_accuracy: 0.8148 - 91ms/epoch - 3ms/step\n",
      "Epoch 70/250\n",
      "27/27 - 0s - loss: 0.4916 - accuracy: 0.7802 - val_loss: 0.3737 - val_accuracy: 0.8148 - 93ms/epoch - 3ms/step\n",
      "Epoch 71/250\n",
      "27/27 - 0s - loss: 0.4820 - accuracy: 0.7814 - val_loss: 0.3702 - val_accuracy: 0.8148 - 91ms/epoch - 3ms/step\n",
      "Epoch 72/250\n",
      "27/27 - 0s - loss: 0.4959 - accuracy: 0.7897 - val_loss: 0.3683 - val_accuracy: 0.8148 - 91ms/epoch - 3ms/step\n",
      "Epoch 73/250\n",
      "27/27 - 0s - loss: 0.4904 - accuracy: 0.7897 - val_loss: 0.3769 - val_accuracy: 0.8148 - 92ms/epoch - 3ms/step\n",
      "Epoch 74/250\n",
      "27/27 - 0s - loss: 0.4880 - accuracy: 0.7909 - val_loss: 0.3657 - val_accuracy: 0.8148 - 89ms/epoch - 3ms/step\n",
      "Epoch 75/250\n",
      "27/27 - 0s - loss: 0.4844 - accuracy: 0.7909 - val_loss: 0.3712 - val_accuracy: 0.8148 - 138ms/epoch - 5ms/step\n",
      "Epoch 76/250\n",
      "27/27 - 0s - loss: 0.4879 - accuracy: 0.7873 - val_loss: 0.3707 - val_accuracy: 0.8148 - 98ms/epoch - 4ms/step\n",
      "Epoch 77/250\n",
      "27/27 - 0s - loss: 0.4761 - accuracy: 0.7861 - val_loss: 0.3559 - val_accuracy: 0.8148 - 91ms/epoch - 3ms/step\n",
      "Epoch 78/250\n",
      "27/27 - 0s - loss: 0.4887 - accuracy: 0.7861 - val_loss: 0.3613 - val_accuracy: 0.8148 - 96ms/epoch - 4ms/step\n",
      "Epoch 79/250\n",
      "27/27 - 0s - loss: 0.4696 - accuracy: 0.7873 - val_loss: 0.3482 - val_accuracy: 0.8148 - 91ms/epoch - 3ms/step\n",
      "Epoch 80/250\n",
      "27/27 - 0s - loss: 0.4937 - accuracy: 0.7861 - val_loss: 0.3530 - val_accuracy: 0.8148 - 92ms/epoch - 3ms/step\n",
      "Epoch 81/250\n",
      "27/27 - 0s - loss: 0.4763 - accuracy: 0.7909 - val_loss: 0.3510 - val_accuracy: 0.8148 - 90ms/epoch - 3ms/step\n",
      "Epoch 82/250\n",
      "27/27 - 0s - loss: 0.4738 - accuracy: 0.7957 - val_loss: 0.3595 - val_accuracy: 0.8148 - 91ms/epoch - 3ms/step\n",
      "Epoch 83/250\n",
      "27/27 - 0s - loss: 0.4927 - accuracy: 0.7861 - val_loss: 0.3689 - val_accuracy: 0.8148 - 94ms/epoch - 3ms/step\n",
      "Epoch 84/250\n",
      "27/27 - 0s - loss: 0.4826 - accuracy: 0.7945 - val_loss: 0.3680 - val_accuracy: 0.8148 - 89ms/epoch - 3ms/step\n",
      "Epoch 85/250\n",
      "27/27 - 0s - loss: 0.4662 - accuracy: 0.8076 - val_loss: 0.3548 - val_accuracy: 0.8148 - 88ms/epoch - 3ms/step\n",
      "Epoch 86/250\n",
      "27/27 - 0s - loss: 0.4819 - accuracy: 0.7945 - val_loss: 0.3576 - val_accuracy: 0.8148 - 93ms/epoch - 3ms/step\n",
      "Epoch 87/250\n",
      "27/27 - 0s - loss: 0.4751 - accuracy: 0.7885 - val_loss: 0.3497 - val_accuracy: 0.8148 - 92ms/epoch - 3ms/step\n",
      "Epoch 88/250\n",
      "27/27 - 0s - loss: 0.4654 - accuracy: 0.8065 - val_loss: 0.3437 - val_accuracy: 0.8148 - 92ms/epoch - 3ms/step\n",
      "Epoch 89/250\n",
      "27/27 - 0s - loss: 0.4632 - accuracy: 0.7945 - val_loss: 0.3372 - val_accuracy: 0.8148 - 94ms/epoch - 3ms/step\n",
      "Epoch 90/250\n",
      "27/27 - 0s - loss: 0.4850 - accuracy: 0.7957 - val_loss: 0.3481 - val_accuracy: 0.8333 - 91ms/epoch - 3ms/step\n",
      "Epoch 91/250\n",
      "27/27 - 0s - loss: 0.4736 - accuracy: 0.7838 - val_loss: 0.3477 - val_accuracy: 0.8519 - 91ms/epoch - 3ms/step\n",
      "Epoch 92/250\n",
      "27/27 - 0s - loss: 0.4748 - accuracy: 0.7897 - val_loss: 0.3371 - val_accuracy: 0.8519 - 94ms/epoch - 3ms/step\n",
      "Epoch 93/250\n",
      "27/27 - 0s - loss: 0.4724 - accuracy: 0.7957 - val_loss: 0.3426 - val_accuracy: 0.8333 - 90ms/epoch - 3ms/step\n",
      "Epoch 94/250\n",
      "27/27 - 0s - loss: 0.4526 - accuracy: 0.8041 - val_loss: 0.3333 - val_accuracy: 0.8519 - 89ms/epoch - 3ms/step\n",
      "Epoch 95/250\n",
      "27/27 - 0s - loss: 0.4583 - accuracy: 0.8100 - val_loss: 0.3339 - val_accuracy: 0.8333 - 91ms/epoch - 3ms/step\n",
      "Epoch 96/250\n",
      "27/27 - 0s - loss: 0.4643 - accuracy: 0.8017 - val_loss: 0.3456 - val_accuracy: 0.8519 - 92ms/epoch - 3ms/step\n",
      "Epoch 97/250\n",
      "27/27 - 0s - loss: 0.4580 - accuracy: 0.8017 - val_loss: 0.3515 - val_accuracy: 0.8704 - 91ms/epoch - 3ms/step\n",
      "Epoch 98/250\n",
      "27/27 - 0s - loss: 0.4421 - accuracy: 0.8184 - val_loss: 0.3372 - val_accuracy: 0.8519 - 90ms/epoch - 3ms/step\n",
      "Epoch 99/250\n",
      "27/27 - 0s - loss: 0.4555 - accuracy: 0.7933 - val_loss: 0.3395 - val_accuracy: 0.8704 - 96ms/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "27/27 - 0s - loss: 0.4527 - accuracy: 0.8136 - val_loss: 0.3398 - val_accuracy: 0.8704 - 89ms/epoch - 3ms/step\n",
      "Epoch 101/250\n",
      "27/27 - 0s - loss: 0.4536 - accuracy: 0.8041 - val_loss: 0.3384 - val_accuracy: 0.8704 - 93ms/epoch - 3ms/step\n",
      "Epoch 102/250\n",
      "27/27 - 0s - loss: 0.4530 - accuracy: 0.7981 - val_loss: 0.3355 - val_accuracy: 0.8704 - 92ms/epoch - 3ms/step\n",
      "Epoch 103/250\n",
      "27/27 - 0s - loss: 0.4561 - accuracy: 0.8041 - val_loss: 0.3393 - val_accuracy: 0.8333 - 93ms/epoch - 3ms/step\n",
      "Epoch 104/250\n",
      "27/27 - 0s - loss: 0.4595 - accuracy: 0.8100 - val_loss: 0.3281 - val_accuracy: 0.8704 - 90ms/epoch - 3ms/step\n",
      "Epoch 105/250\n",
      "27/27 - 0s - loss: 0.4384 - accuracy: 0.8148 - val_loss: 0.3232 - val_accuracy: 0.8704 - 92ms/epoch - 3ms/step\n",
      "Epoch 106/250\n",
      "27/27 - 0s - loss: 0.4570 - accuracy: 0.8076 - val_loss: 0.3236 - val_accuracy: 0.8333 - 90ms/epoch - 3ms/step\n",
      "Epoch 107/250\n",
      "27/27 - 0s - loss: 0.4393 - accuracy: 0.8136 - val_loss: 0.3128 - val_accuracy: 0.8704 - 90ms/epoch - 3ms/step\n",
      "Epoch 108/250\n",
      "27/27 - 0s - loss: 0.4606 - accuracy: 0.8112 - val_loss: 0.3198 - val_accuracy: 0.8704 - 90ms/epoch - 3ms/step\n",
      "Epoch 109/250\n",
      "27/27 - 0s - loss: 0.4399 - accuracy: 0.8100 - val_loss: 0.3194 - val_accuracy: 0.8704 - 96ms/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "27/27 - 0s - loss: 0.4449 - accuracy: 0.8041 - val_loss: 0.3259 - val_accuracy: 0.8333 - 94ms/epoch - 3ms/step\n",
      "Epoch 111/250\n",
      "27/27 - 0s - loss: 0.4373 - accuracy: 0.8124 - val_loss: 0.3143 - val_accuracy: 0.8704 - 93ms/epoch - 3ms/step\n",
      "Epoch 112/250\n",
      "27/27 - 0s - loss: 0.4466 - accuracy: 0.8053 - val_loss: 0.3091 - val_accuracy: 0.8704 - 93ms/epoch - 3ms/step\n",
      "Epoch 113/250\n",
      "27/27 - 0s - loss: 0.4490 - accuracy: 0.8112 - val_loss: 0.3221 - val_accuracy: 0.8704 - 91ms/epoch - 3ms/step\n",
      "Epoch 114/250\n",
      "27/27 - 0s - loss: 0.4470 - accuracy: 0.8148 - val_loss: 0.3169 - val_accuracy: 0.8704 - 92ms/epoch - 3ms/step\n",
      "Epoch 115/250\n",
      "27/27 - 0s - loss: 0.4304 - accuracy: 0.8148 - val_loss: 0.3186 - val_accuracy: 0.8704 - 92ms/epoch - 3ms/step\n",
      "Epoch 116/250\n",
      "27/27 - 0s - loss: 0.4424 - accuracy: 0.8172 - val_loss: 0.3257 - val_accuracy: 0.8704 - 91ms/epoch - 3ms/step\n",
      "Epoch 117/250\n",
      "27/27 - 0s - loss: 0.4484 - accuracy: 0.8208 - val_loss: 0.3220 - val_accuracy: 0.8704 - 89ms/epoch - 3ms/step\n",
      "Epoch 118/250\n",
      "27/27 - 0s - loss: 0.4386 - accuracy: 0.8112 - val_loss: 0.3117 - val_accuracy: 0.8704 - 91ms/epoch - 3ms/step\n",
      "Epoch 119/250\n",
      "27/27 - 0s - loss: 0.4478 - accuracy: 0.8124 - val_loss: 0.3053 - val_accuracy: 0.8704 - 99ms/epoch - 4ms/step\n",
      "Epoch 120/250\n",
      "27/27 - 0s - loss: 0.4556 - accuracy: 0.8053 - val_loss: 0.3183 - val_accuracy: 0.8704 - 107ms/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "27/27 - 0s - loss: 0.4288 - accuracy: 0.8220 - val_loss: 0.3145 - val_accuracy: 0.8704 - 100ms/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "27/27 - 0s - loss: 0.4455 - accuracy: 0.8053 - val_loss: 0.3141 - val_accuracy: 0.8704 - 93ms/epoch - 3ms/step\n",
      "Epoch 123/250\n",
      "27/27 - 0s - loss: 0.4424 - accuracy: 0.8112 - val_loss: 0.3157 - val_accuracy: 0.8704 - 90ms/epoch - 3ms/step\n",
      "Epoch 124/250\n",
      "27/27 - 0s - loss: 0.4303 - accuracy: 0.8088 - val_loss: 0.3165 - val_accuracy: 0.8704 - 91ms/epoch - 3ms/step\n",
      "Epoch 125/250\n",
      "27/27 - 0s - loss: 0.4434 - accuracy: 0.8053 - val_loss: 0.3158 - val_accuracy: 0.8704 - 93ms/epoch - 3ms/step\n",
      "Epoch 126/250\n",
      "27/27 - 0s - loss: 0.4373 - accuracy: 0.8208 - val_loss: 0.3194 - val_accuracy: 0.8704 - 90ms/epoch - 3ms/step\n",
      "Epoch 127/250\n",
      "27/27 - 0s - loss: 0.4451 - accuracy: 0.8208 - val_loss: 0.3183 - val_accuracy: 0.8704 - 91ms/epoch - 3ms/step\n",
      "Epoch 128/250\n",
      "27/27 - 0s - loss: 0.4285 - accuracy: 0.8100 - val_loss: 0.3166 - val_accuracy: 0.8704 - 95ms/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "27/27 - 0s - loss: 0.4345 - accuracy: 0.8065 - val_loss: 0.3136 - val_accuracy: 0.8704 - 90ms/epoch - 3ms/step\n",
      "Epoch 130/250\n",
      "27/27 - 0s - loss: 0.4386 - accuracy: 0.8172 - val_loss: 0.3147 - val_accuracy: 0.8704 - 92ms/epoch - 3ms/step\n",
      "Epoch 131/250\n",
      "27/27 - 0s - loss: 0.4205 - accuracy: 0.8232 - val_loss: 0.3080 - val_accuracy: 0.8704 - 92ms/epoch - 3ms/step\n",
      "Epoch 132/250\n",
      "27/27 - 0s - loss: 0.4291 - accuracy: 0.8208 - val_loss: 0.3118 - val_accuracy: 0.8704 - 89ms/epoch - 3ms/step\n",
      "Epoch 133/250\n",
      "27/27 - 0s - loss: 0.4363 - accuracy: 0.8088 - val_loss: 0.3140 - val_accuracy: 0.8704 - 95ms/epoch - 4ms/step\n",
      "Epoch 134/250\n",
      "27/27 - 0s - loss: 0.4390 - accuracy: 0.8160 - val_loss: 0.3123 - val_accuracy: 0.8704 - 93ms/epoch - 3ms/step\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39910760521888733, 0.8327721953392029]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    validation_split=0.06,\n",
    "    callbacks=[early_stopping],\n",
    "    epochs=250,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "model.evaluate(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot( history.history['accuracy'] )\n",
    "plt.plot( history.history['loss'] )\n",
    "plt.plot( history.history['val_loss'] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions on training dataset :-\n",
      "742 correct predictions out of 891\n",
      "accuracy = 83.27 %\n"
     ]
    }
   ],
   "source": [
    "# predicting on the testing data\n",
    "\n",
    "predictions = model.predict(train_x)\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(predictions)):\n",
    "    # print(f\"{train_y[i]} predicted --> { (predictions[i][0]*100)//1 } %\")\n",
    "\n",
    "    if predictions[i] > 0.500 and train_y[i] == 1:\n",
    "            correct = correct + 1\n",
    "\n",
    "    if predictions[i] < 0.500 and train_y[i] == 0:\n",
    "            correct = correct + 1\n",
    "\n",
    "print(\"predictions on training dataset :-\")\n",
    "print(f\"{correct} correct predictions out of {len(predictions)}\")\n",
    "print(f\"accuracy = { str((correct / len(predictions)) * 100)[:5] } %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "categorising array --> raw_sex\n",
      "unique values --> {'male': 1, 'female': 2}\n",
      "male --> [1. 0.]\n",
      "female --> [0. 1.]\n",
      "male --> [1. 0.]\n",
      "male --> [1. 0.]\n",
      "female --> [0. 1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_sex = list(test_df['Sex'])         # categorical\n",
    "\n",
    "cat_sex = categorical(raw_sex, sex_tokenizer, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values --> 0 out of 418\n",
      "most common value --> S\n",
      "replaced all 'nan' values with 'S'\n",
      "\n",
      "categorising array --> raw_region\n",
      "unique values --> {'S': 1, 'C': 2, 'Q': 3}\n",
      "Q --> [0. 0. 1.]\n",
      "S --> [1. 0. 0.]\n",
      "Q --> [0. 0. 1.]\n",
      "S --> [1. 0. 0.]\n",
      "S --> [1. 0. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_region = list(test_df['Embarked'])     # categorical + missing values\n",
    "raw_region = most_common_imputer(raw_region, debug=True)\n",
    "\n",
    "cat_region = categorical(raw_region, region_tokenizer, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passenger class --> [1, 2, 3] \n",
      "siblings --> [0, 1, 2, 3, 4, 5, 8] \n",
      "parents & children --> [0, 1, 2, 3, 4, 5, 6, 9] \n",
      "sex --> ['female', 'male'] \n",
      "region --> ['S', 'Q', 'C'] \n"
     ]
    }
   ],
   "source": [
    "# dropped 'Name', 'Ticket'\n",
    "# 'Cabin' --> Cabin present or not? \n",
    "\n",
    "p_class = list(test_df['Pclass'])\n",
    "\n",
    "siblings = list(test_df['SibSp'])\n",
    "parents = list(test_df['Parch'])\n",
    "\n",
    "fare = list(test_df['Fare'])\n",
    "\n",
    "print(f\"passenger class --> {list(set(p_class))} \")\n",
    "print(f\"siblings --> {list(set(siblings))} \")\n",
    "print(f\"parents & children --> {list(set(parents))} \")\n",
    "print(f\"sex --> {list(set(raw_sex))} \")\n",
    "print(f\"region --> {list(set(raw_region))} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan --> 0\n",
      "nan --> 0\n",
      "nan --> 0\n",
      "nan --> 0\n",
      "nan --> 0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "cabin_present = list(test_df['Cabin'])\n",
    "cat_cabin = binary_categorical(cabin_present, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --> Mrs. --> count = 72\n",
      "1 --> Miss. --> count = 78\n",
      "2 --> Rev. --> count = 2\n",
      "3 --> Mr. --> count = 244\n",
      "4 --> Master. --> count = 21\n",
      "5 --> Dr. --> count = 1\n",
      "['Mr.', 'Mrs.', 'Mr.', 'Mr.', 'Mrs.', 'Mr.', 'Miss.', 'Mr.', 'Mrs.', 'Mr.']\n"
     ]
    }
   ],
   "source": [
    "raw_names = list(test_df['Name'])\n",
    "\n",
    "proc_names = []\n",
    "positions = ['Mrs.', 'Miss.', 'Rev.', 'Mr.', 'Master.', 'Dr.']\n",
    "\n",
    "for i in range( len(raw_names) ):\n",
    "    name_array = raw_names[i].split(' ')\n",
    "    # print(i, name_array, sep=\" --> \")\n",
    "\n",
    "    token_found = 0\n",
    "    for token in name_array:\n",
    "        if token in positions:\n",
    "            token_found = 1\n",
    "            # print(f\"{token} --> {positions.index(token)}\\n\")\n",
    "            # proc_names.append( positions.index(token) )\n",
    "            proc_names.append( token )\n",
    "    if token_found == 0:\n",
    "        proc_names.append( 'Mr.' )\n",
    "\n",
    "for i in range(len(positions)):\n",
    "    print(f\"{i} --> {positions[i]} --> count = {proc_names.count(positions[i])}\")\n",
    "\n",
    "print(proc_names[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "categorising array --> proc_names\n",
      "unique values --> {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Dr': 5, 'Rev': 6}\n",
      "Mr. --> [1. 0. 0. 0. 0. 0.]\n",
      "Mrs. --> [0. 0. 1. 0. 0. 0.]\n",
      "Mr. --> [1. 0. 0. 0. 0. 0.]\n",
      "Mr. --> [1. 0. 0. 0. 0. 0.]\n",
      "Mrs. --> [0. 0. 1. 0. 0. 0.]\n",
      "\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "cat_names = categorical(proc_names, name_tokenizer, debug=True)\n",
    "\n",
    "print(cat_names[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 22.0, 0, 0, 7.8292, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[3, 38.0, 1, 0, 7.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[2, 26.0, 0, 0, 9.6875, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[3, 35.0, 0, 0, 8.6625, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[3, 35.0, 1, 1, 12.2875, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[3, 23.0, 0, 0, 9.225, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "test_x = []\n",
    "\n",
    "for i in range(len(raw_sex)):\n",
    "    temp = [\n",
    "        p_class[i], imputed_age[i],\n",
    "        siblings[i], parents[i], \n",
    "        fare[i]\n",
    "        # cat_cabin[i]\n",
    "    ]\n",
    "    temp.extend(cat_sex[i])\n",
    "    temp.extend(cat_region[i])\n",
    "    temp.extend(cat_names[i])\n",
    "    test_x.append(temp)\n",
    "    if i < 6: print(temp)\n",
    "    \n",
    "test_x = np.array(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 16)\n",
      "input shape for test_x = 16\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(\"input shape for test_x =\", train_x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_x)\n",
    "\n",
    "csv_pred = []\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i][0] > 0.500: \n",
    "        csv_pred.append(1)\n",
    "    else:\n",
    "        csv_pred.append(0)\n",
    "\n",
    "print(csv_pred[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_id = list(test_df['PassengerId'])\n",
    "\n",
    "submit_dict = {\n",
    "    'PassengerId': passenger_id,\n",
    "    'Survived': csv_pred\n",
    "}\n",
    "\n",
    "submit_df = pd.DataFrame(submit_dict)\n",
    "submit_df.head()\n",
    "\n",
    "submit_df.to_csv('submit.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf6ab032c8d0f1ddf2ea4dd4e609e6e6dfd5e53c8a42a3a69958aaabf5715049"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
