{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 total entries\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "print(f\"{len(train_df)} total entries\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_imputer(raw_array, debug=False):\n",
    "\n",
    "    def namestr(obj, namespace):\n",
    "        return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "    null_count = 0\n",
    "    sum = 0\n",
    "    mean = 0\n",
    "    imputed_array = []\n",
    "\n",
    "    for item in raw_array:\n",
    "        if str(item) == 'nan':\n",
    "            # print(item, end=', ')\n",
    "            null_count = null_count + 1\n",
    "        else: sum = sum + item\n",
    "    \n",
    "    mean = ( sum / len(raw_array) ) // 1\n",
    "\n",
    "    if debug == True:\n",
    "        print(f\"\\nimputing array --> {namestr(raw_array, globals())[0]}\")\n",
    "        print(f\"{null_count} null values\")\n",
    "        print(f\"{len(raw_array) - null_count} numeric values\")\n",
    "        print(f\"{len(raw_array)} total values\")\n",
    "        print(f\"mean = { mean }\")\n",
    "        print(f\"replaced all missing values with mean {mean}\\n\")\n",
    "\n",
    "    for item in raw_array:\n",
    "        if str(item) == 'nan':\n",
    "            item = mean\n",
    "        imputed_array.append(item)\n",
    "        # print(item, end=', ')\n",
    "\n",
    "    return imputed_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "imputing array --> raw_age\n",
      "177 null values\n",
      "714 numeric values\n",
      "891 total values\n",
      "mean = 23.0\n",
      "replaced all missing values with mean 23.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_age = list(train_df['Age'])         # missing values\n",
    "imputed_age = mean_imputer(raw_age, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def categorical(raw_array, tokenizer, debug=False):\n",
    "\n",
    "    def namestr(obj, namespace):\n",
    "        return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "\n",
    "    seq_array = tokenizer.texts_to_sequences(raw_array)\n",
    "\n",
    "    cat_array = tf.keras.utils.to_categorical(seq_array)\n",
    "    cat_array = cat_array[:, 1:]   # cause the [0] value doesnt have anything in the word index\n",
    "\n",
    "\n",
    "    if debug == True:\n",
    "        print(f\"\\ncategorising array --> {namestr(raw_array, globals())[0]}\")\n",
    "        print(f\"unique values --> {tokenizer.word_index}\")\n",
    "        for i in range(5):\n",
    "            print(f\"{raw_array[i]} --> { cat_array[i] }\")\n",
    "        print()\n",
    "        \n",
    "    return cat_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "categorising array --> raw_sex\n",
      "unique values --> {'male': 1, 'female': 2}\n",
      "male --> [1. 0.]\n",
      "female --> [0. 1.]\n",
      "female --> [0. 1.]\n",
      "female --> [0. 1.]\n",
      "male --> [1. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_sex = list(train_df['Sex'])         # categorical\n",
    "\n",
    "sex_tokenizer = tf.keras.preprocessing.text.Tokenizer( lower=False )\n",
    "sex_tokenizer.fit_on_texts(raw_sex)\n",
    "\n",
    "cat_sex = categorical(raw_sex, sex_tokenizer, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_imputer(array, debug=False):\n",
    "\n",
    "    most_common = max(array, key = array.count)\n",
    "    missing_values = 0\n",
    "\n",
    "    for i in range(len(array)):\n",
    "        if str( array[i] ) == 'nan':\n",
    "            missing_values = missing_values + 1\n",
    "            array[i] = most_common\n",
    "\n",
    "    if debug == True:\n",
    "        print(f\"missing values --> {missing_values} out of {len(array)}\")\n",
    "        print(f\"most common value --> {most_common}\")\n",
    "        print(f\"replaced all 'nan' values with '{most_common}'\")\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values --> 2 out of 891\n",
      "most common value --> S\n",
      "replaced all 'nan' values with 'S'\n",
      "\n",
      "categorising array --> raw_region\n",
      "unique values --> {'S': 1, 'C': 2, 'Q': 3}\n",
      "S --> [1. 0. 0.]\n",
      "C --> [0. 1. 0.]\n",
      "S --> [1. 0. 0.]\n",
      "S --> [1. 0. 0.]\n",
      "S --> [1. 0. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_region = list(train_df['Embarked'])     # categorical + missing values\n",
    "raw_region = most_common_imputer(raw_region, debug=True)\n",
    "\n",
    "region_tokenizer = tf.keras.preprocessing.text.Tokenizer( lower=False )\n",
    "region_tokenizer.fit_on_texts(raw_region)\n",
    "\n",
    "cat_region = categorical(raw_region, region_tokenizer, debug=True)\n",
    "\n",
    "# for i in range(8):\n",
    "#     print(f\"{raw_region[i]} --> {cat_region[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived --> [0, 1] \n",
      "passenger class --> [1, 2, 3] \n",
      "siblings --> [0, 1, 2, 3, 4, 5, 8] \n",
      "parents & children --> [0, 1, 2, 3, 4, 5, 6] \n",
      "sex --> ['female', 'male'] \n",
      "region --> ['C', 'S', 'Q'] \n"
     ]
    }
   ],
   "source": [
    "# dropped 'Name', 'Ticket'\n",
    "# 'Cabin' --> Cabin present or not? \n",
    "\n",
    "survived = list(train_df['Survived'])\n",
    "\n",
    "p_class = list(train_df['Pclass'])\n",
    "\n",
    "siblings = list(train_df['SibSp'])\n",
    "parents = list(train_df['Parch'])\n",
    "\n",
    "fare = list(train_df['Fare'])\n",
    "\n",
    "print(f\"survived --> {list(set(survived))} \")\n",
    "print(f\"passenger class --> {list(set(p_class))} \")\n",
    "print(f\"siblings --> {list(set(siblings))} \")\n",
    "print(f\"parents & children --> {list(set(parents))} \")\n",
    "print(f\"sex --> {list(set(raw_sex))} \")\n",
    "print(f\"region --> {list(set(raw_region))} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_categorical(array, debug=False):\n",
    "\n",
    "    cat_array = []\n",
    "\n",
    "    for i in range(len(array)):\n",
    "        if str(array[i]) == 'nan':\n",
    "            cat_array.append(0)\n",
    "        else:\n",
    "            cat_array.append(1)\n",
    "\n",
    "    if debug == True:\n",
    "        for i in range(5):\n",
    "            print(f\"{array[i]} --> {cat_array[i]}\")\n",
    "        print(cat_array[:10])\n",
    "\n",
    "    return cat_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan --> 0\n",
      "C85 --> 1\n",
      "nan --> 0\n",
      "C123 --> 1\n",
      "nan --> 0\n",
      "[0, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "cabin_present = list(train_df['Cabin'])\n",
    "cat_cabin = binary_categorical(cabin_present, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --> Mrs. --> count = 125\n",
      "1 --> Miss. --> count = 182\n",
      "2 --> Rev. --> count = 6\n",
      "3 --> Mr. --> count = 531\n",
      "4 --> Master. --> count = 40\n",
      "5 --> Dr. --> count = 7\n",
      "['Mr.', 'Mrs.', 'Miss.', 'Mrs.', 'Mr.', 'Mr.', 'Mr.', 'Master.', 'Mrs.', 'Mrs.']\n"
     ]
    }
   ],
   "source": [
    "raw_names = list(train_df['Name'])\n",
    "\n",
    "proc_names = []\n",
    "positions = ['Mrs.', 'Miss.', 'Rev.', 'Mr.', 'Master.', 'Dr.']\n",
    "\n",
    "for i in range( len(raw_names) ):\n",
    "    name_array = raw_names[i].split(' ')\n",
    "    # print(i, name_array, sep=\" --> \")\n",
    "\n",
    "    token_found = 0\n",
    "    for token in name_array:\n",
    "        if token in positions:\n",
    "            token_found = 1\n",
    "            # print(f\"{token} --> {positions.index(token)}\\n\")\n",
    "            # proc_names.append( positions.index(token) )\n",
    "            proc_names.append( token )\n",
    "    if token_found == 0:\n",
    "        proc_names.append( 'Mr.' )\n",
    "\n",
    "for i in range(len(positions)):\n",
    "    print(f\"{i} --> {positions[i]} --> count = {proc_names.count(positions[i])}\")\n",
    "\n",
    "print(proc_names[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "categorising array --> proc_names\n",
      "unique values --> {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Dr': 5, 'Rev': 6}\n",
      "Mr. --> [1. 0. 0. 0. 0. 0.]\n",
      "Mrs. --> [0. 0. 1. 0. 0. 0.]\n",
      "Miss. --> [0. 1. 0. 0. 0. 0.]\n",
      "Mrs. --> [0. 0. 1. 0. 0. 0.]\n",
      "Mr. --> [1. 0. 0. 0. 0. 0.]\n",
      "\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "name_tokenizer = tf.keras.preprocessing.text.Tokenizer( lower=False )\n",
    "name_tokenizer.fit_on_texts(proc_names)\n",
    "\n",
    "cat_names = categorical(proc_names, name_tokenizer, debug=True)\n",
    "\n",
    "print(cat_names[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 22.0, 1, 0, 7.25, 0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[1, 38.0, 1, 0, 71.2833, 1, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[3, 26.0, 0, 0, 7.925, 0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[1, 35.0, 1, 0, 53.1, 1, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[3, 35.0, 0, 0, 8.05, 0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[3, 23.0, 0, 0, 8.4583, 0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "train_x = []\n",
    "\n",
    "for i in range(len(raw_sex)):\n",
    "    temp = [\n",
    "        p_class[i], imputed_age[i],\n",
    "        siblings[i], parents[i], \n",
    "        fare[i], cat_cabin[i]\n",
    "    ]\n",
    "    temp.extend(cat_sex[i])\n",
    "    temp.extend(cat_region[i])\n",
    "    temp.extend(cat_names[i])\n",
    "    train_x.append(temp)\n",
    "    if i < 6: print(temp)  # printing a sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 17)\n",
      "input shape for model = 17\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "survived = list(train_df['Survived'])\n",
    "\n",
    "train_y = np.array(survived)\n",
    "train_x = np.array(train_x)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(\"input shape for model =\", train_x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "visible = layers.Input( shape=[ train_x.shape[1] ] )\n",
    "x = layers.Dense(64, activation='relu')(visible)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(16, activation='relu')(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    min_delta=0.0003,\n",
    "    patience=40,\n",
    "    restore_best_weights=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "28/28 - 1s - loss: 1.3912 - accuracy: 0.5578 - 1s/epoch - 47ms/step\n",
      "Epoch 2/250\n",
      "28/28 - 0s - loss: 0.8798 - accuracy: 0.5713 - 61ms/epoch - 2ms/step\n",
      "Epoch 3/250\n",
      "28/28 - 0s - loss: 0.8343 - accuracy: 0.5814 - 60ms/epoch - 2ms/step\n",
      "Epoch 4/250\n",
      "28/28 - 0s - loss: 0.7730 - accuracy: 0.5701 - 60ms/epoch - 2ms/step\n",
      "Epoch 5/250\n",
      "28/28 - 0s - loss: 0.7234 - accuracy: 0.5971 - 87ms/epoch - 3ms/step\n",
      "Epoch 6/250\n",
      "28/28 - 0s - loss: 0.6987 - accuracy: 0.5971 - 83ms/epoch - 3ms/step\n",
      "Epoch 7/250\n",
      "28/28 - 0s - loss: 0.6949 - accuracy: 0.5937 - 68ms/epoch - 2ms/step\n",
      "Epoch 8/250\n",
      "28/28 - 0s - loss: 0.7032 - accuracy: 0.6038 - 60ms/epoch - 2ms/step\n",
      "Epoch 9/250\n",
      "28/28 - 0s - loss: 0.7109 - accuracy: 0.6162 - 65ms/epoch - 2ms/step\n",
      "Epoch 10/250\n",
      "28/28 - 0s - loss: 0.7060 - accuracy: 0.6150 - 73ms/epoch - 3ms/step\n",
      "Epoch 11/250\n",
      "28/28 - 0s - loss: 0.6745 - accuracy: 0.6173 - 100ms/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "28/28 - 0s - loss: 0.6717 - accuracy: 0.6274 - 89ms/epoch - 3ms/step\n",
      "Epoch 13/250\n",
      "28/28 - 0s - loss: 0.6561 - accuracy: 0.6510 - 76ms/epoch - 3ms/step\n",
      "Epoch 14/250\n",
      "28/28 - 0s - loss: 0.6957 - accuracy: 0.6184 - 84ms/epoch - 3ms/step\n",
      "Epoch 15/250\n",
      "28/28 - 0s - loss: 0.6514 - accuracy: 0.6330 - 88ms/epoch - 3ms/step\n",
      "Epoch 16/250\n",
      "28/28 - 0s - loss: 0.6631 - accuracy: 0.6409 - 93ms/epoch - 3ms/step\n",
      "Epoch 17/250\n",
      "28/28 - 0s - loss: 0.6534 - accuracy: 0.6296 - 72ms/epoch - 3ms/step\n",
      "Epoch 18/250\n",
      "28/28 - 0s - loss: 0.6435 - accuracy: 0.6386 - 76ms/epoch - 3ms/step\n",
      "Epoch 19/250\n",
      "28/28 - 0s - loss: 0.6462 - accuracy: 0.6476 - 78ms/epoch - 3ms/step\n",
      "Epoch 20/250\n",
      "28/28 - 0s - loss: 0.6473 - accuracy: 0.6431 - 79ms/epoch - 3ms/step\n",
      "Epoch 21/250\n",
      "28/28 - 0s - loss: 0.6379 - accuracy: 0.6352 - 85ms/epoch - 3ms/step\n",
      "Epoch 22/250\n",
      "28/28 - 0s - loss: 0.6333 - accuracy: 0.6554 - 99ms/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "28/28 - 0s - loss: 0.6262 - accuracy: 0.6532 - 68ms/epoch - 2ms/step\n",
      "Epoch 24/250\n",
      "28/28 - 0s - loss: 0.6238 - accuracy: 0.6543 - 70ms/epoch - 2ms/step\n",
      "Epoch 25/250\n",
      "28/28 - 0s - loss: 0.6211 - accuracy: 0.6442 - 74ms/epoch - 3ms/step\n",
      "Epoch 26/250\n",
      "28/28 - 0s - loss: 0.6110 - accuracy: 0.6554 - 78ms/epoch - 3ms/step\n",
      "Epoch 27/250\n",
      "28/28 - 0s - loss: 0.6186 - accuracy: 0.6869 - 89ms/epoch - 3ms/step\n",
      "Epoch 28/250\n",
      "28/28 - 0s - loss: 0.6235 - accuracy: 0.6622 - 86ms/epoch - 3ms/step\n",
      "Epoch 29/250\n",
      "28/28 - 0s - loss: 0.5915 - accuracy: 0.6835 - 65ms/epoch - 2ms/step\n",
      "Epoch 30/250\n",
      "28/28 - 0s - loss: 0.6067 - accuracy: 0.6431 - 67ms/epoch - 2ms/step\n",
      "Epoch 31/250\n",
      "28/28 - 0s - loss: 0.6120 - accuracy: 0.6543 - 70ms/epoch - 2ms/step\n",
      "Epoch 32/250\n",
      "28/28 - 0s - loss: 0.5844 - accuracy: 0.6700 - 65ms/epoch - 2ms/step\n",
      "Epoch 33/250\n",
      "28/28 - 0s - loss: 0.6045 - accuracy: 0.6599 - 67ms/epoch - 2ms/step\n",
      "Epoch 34/250\n",
      "28/28 - 0s - loss: 0.6157 - accuracy: 0.6577 - 66ms/epoch - 2ms/step\n",
      "Epoch 35/250\n",
      "28/28 - 0s - loss: 0.5781 - accuracy: 0.6712 - 63ms/epoch - 2ms/step\n",
      "Epoch 36/250\n",
      "28/28 - 0s - loss: 0.5861 - accuracy: 0.6644 - 68ms/epoch - 2ms/step\n",
      "Epoch 37/250\n",
      "28/28 - 0s - loss: 0.5959 - accuracy: 0.6700 - 64ms/epoch - 2ms/step\n",
      "Epoch 38/250\n",
      "28/28 - 0s - loss: 0.5674 - accuracy: 0.6880 - 63ms/epoch - 2ms/step\n",
      "Epoch 39/250\n",
      "28/28 - 0s - loss: 0.5949 - accuracy: 0.6655 - 62ms/epoch - 2ms/step\n",
      "Epoch 40/250\n",
      "28/28 - 0s - loss: 0.5884 - accuracy: 0.6756 - 65ms/epoch - 2ms/step\n",
      "Epoch 41/250\n",
      "28/28 - 0s - loss: 0.5646 - accuracy: 0.6790 - 64ms/epoch - 2ms/step\n",
      "Epoch 42/250\n",
      "28/28 - 0s - loss: 0.5589 - accuracy: 0.7037 - 65ms/epoch - 2ms/step\n",
      "Epoch 43/250\n",
      "28/28 - 0s - loss: 0.5701 - accuracy: 0.6981 - 67ms/epoch - 2ms/step\n",
      "Epoch 44/250\n",
      "28/28 - 0s - loss: 0.5563 - accuracy: 0.7172 - 65ms/epoch - 2ms/step\n",
      "Epoch 45/250\n",
      "28/28 - 0s - loss: 0.5649 - accuracy: 0.6947 - 65ms/epoch - 2ms/step\n",
      "Epoch 46/250\n",
      "28/28 - 0s - loss: 0.5651 - accuracy: 0.6902 - 66ms/epoch - 2ms/step\n",
      "Epoch 47/250\n",
      "28/28 - 0s - loss: 0.5506 - accuracy: 0.7217 - 67ms/epoch - 2ms/step\n",
      "Epoch 48/250\n",
      "28/28 - 0s - loss: 0.5583 - accuracy: 0.7160 - 64ms/epoch - 2ms/step\n",
      "Epoch 49/250\n",
      "28/28 - 0s - loss: 0.5562 - accuracy: 0.6970 - 65ms/epoch - 2ms/step\n",
      "Epoch 50/250\n",
      "28/28 - 0s - loss: 0.5523 - accuracy: 0.7228 - 67ms/epoch - 2ms/step\n",
      "Epoch 51/250\n",
      "28/28 - 0s - loss: 0.5493 - accuracy: 0.7194 - 63ms/epoch - 2ms/step\n",
      "Epoch 52/250\n",
      "28/28 - 0s - loss: 0.5411 - accuracy: 0.7419 - 66ms/epoch - 2ms/step\n",
      "Epoch 53/250\n",
      "28/28 - 0s - loss: 0.5571 - accuracy: 0.7037 - 66ms/epoch - 2ms/step\n",
      "Epoch 54/250\n",
      "28/28 - 0s - loss: 0.5665 - accuracy: 0.7250 - 61ms/epoch - 2ms/step\n",
      "Epoch 55/250\n",
      "28/28 - 0s - loss: 0.5662 - accuracy: 0.7228 - 66ms/epoch - 2ms/step\n",
      "Epoch 56/250\n",
      "28/28 - 0s - loss: 0.5336 - accuracy: 0.7262 - 64ms/epoch - 2ms/step\n",
      "Epoch 57/250\n",
      "28/28 - 0s - loss: 0.5338 - accuracy: 0.7475 - 66ms/epoch - 2ms/step\n",
      "Epoch 58/250\n",
      "28/28 - 0s - loss: 0.5402 - accuracy: 0.7306 - 65ms/epoch - 2ms/step\n",
      "Epoch 59/250\n",
      "28/28 - 0s - loss: 0.5171 - accuracy: 0.7452 - 66ms/epoch - 2ms/step\n",
      "Epoch 60/250\n",
      "28/28 - 0s - loss: 0.5146 - accuracy: 0.7688 - 65ms/epoch - 2ms/step\n",
      "Epoch 61/250\n",
      "28/28 - 0s - loss: 0.5342 - accuracy: 0.7508 - 66ms/epoch - 2ms/step\n",
      "Epoch 62/250\n",
      "28/28 - 0s - loss: 0.5127 - accuracy: 0.7632 - 62ms/epoch - 2ms/step\n",
      "Epoch 63/250\n",
      "28/28 - 0s - loss: 0.5362 - accuracy: 0.7733 - 67ms/epoch - 2ms/step\n",
      "Epoch 64/250\n",
      "28/28 - 0s - loss: 0.5031 - accuracy: 0.7654 - 70ms/epoch - 3ms/step\n",
      "Epoch 65/250\n",
      "28/28 - 0s - loss: 0.5181 - accuracy: 0.7710 - 67ms/epoch - 2ms/step\n",
      "Epoch 66/250\n",
      "28/28 - 0s - loss: 0.5200 - accuracy: 0.7565 - 68ms/epoch - 2ms/step\n",
      "Epoch 67/250\n",
      "28/28 - 0s - loss: 0.5501 - accuracy: 0.7722 - 67ms/epoch - 2ms/step\n",
      "Epoch 68/250\n",
      "28/28 - 0s - loss: 0.5119 - accuracy: 0.7834 - 67ms/epoch - 2ms/step\n",
      "Epoch 69/250\n",
      "28/28 - 0s - loss: 0.5276 - accuracy: 0.7643 - 71ms/epoch - 3ms/step\n",
      "Epoch 70/250\n",
      "28/28 - 0s - loss: 0.5196 - accuracy: 0.7677 - 68ms/epoch - 2ms/step\n",
      "Epoch 71/250\n",
      "28/28 - 0s - loss: 0.5056 - accuracy: 0.7744 - 65ms/epoch - 2ms/step\n",
      "Epoch 72/250\n",
      "28/28 - 0s - loss: 0.5249 - accuracy: 0.7688 - 69ms/epoch - 2ms/step\n",
      "Epoch 73/250\n",
      "28/28 - 0s - loss: 0.5042 - accuracy: 0.7789 - 64ms/epoch - 2ms/step\n",
      "Epoch 74/250\n",
      "28/28 - 0s - loss: 0.5022 - accuracy: 0.7733 - 68ms/epoch - 2ms/step\n",
      "Epoch 75/250\n",
      "28/28 - 0s - loss: 0.5079 - accuracy: 0.7868 - 66ms/epoch - 2ms/step\n",
      "Epoch 76/250\n",
      "28/28 - 0s - loss: 0.5001 - accuracy: 0.7710 - 65ms/epoch - 2ms/step\n",
      "Epoch 77/250\n",
      "28/28 - 0s - loss: 0.4985 - accuracy: 0.7845 - 67ms/epoch - 2ms/step\n",
      "Epoch 78/250\n",
      "28/28 - 0s - loss: 0.5110 - accuracy: 0.7890 - 70ms/epoch - 2ms/step\n",
      "Epoch 79/250\n",
      "28/28 - 0s - loss: 0.4926 - accuracy: 0.7901 - 66ms/epoch - 2ms/step\n",
      "Epoch 80/250\n",
      "28/28 - 0s - loss: 0.4886 - accuracy: 0.7845 - 67ms/epoch - 2ms/step\n",
      "Epoch 81/250\n",
      "28/28 - 0s - loss: 0.5083 - accuracy: 0.7890 - 65ms/epoch - 2ms/step\n",
      "Epoch 82/250\n",
      "28/28 - 0s - loss: 0.4875 - accuracy: 0.7935 - 64ms/epoch - 2ms/step\n",
      "Epoch 83/250\n",
      "28/28 - 0s - loss: 0.4940 - accuracy: 0.7980 - 66ms/epoch - 2ms/step\n",
      "Epoch 84/250\n",
      "28/28 - 0s - loss: 0.4908 - accuracy: 0.7991 - 67ms/epoch - 2ms/step\n",
      "Epoch 85/250\n",
      "28/28 - 0s - loss: 0.4753 - accuracy: 0.8013 - 66ms/epoch - 2ms/step\n",
      "Epoch 86/250\n",
      "28/28 - 0s - loss: 0.4984 - accuracy: 0.7890 - 63ms/epoch - 2ms/step\n",
      "Epoch 87/250\n",
      "28/28 - 0s - loss: 0.4628 - accuracy: 0.7991 - 69ms/epoch - 2ms/step\n",
      "Epoch 88/250\n",
      "28/28 - 0s - loss: 0.4880 - accuracy: 0.7946 - 63ms/epoch - 2ms/step\n",
      "Epoch 89/250\n",
      "28/28 - 0s - loss: 0.4851 - accuracy: 0.7935 - 63ms/epoch - 2ms/step\n",
      "Epoch 90/250\n",
      "28/28 - 0s - loss: 0.4738 - accuracy: 0.7969 - 65ms/epoch - 2ms/step\n",
      "Epoch 91/250\n",
      "28/28 - 0s - loss: 0.4709 - accuracy: 0.8081 - 70ms/epoch - 3ms/step\n",
      "Epoch 92/250\n",
      "28/28 - 0s - loss: 0.4677 - accuracy: 0.7946 - 64ms/epoch - 2ms/step\n",
      "Epoch 93/250\n",
      "28/28 - 0s - loss: 0.4793 - accuracy: 0.8002 - 71ms/epoch - 3ms/step\n",
      "Epoch 94/250\n",
      "28/28 - 0s - loss: 0.4500 - accuracy: 0.8092 - 66ms/epoch - 2ms/step\n",
      "Epoch 95/250\n",
      "28/28 - 0s - loss: 0.4774 - accuracy: 0.8070 - 68ms/epoch - 2ms/step\n",
      "Epoch 96/250\n",
      "28/28 - 0s - loss: 0.4803 - accuracy: 0.8081 - 70ms/epoch - 2ms/step\n",
      "Epoch 97/250\n",
      "28/28 - 0s - loss: 0.4806 - accuracy: 0.8070 - 63ms/epoch - 2ms/step\n",
      "Epoch 98/250\n",
      "28/28 - 0s - loss: 0.4539 - accuracy: 0.8159 - 69ms/epoch - 2ms/step\n",
      "Epoch 99/250\n",
      "28/28 - 0s - loss: 0.4668 - accuracy: 0.8103 - 66ms/epoch - 2ms/step\n",
      "Epoch 100/250\n",
      "28/28 - 0s - loss: 0.4645 - accuracy: 0.8036 - 64ms/epoch - 2ms/step\n",
      "Epoch 101/250\n",
      "28/28 - 0s - loss: 0.4650 - accuracy: 0.8081 - 66ms/epoch - 2ms/step\n",
      "Epoch 102/250\n",
      "28/28 - 0s - loss: 0.4545 - accuracy: 0.8058 - 68ms/epoch - 2ms/step\n",
      "Epoch 103/250\n",
      "28/28 - 0s - loss: 0.4700 - accuracy: 0.8025 - 65ms/epoch - 2ms/step\n",
      "Epoch 104/250\n",
      "28/28 - 0s - loss: 0.4471 - accuracy: 0.8092 - 64ms/epoch - 2ms/step\n",
      "Epoch 105/250\n",
      "28/28 - 0s - loss: 0.4459 - accuracy: 0.8148 - 64ms/epoch - 2ms/step\n",
      "Epoch 106/250\n",
      "28/28 - 0s - loss: 0.4446 - accuracy: 0.8193 - 65ms/epoch - 2ms/step\n",
      "Epoch 107/250\n",
      "28/28 - 0s - loss: 0.4462 - accuracy: 0.8126 - 63ms/epoch - 2ms/step\n",
      "Epoch 108/250\n",
      "28/28 - 0s - loss: 0.4481 - accuracy: 0.8114 - 64ms/epoch - 2ms/step\n",
      "Epoch 109/250\n",
      "28/28 - 0s - loss: 0.4431 - accuracy: 0.8114 - 65ms/epoch - 2ms/step\n",
      "Epoch 110/250\n",
      "28/28 - 0s - loss: 0.4370 - accuracy: 0.8283 - 65ms/epoch - 2ms/step\n",
      "Epoch 111/250\n",
      "28/28 - 0s - loss: 0.4395 - accuracy: 0.8092 - 71ms/epoch - 3ms/step\n",
      "Epoch 112/250\n",
      "28/28 - 0s - loss: 0.4478 - accuracy: 0.8227 - 68ms/epoch - 2ms/step\n",
      "Epoch 113/250\n",
      "28/28 - 0s - loss: 0.4355 - accuracy: 0.8092 - 68ms/epoch - 2ms/step\n",
      "Epoch 114/250\n",
      "28/28 - 0s - loss: 0.4365 - accuracy: 0.8126 - 65ms/epoch - 2ms/step\n",
      "Epoch 115/250\n",
      "28/28 - 0s - loss: 0.4372 - accuracy: 0.8137 - 65ms/epoch - 2ms/step\n",
      "Epoch 116/250\n",
      "28/28 - 0s - loss: 0.4529 - accuracy: 0.8114 - 67ms/epoch - 2ms/step\n",
      "Epoch 117/250\n",
      "28/28 - 0s - loss: 0.4214 - accuracy: 0.8283 - 68ms/epoch - 2ms/step\n",
      "Epoch 118/250\n",
      "28/28 - 0s - loss: 0.4397 - accuracy: 0.8159 - 120ms/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "28/28 - 0s - loss: 0.4331 - accuracy: 0.8193 - 70ms/epoch - 3ms/step\n",
      "Epoch 120/250\n",
      "28/28 - 0s - loss: 0.4390 - accuracy: 0.8182 - 64ms/epoch - 2ms/step\n",
      "Epoch 121/250\n",
      "28/28 - 0s - loss: 0.4332 - accuracy: 0.8215 - 64ms/epoch - 2ms/step\n",
      "Epoch 122/250\n",
      "28/28 - 0s - loss: 0.4500 - accuracy: 0.8204 - 64ms/epoch - 2ms/step\n",
      "Epoch 123/250\n",
      "28/28 - 0s - loss: 0.4117 - accuracy: 0.8238 - 66ms/epoch - 2ms/step\n",
      "Epoch 124/250\n",
      "28/28 - 0s - loss: 0.4224 - accuracy: 0.8092 - 62ms/epoch - 2ms/step\n",
      "Epoch 125/250\n",
      "28/28 - 0s - loss: 0.4350 - accuracy: 0.8204 - 65ms/epoch - 2ms/step\n",
      "Epoch 126/250\n",
      "28/28 - 0s - loss: 0.4260 - accuracy: 0.8238 - 64ms/epoch - 2ms/step\n",
      "Epoch 127/250\n",
      "28/28 - 0s - loss: 0.4423 - accuracy: 0.8227 - 66ms/epoch - 2ms/step\n",
      "Epoch 128/250\n",
      "28/28 - 0s - loss: 0.4186 - accuracy: 0.8305 - 68ms/epoch - 2ms/step\n",
      "Epoch 129/250\n",
      "28/28 - 0s - loss: 0.4379 - accuracy: 0.8159 - 64ms/epoch - 2ms/step\n",
      "Epoch 130/250\n",
      "28/28 - 0s - loss: 0.4271 - accuracy: 0.8238 - 72ms/epoch - 3ms/step\n",
      "Epoch 131/250\n",
      "28/28 - 0s - loss: 0.4231 - accuracy: 0.8373 - 66ms/epoch - 2ms/step\n",
      "Epoch 132/250\n",
      "28/28 - 0s - loss: 0.4223 - accuracy: 0.8182 - 68ms/epoch - 2ms/step\n",
      "Epoch 133/250\n",
      "28/28 - 0s - loss: 0.4407 - accuracy: 0.8238 - 64ms/epoch - 2ms/step\n",
      "Epoch 134/250\n",
      "28/28 - 0s - loss: 0.4103 - accuracy: 0.8395 - 62ms/epoch - 2ms/step\n",
      "Epoch 135/250\n",
      "28/28 - 0s - loss: 0.4345 - accuracy: 0.8294 - 62ms/epoch - 2ms/step\n",
      "Epoch 136/250\n",
      "28/28 - 0s - loss: 0.4274 - accuracy: 0.8126 - 65ms/epoch - 2ms/step\n",
      "Epoch 137/250\n",
      "28/28 - 0s - loss: 0.4204 - accuracy: 0.8227 - 68ms/epoch - 2ms/step\n",
      "Epoch 138/250\n",
      "28/28 - 0s - loss: 0.4286 - accuracy: 0.8260 - 66ms/epoch - 2ms/step\n",
      "Epoch 139/250\n",
      "28/28 - 0s - loss: 0.4145 - accuracy: 0.8316 - 63ms/epoch - 2ms/step\n",
      "Epoch 140/250\n",
      "28/28 - 0s - loss: 0.4231 - accuracy: 0.8328 - 63ms/epoch - 2ms/step\n",
      "Epoch 141/250\n",
      "28/28 - 0s - loss: 0.4223 - accuracy: 0.8148 - 66ms/epoch - 2ms/step\n",
      "Epoch 142/250\n",
      "28/28 - 0s - loss: 0.4261 - accuracy: 0.8249 - 65ms/epoch - 2ms/step\n",
      "Epoch 143/250\n",
      "28/28 - 0s - loss: 0.4321 - accuracy: 0.8418 - 64ms/epoch - 2ms/step\n",
      "Epoch 144/250\n",
      "28/28 - 0s - loss: 0.4256 - accuracy: 0.8182 - 64ms/epoch - 2ms/step\n",
      "Epoch 145/250\n",
      "28/28 - 0s - loss: 0.4277 - accuracy: 0.8283 - 67ms/epoch - 2ms/step\n",
      "Epoch 146/250\n",
      "28/28 - 0s - loss: 0.4071 - accuracy: 0.8215 - 65ms/epoch - 2ms/step\n",
      "Epoch 147/250\n",
      "28/28 - 0s - loss: 0.4116 - accuracy: 0.8272 - 58ms/epoch - 2ms/step\n",
      "Epoch 148/250\n",
      "28/28 - 0s - loss: 0.4197 - accuracy: 0.8215 - 67ms/epoch - 2ms/step\n",
      "Epoch 149/250\n",
      "28/28 - 0s - loss: 0.4214 - accuracy: 0.8215 - 68ms/epoch - 2ms/step\n",
      "Epoch 150/250\n",
      "28/28 - 0s - loss: 0.4406 - accuracy: 0.8294 - 62ms/epoch - 2ms/step\n",
      "Epoch 151/250\n",
      "28/28 - 0s - loss: 0.4156 - accuracy: 0.8316 - 67ms/epoch - 2ms/step\n",
      "Epoch 152/250\n",
      "28/28 - 0s - loss: 0.4103 - accuracy: 0.8283 - 64ms/epoch - 2ms/step\n",
      "Epoch 153/250\n",
      "28/28 - 0s - loss: 0.4286 - accuracy: 0.8238 - 62ms/epoch - 2ms/step\n",
      "Epoch 154/250\n",
      "28/28 - 0s - loss: 0.4131 - accuracy: 0.8373 - 64ms/epoch - 2ms/step\n",
      "Epoch 155/250\n",
      "28/28 - 0s - loss: 0.4199 - accuracy: 0.8238 - 63ms/epoch - 2ms/step\n",
      "Epoch 156/250\n",
      "28/28 - 0s - loss: 0.4236 - accuracy: 0.8350 - 61ms/epoch - 2ms/step\n",
      "Epoch 157/250\n",
      "28/28 - 0s - loss: 0.4353 - accuracy: 0.8316 - 73ms/epoch - 3ms/step\n",
      "Epoch 158/250\n",
      "28/28 - 0s - loss: 0.4012 - accuracy: 0.8249 - 66ms/epoch - 2ms/step\n",
      "Epoch 159/250\n",
      "28/28 - 0s - loss: 0.4118 - accuracy: 0.8395 - 64ms/epoch - 2ms/step\n",
      "Epoch 160/250\n",
      "28/28 - 0s - loss: 0.4134 - accuracy: 0.8193 - 63ms/epoch - 2ms/step\n",
      "Epoch 161/250\n",
      "28/28 - 0s - loss: 0.4118 - accuracy: 0.8350 - 64ms/epoch - 2ms/step\n",
      "Epoch 162/250\n",
      "28/28 - 0s - loss: 0.4215 - accuracy: 0.8227 - 69ms/epoch - 2ms/step\n",
      "Epoch 163/250\n",
      "28/28 - 0s - loss: 0.4184 - accuracy: 0.8294 - 67ms/epoch - 2ms/step\n",
      "Epoch 164/250\n",
      "28/28 - 0s - loss: 0.4263 - accuracy: 0.8238 - 66ms/epoch - 2ms/step\n",
      "Epoch 165/250\n",
      "28/28 - 0s - loss: 0.4134 - accuracy: 0.8249 - 64ms/epoch - 2ms/step\n",
      "Epoch 166/250\n",
      "28/28 - 0s - loss: 0.4156 - accuracy: 0.8373 - 65ms/epoch - 2ms/step\n",
      "Epoch 167/250\n",
      "28/28 - 0s - loss: 0.4146 - accuracy: 0.8260 - 64ms/epoch - 2ms/step\n",
      "Epoch 168/250\n",
      "28/28 - 0s - loss: 0.4078 - accuracy: 0.8328 - 61ms/epoch - 2ms/step\n",
      "Epoch 169/250\n",
      "28/28 - 0s - loss: 0.4055 - accuracy: 0.8316 - 64ms/epoch - 2ms/step\n",
      "Epoch 170/250\n",
      "28/28 - 0s - loss: 0.4040 - accuracy: 0.8406 - 65ms/epoch - 2ms/step\n",
      "Epoch 171/250\n",
      "28/28 - 0s - loss: 0.4182 - accuracy: 0.8361 - 64ms/epoch - 2ms/step\n",
      "Epoch 172/250\n",
      "28/28 - 0s - loss: 0.4086 - accuracy: 0.8328 - 68ms/epoch - 2ms/step\n",
      "Epoch 173/250\n",
      "28/28 - 0s - loss: 0.3985 - accuracy: 0.8361 - 64ms/epoch - 2ms/step\n",
      "Epoch 174/250\n",
      "28/28 - 0s - loss: 0.3999 - accuracy: 0.8238 - 65ms/epoch - 2ms/step\n",
      "Epoch 175/250\n",
      "28/28 - 0s - loss: 0.4066 - accuracy: 0.8283 - 62ms/epoch - 2ms/step\n",
      "Epoch 176/250\n",
      "28/28 - 0s - loss: 0.4106 - accuracy: 0.8384 - 65ms/epoch - 2ms/step\n",
      "Epoch 177/250\n",
      "28/28 - 0s - loss: 0.3986 - accuracy: 0.8339 - 65ms/epoch - 2ms/step\n",
      "Epoch 178/250\n",
      "28/28 - 0s - loss: 0.4102 - accuracy: 0.8339 - 66ms/epoch - 2ms/step\n",
      "Epoch 179/250\n",
      "28/28 - 0s - loss: 0.4046 - accuracy: 0.8283 - 65ms/epoch - 2ms/step\n",
      "Epoch 180/250\n",
      "28/28 - 0s - loss: 0.4082 - accuracy: 0.8350 - 63ms/epoch - 2ms/step\n",
      "Epoch 181/250\n",
      "28/28 - 0s - loss: 0.4124 - accuracy: 0.8305 - 67ms/epoch - 2ms/step\n",
      "Epoch 182/250\n",
      "28/28 - 0s - loss: 0.4038 - accuracy: 0.8406 - 64ms/epoch - 2ms/step\n",
      "Epoch 183/250\n",
      "28/28 - 0s - loss: 0.4159 - accuracy: 0.8294 - 59ms/epoch - 2ms/step\n",
      "Epoch 184/250\n",
      "28/28 - 0s - loss: 0.4090 - accuracy: 0.8339 - 65ms/epoch - 2ms/step\n",
      "Epoch 185/250\n",
      "28/28 - 0s - loss: 0.4220 - accuracy: 0.8316 - 60ms/epoch - 2ms/step\n",
      "Epoch 186/250\n",
      "28/28 - 0s - loss: 0.4087 - accuracy: 0.8227 - 68ms/epoch - 2ms/step\n",
      "Epoch 187/250\n",
      "28/28 - 0s - loss: 0.4087 - accuracy: 0.8283 - 57ms/epoch - 2ms/step\n",
      "Epoch 188/250\n",
      "28/28 - 0s - loss: 0.4129 - accuracy: 0.8384 - 64ms/epoch - 2ms/step\n",
      "Epoch 189/250\n",
      "28/28 - 0s - loss: 0.3990 - accuracy: 0.8406 - 63ms/epoch - 2ms/step\n",
      "Epoch 190/250\n",
      "28/28 - 0s - loss: 0.3988 - accuracy: 0.8406 - 65ms/epoch - 2ms/step\n",
      "Epoch 191/250\n",
      "28/28 - 0s - loss: 0.4223 - accuracy: 0.8328 - 65ms/epoch - 2ms/step\n",
      "Epoch 192/250\n",
      "28/28 - 0s - loss: 0.3992 - accuracy: 0.8395 - 78ms/epoch - 3ms/step\n",
      "Epoch 193/250\n",
      "28/28 - 0s - loss: 0.4106 - accuracy: 0.8373 - 69ms/epoch - 2ms/step\n",
      "Epoch 194/250\n",
      "28/28 - 0s - loss: 0.4108 - accuracy: 0.8406 - 67ms/epoch - 2ms/step\n",
      "Epoch 195/250\n",
      "28/28 - 0s - loss: 0.4105 - accuracy: 0.8260 - 67ms/epoch - 2ms/step\n",
      "Epoch 196/250\n",
      "28/28 - 0s - loss: 0.4083 - accuracy: 0.8316 - 64ms/epoch - 2ms/step\n",
      "Epoch 197/250\n",
      "28/28 - 0s - loss: 0.4077 - accuracy: 0.8305 - 65ms/epoch - 2ms/step\n",
      "Epoch 198/250\n",
      "28/28 - 0s - loss: 0.4064 - accuracy: 0.8283 - 64ms/epoch - 2ms/step\n",
      "Epoch 199/250\n",
      "28/28 - 0s - loss: 0.4065 - accuracy: 0.8361 - 61ms/epoch - 2ms/step\n",
      "Epoch 200/250\n",
      "28/28 - 0s - loss: 0.4114 - accuracy: 0.8227 - 64ms/epoch - 2ms/step\n",
      "Epoch 201/250\n",
      "28/28 - 0s - loss: 0.4029 - accuracy: 0.8328 - 63ms/epoch - 2ms/step\n",
      "Epoch 202/250\n",
      "28/28 - 0s - loss: 0.4031 - accuracy: 0.8373 - 60ms/epoch - 2ms/step\n",
      "Epoch 203/250\n",
      "28/28 - 0s - loss: 0.3990 - accuracy: 0.8406 - 65ms/epoch - 2ms/step\n",
      "Epoch 204/250\n",
      "28/28 - 0s - loss: 0.4037 - accuracy: 0.8429 - 61ms/epoch - 2ms/step\n",
      "Epoch 205/250\n",
      "28/28 - 0s - loss: 0.4071 - accuracy: 0.8350 - 64ms/epoch - 2ms/step\n",
      "Epoch 206/250\n",
      "28/28 - 0s - loss: 0.3918 - accuracy: 0.8474 - 64ms/epoch - 2ms/step\n",
      "Epoch 207/250\n",
      "28/28 - 0s - loss: 0.3945 - accuracy: 0.8418 - 59ms/epoch - 2ms/step\n",
      "Epoch 208/250\n",
      "28/28 - 0s - loss: 0.3982 - accuracy: 0.8283 - 63ms/epoch - 2ms/step\n",
      "Epoch 209/250\n",
      "28/28 - 0s - loss: 0.4284 - accuracy: 0.8294 - 63ms/epoch - 2ms/step\n",
      "Epoch 210/250\n",
      "28/28 - 0s - loss: 0.4016 - accuracy: 0.8350 - 63ms/epoch - 2ms/step\n",
      "Epoch 211/250\n",
      "28/28 - 0s - loss: 0.3958 - accuracy: 0.8328 - 62ms/epoch - 2ms/step\n",
      "Epoch 212/250\n",
      "28/28 - 0s - loss: 0.3851 - accuracy: 0.8373 - 61ms/epoch - 2ms/step\n",
      "Epoch 213/250\n",
      "28/28 - 0s - loss: 0.3895 - accuracy: 0.8462 - 65ms/epoch - 2ms/step\n",
      "Epoch 214/250\n",
      "28/28 - 0s - loss: 0.3771 - accuracy: 0.8474 - 63ms/epoch - 2ms/step\n",
      "Epoch 215/250\n",
      "28/28 - 0s - loss: 0.4006 - accuracy: 0.8395 - 65ms/epoch - 2ms/step\n",
      "Epoch 216/250\n",
      "28/28 - 0s - loss: 0.3932 - accuracy: 0.8429 - 62ms/epoch - 2ms/step\n",
      "Epoch 217/250\n",
      "28/28 - 0s - loss: 0.4040 - accuracy: 0.8339 - 65ms/epoch - 2ms/step\n",
      "Epoch 218/250\n",
      "28/28 - 0s - loss: 0.4020 - accuracy: 0.8418 - 63ms/epoch - 2ms/step\n",
      "Epoch 219/250\n",
      "28/28 - 0s - loss: 0.3868 - accuracy: 0.8418 - 67ms/epoch - 2ms/step\n",
      "Epoch 220/250\n",
      "28/28 - 0s - loss: 0.3934 - accuracy: 0.8283 - 63ms/epoch - 2ms/step\n",
      "Epoch 221/250\n",
      "28/28 - 0s - loss: 0.3861 - accuracy: 0.8339 - 66ms/epoch - 2ms/step\n",
      "Epoch 222/250\n",
      "28/28 - 0s - loss: 0.4064 - accuracy: 0.8384 - 62ms/epoch - 2ms/step\n",
      "Epoch 223/250\n",
      "28/28 - 0s - loss: 0.4082 - accuracy: 0.8272 - 64ms/epoch - 2ms/step\n",
      "Epoch 224/250\n",
      "28/28 - 0s - loss: 0.3763 - accuracy: 0.8451 - 66ms/epoch - 2ms/step\n",
      "Epoch 225/250\n",
      "28/28 - 0s - loss: 0.3861 - accuracy: 0.8373 - 68ms/epoch - 2ms/step\n",
      "Epoch 226/250\n",
      "28/28 - 0s - loss: 0.3852 - accuracy: 0.8406 - 64ms/epoch - 2ms/step\n",
      "Epoch 227/250\n",
      "28/28 - 0s - loss: 0.4023 - accuracy: 0.8316 - 66ms/epoch - 2ms/step\n",
      "Epoch 228/250\n",
      "28/28 - 0s - loss: 0.3936 - accuracy: 0.8260 - 61ms/epoch - 2ms/step\n",
      "Epoch 229/250\n",
      "28/28 - 0s - loss: 0.4003 - accuracy: 0.8406 - 64ms/epoch - 2ms/step\n",
      "Epoch 230/250\n",
      "28/28 - 0s - loss: 0.4117 - accuracy: 0.8384 - 65ms/epoch - 2ms/step\n",
      "Epoch 231/250\n",
      "28/28 - 0s - loss: 0.4164 - accuracy: 0.8182 - 63ms/epoch - 2ms/step\n",
      "Epoch 232/250\n",
      "28/28 - 0s - loss: 0.3849 - accuracy: 0.8429 - 63ms/epoch - 2ms/step\n",
      "Epoch 233/250\n",
      "28/28 - 0s - loss: 0.3888 - accuracy: 0.8350 - 65ms/epoch - 2ms/step\n",
      "Epoch 234/250\n",
      "28/28 - 0s - loss: 0.3838 - accuracy: 0.8406 - 65ms/epoch - 2ms/step\n",
      "Epoch 235/250\n",
      "28/28 - 0s - loss: 0.3901 - accuracy: 0.8429 - 67ms/epoch - 2ms/step\n",
      "Epoch 236/250\n",
      "28/28 - 0s - loss: 0.3839 - accuracy: 0.8451 - 63ms/epoch - 2ms/step\n",
      "Epoch 237/250\n",
      "28/28 - 0s - loss: 0.4001 - accuracy: 0.8294 - 64ms/epoch - 2ms/step\n",
      "Epoch 238/250\n",
      "28/28 - 0s - loss: 0.3928 - accuracy: 0.8429 - 62ms/epoch - 2ms/step\n",
      "Epoch 239/250\n",
      "28/28 - 0s - loss: 0.3934 - accuracy: 0.8485 - 63ms/epoch - 2ms/step\n",
      "Epoch 240/250\n",
      "28/28 - 0s - loss: 0.3902 - accuracy: 0.8406 - 61ms/epoch - 2ms/step\n",
      "Epoch 241/250\n",
      "28/28 - 0s - loss: 0.3914 - accuracy: 0.8395 - 65ms/epoch - 2ms/step\n",
      "Epoch 242/250\n",
      "28/28 - 0s - loss: 0.3849 - accuracy: 0.8361 - 64ms/epoch - 2ms/step\n",
      "Epoch 243/250\n",
      "28/28 - 0s - loss: 0.3873 - accuracy: 0.8451 - 65ms/epoch - 2ms/step\n",
      "Epoch 244/250\n",
      "28/28 - 0s - loss: 0.4110 - accuracy: 0.8294 - 65ms/epoch - 2ms/step\n",
      "Epoch 245/250\n",
      "28/28 - 0s - loss: 0.3860 - accuracy: 0.8519 - 64ms/epoch - 2ms/step\n",
      "Epoch 246/250\n",
      "28/28 - 0s - loss: 0.3825 - accuracy: 0.8530 - 64ms/epoch - 2ms/step\n",
      "Epoch 247/250\n",
      "28/28 - 0s - loss: 0.4069 - accuracy: 0.8249 - 65ms/epoch - 2ms/step\n",
      "Epoch 248/250\n",
      "28/28 - 0s - loss: 0.4055 - accuracy: 0.8373 - 62ms/epoch - 2ms/step\n",
      "Epoch 249/250\n",
      "28/28 - 0s - loss: 0.3827 - accuracy: 0.8361 - 63ms/epoch - 2ms/step\n",
      "Epoch 250/250\n",
      "28/28 - 0s - loss: 0.3914 - accuracy: 0.8305 - 63ms/epoch - 2ms/step\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35473382472991943, 0.8563411831855774]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    # validation_split=0.1,\n",
    "    callbacks=[early_stopping],\n",
    "    epochs=250,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "model.evaluate(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot( history.history['accuracy'] )\n",
    "plt.plot( history.history['loss'] )\n",
    "# plt.plot( history.history['val_loss'] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions on training dataset :-\n",
      "763 correct predictions out of 891\n",
      "accuracy = 85.63 %\n"
     ]
    }
   ],
   "source": [
    "# predicting on the testing data\n",
    "\n",
    "predictions = model.predict(train_x)\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(predictions)):\n",
    "    # print(f\"{train_y[i]} predicted --> { (predictions[i][0]*100)//1 } %\")\n",
    "\n",
    "    if predictions[i] > 0.500 and train_y[i] == 1:\n",
    "            correct = correct + 1\n",
    "\n",
    "    if predictions[i] < 0.500 and train_y[i] == 0:\n",
    "            correct = correct + 1\n",
    "\n",
    "print(\"predictions on training dataset :-\")\n",
    "print(f\"{correct} correct predictions out of {len(predictions)}\")\n",
    "print(f\"accuracy = { str((correct / len(predictions)) * 100)[:5] } %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "categorising array --> raw_sex\n",
      "unique values --> {'male': 1, 'female': 2}\n",
      "male --> [1. 0.]\n",
      "female --> [0. 1.]\n",
      "male --> [1. 0.]\n",
      "male --> [1. 0.]\n",
      "female --> [0. 1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_sex = list(test_df['Sex'])         # categorical\n",
    "\n",
    "cat_sex = categorical(raw_sex, sex_tokenizer, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values --> 0 out of 418\n",
      "most common value --> S\n",
      "replaced all 'nan' values with 'S'\n",
      "\n",
      "categorising array --> raw_region\n",
      "unique values --> {'S': 1, 'C': 2, 'Q': 3}\n",
      "Q --> [0. 0. 1.]\n",
      "S --> [1. 0. 0.]\n",
      "Q --> [0. 0. 1.]\n",
      "S --> [1. 0. 0.]\n",
      "S --> [1. 0. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_region = list(test_df['Embarked'])     # categorical + missing values\n",
    "raw_region = most_common_imputer(raw_region, debug=True)\n",
    "\n",
    "cat_region = categorical(raw_region, region_tokenizer, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passenger class --> [1, 2, 3] \n",
      "siblings --> [0, 1, 2, 3, 4, 5, 8] \n",
      "parents & children --> [0, 1, 2, 3, 4, 5, 6, 9] \n",
      "sex --> ['female', 'male'] \n",
      "region --> ['C', 'S', 'Q'] \n"
     ]
    }
   ],
   "source": [
    "# dropped 'Name', 'Ticket'\n",
    "# 'Cabin' --> Cabin present or not? \n",
    "\n",
    "p_class = list(test_df['Pclass'])\n",
    "\n",
    "siblings = list(test_df['SibSp'])\n",
    "parents = list(test_df['Parch'])\n",
    "\n",
    "fare = list(test_df['Fare'])\n",
    "\n",
    "print(f\"passenger class --> {list(set(p_class))} \")\n",
    "print(f\"siblings --> {list(set(siblings))} \")\n",
    "print(f\"parents & children --> {list(set(parents))} \")\n",
    "print(f\"sex --> {list(set(raw_sex))} \")\n",
    "print(f\"region --> {list(set(raw_region))} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan --> 0\n",
      "nan --> 0\n",
      "nan --> 0\n",
      "nan --> 0\n",
      "nan --> 0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "cabin_present = list(test_df['Cabin'])\n",
    "cat_cabin = binary_categorical(cabin_present, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --> Mrs. --> count = 72\n",
      "1 --> Miss. --> count = 78\n",
      "2 --> Rev. --> count = 2\n",
      "3 --> Mr. --> count = 244\n",
      "4 --> Master. --> count = 21\n",
      "5 --> Dr. --> count = 1\n",
      "['Mr.', 'Mrs.', 'Mr.', 'Mr.', 'Mrs.', 'Mr.', 'Miss.', 'Mr.', 'Mrs.', 'Mr.']\n"
     ]
    }
   ],
   "source": [
    "raw_names = list(test_df['Name'])\n",
    "\n",
    "proc_names = []\n",
    "positions = ['Mrs.', 'Miss.', 'Rev.', 'Mr.', 'Master.', 'Dr.']\n",
    "\n",
    "for i in range( len(raw_names) ):\n",
    "    name_array = raw_names[i].split(' ')\n",
    "    # print(i, name_array, sep=\" --> \")\n",
    "\n",
    "    token_found = 0\n",
    "    for token in name_array:\n",
    "        if token in positions:\n",
    "            token_found = 1\n",
    "            # print(f\"{token} --> {positions.index(token)}\\n\")\n",
    "            # proc_names.append( positions.index(token) )\n",
    "            proc_names.append( token )\n",
    "    if token_found == 0:\n",
    "        proc_names.append( 'Mr.' )\n",
    "\n",
    "for i in range(len(positions)):\n",
    "    print(f\"{i} --> {positions[i]} --> count = {proc_names.count(positions[i])}\")\n",
    "\n",
    "print(proc_names[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "categorising array --> proc_names\n",
      "unique values --> {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Dr': 5, 'Rev': 6}\n",
      "Mr. --> [1. 0. 0. 0. 0. 0.]\n",
      "Mrs. --> [0. 0. 1. 0. 0. 0.]\n",
      "Mr. --> [1. 0. 0. 0. 0. 0.]\n",
      "Mr. --> [1. 0. 0. 0. 0. 0.]\n",
      "Mrs. --> [0. 0. 1. 0. 0. 0.]\n",
      "\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "cat_names = categorical(proc_names, name_tokenizer, debug=True)\n",
    "\n",
    "print(cat_names[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 22.0, 0, 0, 7.8292, 0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[3, 38.0, 1, 0, 7.0, 0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[2, 26.0, 0, 0, 9.6875, 0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[3, 35.0, 0, 0, 8.6625, 0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[3, 35.0, 1, 1, 12.2875, 0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[3, 23.0, 0, 0, 9.225, 0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "test_x = []\n",
    "\n",
    "for i in range(len(raw_sex)):\n",
    "    temp = [\n",
    "        p_class[i], imputed_age[i],\n",
    "        siblings[i], parents[i], \n",
    "        fare[i], cat_cabin[i]\n",
    "    ]\n",
    "    temp.extend(cat_sex[i])\n",
    "    temp.extend(cat_region[i])\n",
    "    temp.extend(cat_names[i])\n",
    "    test_x.append(temp)\n",
    "    if i < 6: print(temp)\n",
    "    \n",
    "test_x = np.array(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 17)\n",
      "input shape for test_x = 17\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(\"input shape for test_x =\", train_x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_x)\n",
    "\n",
    "csv_pred = []\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i][0] > 0.500: \n",
    "        csv_pred.append(1)\n",
    "    else:\n",
    "        csv_pred.append(0)\n",
    "\n",
    "print(csv_pred[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_id = list(test_df['PassengerId'])\n",
    "\n",
    "submit_dict = {\n",
    "    'PassengerId': passenger_id,\n",
    "    'Survived': csv_pred\n",
    "}\n",
    "\n",
    "submit_df = pd.DataFrame(submit_dict)\n",
    "submit_df.head()\n",
    "\n",
    "submit_df.to_csv('submit.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf6ab032c8d0f1ddf2ea4dd4e609e6e6dfd5e53c8a42a3a69958aaabf5715049"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
