{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 total entries\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "print(f\"{len(train_df)} total entries\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_imputer(raw_array, debug=False):\n",
    "\n",
    "    def namestr(obj, namespace):\n",
    "        return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "    null_count = 0\n",
    "    sum = 0\n",
    "    mean = 0\n",
    "    imputed_array = []\n",
    "\n",
    "    for item in raw_array:\n",
    "        if str(item) == 'nan':\n",
    "            # print(item, end=', ')\n",
    "            null_count = null_count + 1\n",
    "        else: sum = sum + item\n",
    "    \n",
    "    mean = ( sum / len(raw_array) ) // 1\n",
    "\n",
    "    if debug == True:\n",
    "        print(f\"\\nimputing array --> {namestr(raw_array, globals())[0]}\")\n",
    "        print(f\"{null_count} null values\")\n",
    "        print(f\"{len(raw_array) - null_count} numeric values\")\n",
    "        print(f\"{len(raw_array)} total values\")\n",
    "        print(f\"mean = { mean }\")\n",
    "        print(f\"replaced all missing values with mean {mean}\\n\")\n",
    "\n",
    "    for item in raw_array:\n",
    "        if str(item) == 'nan':\n",
    "            item = mean\n",
    "        imputed_array.append(item)\n",
    "        # print(item, end=', ')\n",
    "\n",
    "    return imputed_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "imputing array --> raw_age\n",
      "177 null values\n",
      "714 numeric values\n",
      "891 total values\n",
      "mean = 23.0\n",
      "replaced all missing values with mean 23.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_age = list(train_df['Age'])         # missing values\n",
    "imputed_age = mean_imputer(raw_age, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def categorical(raw_array, tokenizer, debug=False):\n",
    "\n",
    "    def namestr(obj, namespace):\n",
    "        return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "\n",
    "    seq_array = tokenizer.texts_to_sequences(raw_array)\n",
    "\n",
    "    cat_array = tf.keras.utils.to_categorical(seq_array)\n",
    "    cat_array = cat_array[:, 1:]   # cause the [0] value doesnt have anything in the word index\n",
    "\n",
    "\n",
    "    if debug == True:\n",
    "        print(f\"\\ncategorising array --> {namestr(raw_array, globals())[0]}\")\n",
    "        print(f\"unique values --> {tokenizer.word_index}\")\n",
    "        for i in range(5):\n",
    "            print(f\"{raw_array[i]} --> { cat_array[i] }\")\n",
    "        print()\n",
    "        \n",
    "    return cat_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "categorising array --> raw_sex\n",
      "unique values --> {'male': 1, 'female': 2}\n",
      "male --> [1. 0.]\n",
      "female --> [0. 1.]\n",
      "female --> [0. 1.]\n",
      "female --> [0. 1.]\n",
      "male --> [1. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_sex = list(train_df['Sex'])         # categorical\n",
    "\n",
    "sex_tokenizer = tf.keras.preprocessing.text.Tokenizer( lower=False )\n",
    "sex_tokenizer.fit_on_texts(raw_sex)\n",
    "\n",
    "cat_sex = categorical(raw_sex, sex_tokenizer, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_imputer(array, debug=False):\n",
    "\n",
    "    most_common = max(array, key = array.count)\n",
    "    missing_values = 0\n",
    "\n",
    "    for i in range(len(array)):\n",
    "        if str( array[i] ) == 'nan':\n",
    "            missing_values = missing_values + 1\n",
    "            array[i] = most_common\n",
    "\n",
    "    if debug == True:\n",
    "        print(f\"missing values --> {missing_values} out of {len(array)}\")\n",
    "        print(f\"most common value --> {most_common}\")\n",
    "        print(f\"replaced all 'nan' values with '{most_common}'\")\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values --> 2 out of 891\n",
      "most common value --> S\n",
      "replaced all 'nan' values with 'S'\n",
      "\n",
      "categorising array --> raw_region\n",
      "unique values --> {'S': 1, 'C': 2, 'Q': 3}\n",
      "S --> [1. 0. 0.]\n",
      "C --> [0. 1. 0.]\n",
      "S --> [1. 0. 0.]\n",
      "S --> [1. 0. 0.]\n",
      "S --> [1. 0. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_region = list(train_df['Embarked'])     # categorical + missing values\n",
    "raw_region = most_common_imputer(raw_region, debug=True)\n",
    "\n",
    "region_tokenizer = tf.keras.preprocessing.text.Tokenizer( lower=False )\n",
    "region_tokenizer.fit_on_texts(raw_region)\n",
    "\n",
    "cat_region = categorical(raw_region, region_tokenizer, debug=True)\n",
    "\n",
    "# for i in range(8):\n",
    "#     print(f\"{raw_region[i]} --> {cat_region[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived --> [0, 1] \n",
      "passenger class --> [1, 2, 3] \n",
      "siblings --> [0, 1, 2, 3, 4, 5, 8] \n",
      "parents & children --> [0, 1, 2, 3, 4, 5, 6] \n",
      "sex --> ['female', 'male'] \n",
      "region --> ['C', 'Q', 'S'] \n"
     ]
    }
   ],
   "source": [
    "# dropped 'Name', 'Ticket'\n",
    "# 'Cabin' --> Cabin present or not? \n",
    "\n",
    "survived = list(train_df['Survived'])\n",
    "\n",
    "p_class = list(train_df['Pclass'])\n",
    "\n",
    "siblings = list(train_df['SibSp'])\n",
    "parents = list(train_df['Parch'])\n",
    "\n",
    "fare = list(train_df['Fare'])\n",
    "\n",
    "print(f\"survived --> {list(set(survived))} \")\n",
    "print(f\"passenger class --> {list(set(p_class))} \")\n",
    "print(f\"siblings --> {list(set(siblings))} \")\n",
    "print(f\"parents & children --> {list(set(parents))} \")\n",
    "print(f\"sex --> {list(set(raw_sex))} \")\n",
    "print(f\"region --> {list(set(raw_region))} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_categorical(array, debug=False):\n",
    "\n",
    "    cat_array = []\n",
    "\n",
    "    for i in range(len(array)):\n",
    "        if str(array[i]) == 'nan':\n",
    "            cat_array.append(0)\n",
    "        else:\n",
    "            cat_array.append(1)\n",
    "\n",
    "    if debug == True:\n",
    "        for i in range(5):\n",
    "            print(f\"{array[i]} --> {cat_array[i]}\")\n",
    "        print(cat_cabin[:10])\n",
    "\n",
    "    return cat_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan --> 0\n",
      "C85 --> 1\n",
      "nan --> 0\n",
      "C123 --> 1\n",
      "nan --> 0\n",
      "[0, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "cabin_present = list(train_df['Cabin'])\n",
    "cat_cabin = binary_categorical(cabin_present, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --> nan --> count = 14\n",
      "1 --> Mrs. --> count = 125\n",
      "2 --> Miss. --> count = 182\n",
      "3 --> Rev. --> count = 6\n",
      "4 --> Mr. --> count = 517\n",
      "5 --> Master. --> count = 40\n",
      "6 --> Dr. --> count = 7\n",
      "['Mr.', 'Mrs.', 'Miss.', 'Mrs.', 'Mr.', 'Mr.', 'Mr.', 'Master.', 'Mrs.', 'Mrs.']\n"
     ]
    }
   ],
   "source": [
    "raw_names = list(train_df['Name'])\n",
    "\n",
    "proc_names = []\n",
    "positions = ['nan', 'Mrs.', 'Miss.', 'Rev.', 'Mr.', 'Master.', 'Dr.']\n",
    "\n",
    "for i in range( len(raw_names) ):\n",
    "    name_array = raw_names[i].split(' ')\n",
    "    # print(i, name_array, sep=\" --> \")\n",
    "\n",
    "    token_found = 0\n",
    "    for token in name_array:\n",
    "        if token in positions:\n",
    "            token_found = 1\n",
    "            # print(f\"{token} --> {positions.index(token)}\\n\")\n",
    "            # proc_names.append( positions.index(token) )\n",
    "            proc_names.append( token )\n",
    "    if token_found == 0:\n",
    "        proc_names.append( 'nan' )\n",
    "\n",
    "for i in range(len(positions)):\n",
    "    print(f\"{i} --> {positions[i]} --> count = {proc_names.count(positions[i])}\")\n",
    "\n",
    "print(proc_names[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "categorising array --> proc_names\n",
      "unique values --> {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'nan': 5, 'Dr': 6, 'Rev': 7}\n",
      "Mr. --> [1. 0. 0. 0. 0. 0. 0.]\n",
      "Mrs. --> [0. 0. 1. 0. 0. 0. 0.]\n",
      "Miss. --> [0. 1. 0. 0. 0. 0. 0.]\n",
      "Mrs. --> [0. 0. 1. 0. 0. 0. 0.]\n",
      "Mr. --> [1. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "name_tokenizer = tf.keras.preprocessing.text.Tokenizer( lower=False )\n",
    "name_tokenizer.fit_on_texts(proc_names)\n",
    "\n",
    "cat_names = categorical(proc_names, name_tokenizer, debug=True)\n",
    "\n",
    "print(cat_names[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 22.0, 1, 0, 7.25, 0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[1, 38.0, 1, 0, 71.2833, 1, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[3, 26.0, 0, 0, 7.925, 0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[1, 35.0, 1, 0, 53.1, 1, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[3, 35.0, 0, 0, 8.05, 0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[3, 23.0, 0, 0, 8.4583, 0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[1, 54.0, 0, 0, 51.8625, 1, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[3, 2.0, 3, 1, 21.075, 0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[3, 27.0, 0, 2, 11.1333, 0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[2, 14.0, 1, 0, 30.0708, 0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "train_x = []\n",
    "\n",
    "for i in range(len(raw_sex)):\n",
    "    temp = [\n",
    "        p_class[i], imputed_age[i],\n",
    "        siblings[i], parents[i], \n",
    "        fare[i], cat_cabin[i]\n",
    "    ]\n",
    "    temp.extend(cat_sex[i])\n",
    "    temp.extend(cat_region[i])\n",
    "    temp.extend(cat_names[i])\n",
    "    train_x.append(temp)\n",
    "    if i < 10: print(temp)  # printing a sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 18)\n",
      "input shape for model = 18\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "survived = list(train_df['Survived'])\n",
    "\n",
    "train_y = np.array(survived)\n",
    "train_x = np.array(train_x)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(\"input shape for model =\", train_x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "visible = layers.Input( shape=[ train_x.shape[1] ] )\n",
    "x = layers.Dense(64, activation='relu')(visible)\n",
    "# x = layers.Dropout(0.3)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "# x = layers.Dropout(0.3)(x)\n",
    "output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001,\n",
    "    patience=40,\n",
    "    restore_best_weights=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "26/26 - 2s - loss: 0.6545 - accuracy: 0.6442 - val_loss: 0.6393 - val_accuracy: 0.6333 - 2s/epoch - 68ms/step\n",
      "Epoch 2/250\n",
      "26/26 - 0s - loss: 0.5830 - accuracy: 0.6829 - val_loss: 0.5331 - val_accuracy: 0.6778 - 106ms/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "26/26 - 0s - loss: 0.5638 - accuracy: 0.6979 - val_loss: 0.5094 - val_accuracy: 0.7333 - 102ms/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "26/26 - 0s - loss: 0.5338 - accuracy: 0.7478 - val_loss: 0.4766 - val_accuracy: 0.7667 - 113ms/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "26/26 - 0s - loss: 0.5022 - accuracy: 0.7728 - val_loss: 0.4540 - val_accuracy: 0.8000 - 131ms/epoch - 5ms/step\n",
      "Epoch 6/250\n",
      "26/26 - 0s - loss: 0.4771 - accuracy: 0.7840 - val_loss: 0.4345 - val_accuracy: 0.8556 - 134ms/epoch - 5ms/step\n",
      "Epoch 7/250\n",
      "26/26 - 0s - loss: 0.4552 - accuracy: 0.8002 - val_loss: 0.4046 - val_accuracy: 0.8222 - 153ms/epoch - 6ms/step\n",
      "Epoch 8/250\n",
      "26/26 - 0s - loss: 0.4484 - accuracy: 0.8052 - val_loss: 0.4014 - val_accuracy: 0.8444 - 122ms/epoch - 5ms/step\n",
      "Epoch 9/250\n",
      "26/26 - 0s - loss: 0.4338 - accuracy: 0.8027 - val_loss: 0.3850 - val_accuracy: 0.8222 - 124ms/epoch - 5ms/step\n",
      "Epoch 10/250\n",
      "26/26 - 0s - loss: 0.4257 - accuracy: 0.8127 - val_loss: 0.3819 - val_accuracy: 0.8333 - 127ms/epoch - 5ms/step\n",
      "Epoch 11/250\n",
      "26/26 - 0s - loss: 0.4369 - accuracy: 0.8052 - val_loss: 0.3730 - val_accuracy: 0.8556 - 129ms/epoch - 5ms/step\n",
      "Epoch 12/250\n",
      "26/26 - 0s - loss: 0.4124 - accuracy: 0.8215 - val_loss: 0.3646 - val_accuracy: 0.8444 - 125ms/epoch - 5ms/step\n",
      "Epoch 13/250\n",
      "26/26 - 0s - loss: 0.4146 - accuracy: 0.8127 - val_loss: 0.3593 - val_accuracy: 0.8444 - 128ms/epoch - 5ms/step\n",
      "Epoch 14/250\n",
      "26/26 - 0s - loss: 0.4152 - accuracy: 0.8227 - val_loss: 0.3570 - val_accuracy: 0.8333 - 132ms/epoch - 5ms/step\n",
      "Epoch 15/250\n",
      "26/26 - 0s - loss: 0.4144 - accuracy: 0.8265 - val_loss: 0.3518 - val_accuracy: 0.8444 - 141ms/epoch - 5ms/step\n",
      "Epoch 16/250\n",
      "26/26 - 0s - loss: 0.4103 - accuracy: 0.8015 - val_loss: 0.3597 - val_accuracy: 0.8556 - 126ms/epoch - 5ms/step\n",
      "Epoch 17/250\n",
      "26/26 - 0s - loss: 0.4208 - accuracy: 0.8015 - val_loss: 0.3474 - val_accuracy: 0.8444 - 107ms/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "26/26 - 0s - loss: 0.4233 - accuracy: 0.8215 - val_loss: 0.3459 - val_accuracy: 0.8444 - 101ms/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "26/26 - 0s - loss: 0.4016 - accuracy: 0.8327 - val_loss: 0.3378 - val_accuracy: 0.8556 - 101ms/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "26/26 - 0s - loss: 0.4055 - accuracy: 0.8215 - val_loss: 0.3321 - val_accuracy: 0.8444 - 106ms/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "26/26 - 0s - loss: 0.4126 - accuracy: 0.8152 - val_loss: 0.3365 - val_accuracy: 0.8556 - 103ms/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "26/26 - 0s - loss: 0.3969 - accuracy: 0.8215 - val_loss: 0.3303 - val_accuracy: 0.8556 - 101ms/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "26/26 - 0s - loss: 0.4094 - accuracy: 0.8252 - val_loss: 0.3300 - val_accuracy: 0.8556 - 107ms/epoch - 4ms/step\n",
      "Epoch 24/250\n",
      "26/26 - 0s - loss: 0.4083 - accuracy: 0.8227 - val_loss: 0.3252 - val_accuracy: 0.8667 - 116ms/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "26/26 - 0s - loss: 0.4092 - accuracy: 0.8227 - val_loss: 0.3287 - val_accuracy: 0.8667 - 105ms/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "26/26 - 0s - loss: 0.4012 - accuracy: 0.8215 - val_loss: 0.3298 - val_accuracy: 0.8556 - 99ms/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "26/26 - 0s - loss: 0.4127 - accuracy: 0.8127 - val_loss: 0.3252 - val_accuracy: 0.8667 - 105ms/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "26/26 - 0s - loss: 0.4111 - accuracy: 0.8265 - val_loss: 0.3298 - val_accuracy: 0.8556 - 100ms/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "26/26 - 0s - loss: 0.4064 - accuracy: 0.8165 - val_loss: 0.3186 - val_accuracy: 0.8778 - 138ms/epoch - 5ms/step\n",
      "Epoch 30/250\n",
      "26/26 - 0s - loss: 0.4025 - accuracy: 0.8302 - val_loss: 0.3322 - val_accuracy: 0.8556 - 137ms/epoch - 5ms/step\n",
      "Epoch 31/250\n",
      "26/26 - 0s - loss: 0.3995 - accuracy: 0.8190 - val_loss: 0.3313 - val_accuracy: 0.8556 - 124ms/epoch - 5ms/step\n",
      "Epoch 32/250\n",
      "26/26 - 0s - loss: 0.4007 - accuracy: 0.8265 - val_loss: 0.3292 - val_accuracy: 0.8778 - 134ms/epoch - 5ms/step\n",
      "Epoch 33/250\n",
      "26/26 - 0s - loss: 0.3970 - accuracy: 0.8252 - val_loss: 0.3301 - val_accuracy: 0.8667 - 130ms/epoch - 5ms/step\n",
      "Epoch 34/250\n",
      "26/26 - 0s - loss: 0.3924 - accuracy: 0.8290 - val_loss: 0.3202 - val_accuracy: 0.8778 - 110ms/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "26/26 - 0s - loss: 0.3858 - accuracy: 0.8377 - val_loss: 0.3177 - val_accuracy: 0.8778 - 96ms/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "26/26 - 0s - loss: 0.3962 - accuracy: 0.8252 - val_loss: 0.3144 - val_accuracy: 0.8778 - 102ms/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "26/26 - 0s - loss: 0.3968 - accuracy: 0.8352 - val_loss: 0.3176 - val_accuracy: 0.8667 - 100ms/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "26/26 - 0s - loss: 0.3897 - accuracy: 0.8352 - val_loss: 0.3244 - val_accuracy: 0.8778 - 93ms/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "26/26 - 0s - loss: 0.3969 - accuracy: 0.8290 - val_loss: 0.3315 - val_accuracy: 0.8778 - 97ms/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "26/26 - 0s - loss: 0.3843 - accuracy: 0.8290 - val_loss: 0.3286 - val_accuracy: 0.8778 - 95ms/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "26/26 - 0s - loss: 0.3881 - accuracy: 0.8402 - val_loss: 0.3278 - val_accuracy: 0.8667 - 101ms/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "26/26 - 0s - loss: 0.3876 - accuracy: 0.8427 - val_loss: 0.3226 - val_accuracy: 0.8778 - 99ms/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "26/26 - 0s - loss: 0.3813 - accuracy: 0.8352 - val_loss: 0.3235 - val_accuracy: 0.8778 - 92ms/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "26/26 - 0s - loss: 0.3831 - accuracy: 0.8402 - val_loss: 0.3157 - val_accuracy: 0.8889 - 93ms/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "26/26 - 0s - loss: 0.3815 - accuracy: 0.8365 - val_loss: 0.3223 - val_accuracy: 0.8889 - 96ms/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "26/26 - 0s - loss: 0.3854 - accuracy: 0.8340 - val_loss: 0.3265 - val_accuracy: 0.8778 - 93ms/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "26/26 - 0s - loss: 0.3761 - accuracy: 0.8390 - val_loss: 0.3219 - val_accuracy: 0.8667 - 96ms/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "26/26 - 0s - loss: 0.3853 - accuracy: 0.8377 - val_loss: 0.3195 - val_accuracy: 0.8778 - 93ms/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "26/26 - 0s - loss: 0.3786 - accuracy: 0.8377 - val_loss: 0.3294 - val_accuracy: 0.8778 - 93ms/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "26/26 - 0s - loss: 0.3874 - accuracy: 0.8327 - val_loss: 0.3321 - val_accuracy: 0.8778 - 94ms/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "26/26 - 0s - loss: 0.3769 - accuracy: 0.8402 - val_loss: 0.3296 - val_accuracy: 0.8667 - 99ms/epoch - 4ms/step\n",
      "Epoch 52/250\n",
      "26/26 - 0s - loss: 0.4045 - accuracy: 0.8227 - val_loss: 0.3219 - val_accuracy: 0.8889 - 100ms/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "26/26 - 0s - loss: 0.3756 - accuracy: 0.8377 - val_loss: 0.3185 - val_accuracy: 0.8667 - 97ms/epoch - 4ms/step\n",
      "Epoch 54/250\n",
      "26/26 - 0s - loss: 0.3864 - accuracy: 0.8352 - val_loss: 0.3182 - val_accuracy: 0.8778 - 92ms/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "26/26 - 0s - loss: 0.3771 - accuracy: 0.8414 - val_loss: 0.3245 - val_accuracy: 0.8778 - 93ms/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "26/26 - 0s - loss: 0.3899 - accuracy: 0.8390 - val_loss: 0.3263 - val_accuracy: 0.8667 - 95ms/epoch - 4ms/step\n",
      "Epoch 57/250\n",
      "26/26 - 0s - loss: 0.3961 - accuracy: 0.8252 - val_loss: 0.3212 - val_accuracy: 0.9000 - 95ms/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "26/26 - 0s - loss: 0.3734 - accuracy: 0.8427 - val_loss: 0.3135 - val_accuracy: 0.8778 - 96ms/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "26/26 - 0s - loss: 0.3790 - accuracy: 0.8464 - val_loss: 0.3231 - val_accuracy: 0.9000 - 97ms/epoch - 4ms/step\n",
      "Epoch 60/250\n",
      "26/26 - 0s - loss: 0.3815 - accuracy: 0.8290 - val_loss: 0.3222 - val_accuracy: 0.8889 - 94ms/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "26/26 - 0s - loss: 0.3816 - accuracy: 0.8377 - val_loss: 0.3296 - val_accuracy: 0.8778 - 101ms/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "26/26 - 0s - loss: 0.3723 - accuracy: 0.8514 - val_loss: 0.3184 - val_accuracy: 0.9111 - 96ms/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "26/26 - 0s - loss: 0.3928 - accuracy: 0.8302 - val_loss: 0.3306 - val_accuracy: 0.8667 - 97ms/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "26/26 - 0s - loss: 0.3685 - accuracy: 0.8365 - val_loss: 0.3213 - val_accuracy: 0.9111 - 96ms/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "26/26 - 0s - loss: 0.3699 - accuracy: 0.8340 - val_loss: 0.3261 - val_accuracy: 0.8889 - 94ms/epoch - 4ms/step\n",
      "Epoch 66/250\n",
      "26/26 - 0s - loss: 0.3676 - accuracy: 0.8489 - val_loss: 0.3251 - val_accuracy: 0.8889 - 93ms/epoch - 4ms/step\n",
      "Epoch 67/250\n",
      "26/26 - 0s - loss: 0.3784 - accuracy: 0.8365 - val_loss: 0.3168 - val_accuracy: 0.8889 - 98ms/epoch - 4ms/step\n",
      "Epoch 68/250\n",
      "26/26 - 0s - loss: 0.3887 - accuracy: 0.8277 - val_loss: 0.3315 - val_accuracy: 0.8778 - 92ms/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "26/26 - 0s - loss: 0.3878 - accuracy: 0.8340 - val_loss: 0.3222 - val_accuracy: 0.8667 - 92ms/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "26/26 - 0s - loss: 0.3746 - accuracy: 0.8327 - val_loss: 0.3295 - val_accuracy: 0.8778 - 97ms/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "26/26 - 0s - loss: 0.3759 - accuracy: 0.8477 - val_loss: 0.3251 - val_accuracy: 0.8778 - 99ms/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "26/26 - 0s - loss: 0.3680 - accuracy: 0.8452 - val_loss: 0.3173 - val_accuracy: 0.8778 - 103ms/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "26/26 - 0s - loss: 0.3533 - accuracy: 0.8552 - val_loss: 0.3173 - val_accuracy: 0.8778 - 146ms/epoch - 6ms/step\n",
      "Epoch 74/250\n",
      "26/26 - 0s - loss: 0.3713 - accuracy: 0.8527 - val_loss: 0.3203 - val_accuracy: 0.8778 - 104ms/epoch - 4ms/step\n",
      "Epoch 75/250\n",
      "26/26 - 0s - loss: 0.3659 - accuracy: 0.8340 - val_loss: 0.3215 - val_accuracy: 0.8778 - 175ms/epoch - 7ms/step\n",
      "Epoch 76/250\n",
      "26/26 - 0s - loss: 0.3582 - accuracy: 0.8477 - val_loss: 0.3141 - val_accuracy: 0.8889 - 121ms/epoch - 5ms/step\n",
      "Epoch 77/250\n",
      "26/26 - 0s - loss: 0.3625 - accuracy: 0.8514 - val_loss: 0.3225 - val_accuracy: 0.8778 - 118ms/epoch - 5ms/step\n",
      "Epoch 78/250\n",
      "26/26 - 0s - loss: 0.3750 - accuracy: 0.8402 - val_loss: 0.3169 - val_accuracy: 0.8889 - 132ms/epoch - 5ms/step\n",
      "Epoch 79/250\n",
      "26/26 - 0s - loss: 0.3694 - accuracy: 0.8390 - val_loss: 0.3111 - val_accuracy: 0.8889 - 128ms/epoch - 5ms/step\n",
      "Epoch 80/250\n",
      "26/26 - 0s - loss: 0.3643 - accuracy: 0.8452 - val_loss: 0.3130 - val_accuracy: 0.8889 - 136ms/epoch - 5ms/step\n",
      "Epoch 81/250\n",
      "26/26 - 0s - loss: 0.3630 - accuracy: 0.8452 - val_loss: 0.3153 - val_accuracy: 0.8778 - 113ms/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "26/26 - 0s - loss: 0.3768 - accuracy: 0.8302 - val_loss: 0.3189 - val_accuracy: 0.8889 - 120ms/epoch - 5ms/step\n",
      "Epoch 83/250\n",
      "26/26 - 0s - loss: 0.3593 - accuracy: 0.8577 - val_loss: 0.3197 - val_accuracy: 0.8667 - 98ms/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "26/26 - 0s - loss: 0.3677 - accuracy: 0.8539 - val_loss: 0.3176 - val_accuracy: 0.8889 - 92ms/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "26/26 - 0s - loss: 0.3731 - accuracy: 0.8452 - val_loss: 0.3203 - val_accuracy: 0.9000 - 92ms/epoch - 4ms/step\n",
      "Epoch 86/250\n",
      "26/26 - 0s - loss: 0.3685 - accuracy: 0.8340 - val_loss: 0.3142 - val_accuracy: 0.8889 - 95ms/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "26/26 - 0s - loss: 0.3762 - accuracy: 0.8427 - val_loss: 0.3143 - val_accuracy: 0.8778 - 94ms/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "26/26 - 0s - loss: 0.3559 - accuracy: 0.8464 - val_loss: 0.3132 - val_accuracy: 0.8778 - 94ms/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "26/26 - 0s - loss: 0.3599 - accuracy: 0.8452 - val_loss: 0.3175 - val_accuracy: 0.8667 - 95ms/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "26/26 - 0s - loss: 0.3519 - accuracy: 0.8502 - val_loss: 0.3127 - val_accuracy: 0.8667 - 104ms/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "26/26 - 0s - loss: 0.3499 - accuracy: 0.8464 - val_loss: 0.3229 - val_accuracy: 0.8778 - 93ms/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "26/26 - 0s - loss: 0.3591 - accuracy: 0.8402 - val_loss: 0.3187 - val_accuracy: 0.8889 - 93ms/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "26/26 - 0s - loss: 0.3630 - accuracy: 0.8365 - val_loss: 0.3134 - val_accuracy: 0.8889 - 93ms/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "26/26 - 0s - loss: 0.3620 - accuracy: 0.8352 - val_loss: 0.3160 - val_accuracy: 0.8778 - 101ms/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "26/26 - 0s - loss: 0.3606 - accuracy: 0.8427 - val_loss: 0.3134 - val_accuracy: 0.9000 - 94ms/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "26/26 - 0s - loss: 0.3660 - accuracy: 0.8402 - val_loss: 0.3139 - val_accuracy: 0.9000 - 92ms/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "26/26 - 0s - loss: 0.3619 - accuracy: 0.8477 - val_loss: 0.3169 - val_accuracy: 0.8889 - 93ms/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "26/26 - 0s - loss: 0.3594 - accuracy: 0.8464 - val_loss: 0.3128 - val_accuracy: 0.9111 - 97ms/epoch - 4ms/step\n",
      "Epoch 99/250\n",
      "26/26 - 0s - loss: 0.3565 - accuracy: 0.8489 - val_loss: 0.3119 - val_accuracy: 0.8889 - 98ms/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "26/26 - 0s - loss: 0.3450 - accuracy: 0.8602 - val_loss: 0.3093 - val_accuracy: 0.8889 - 99ms/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "26/26 - 0s - loss: 0.3568 - accuracy: 0.8527 - val_loss: 0.3181 - val_accuracy: 0.8889 - 105ms/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "26/26 - 0s - loss: 0.3770 - accuracy: 0.8365 - val_loss: 0.3292 - val_accuracy: 0.8667 - 105ms/epoch - 4ms/step\n",
      "Epoch 103/250\n",
      "26/26 - 0s - loss: 0.3665 - accuracy: 0.8452 - val_loss: 0.3187 - val_accuracy: 0.9000 - 113ms/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "26/26 - 0s - loss: 0.3552 - accuracy: 0.8539 - val_loss: 0.3166 - val_accuracy: 0.8889 - 107ms/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "26/26 - 0s - loss: 0.3530 - accuracy: 0.8477 - val_loss: 0.3164 - val_accuracy: 0.8667 - 104ms/epoch - 4ms/step\n",
      "Epoch 106/250\n",
      "26/26 - 0s - loss: 0.3635 - accuracy: 0.8527 - val_loss: 0.3178 - val_accuracy: 0.8889 - 102ms/epoch - 4ms/step\n",
      "Epoch 107/250\n",
      "26/26 - 0s - loss: 0.3558 - accuracy: 0.8614 - val_loss: 0.3261 - val_accuracy: 0.8778 - 93ms/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "26/26 - 0s - loss: 0.3452 - accuracy: 0.8390 - val_loss: 0.3245 - val_accuracy: 0.8889 - 92ms/epoch - 4ms/step\n",
      "Epoch 109/250\n",
      "26/26 - 0s - loss: 0.3500 - accuracy: 0.8577 - val_loss: 0.3415 - val_accuracy: 0.8667 - 98ms/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "26/26 - 0s - loss: 0.3533 - accuracy: 0.8502 - val_loss: 0.3340 - val_accuracy: 0.8667 - 103ms/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "26/26 - 0s - loss: 0.3494 - accuracy: 0.8614 - val_loss: 0.3381 - val_accuracy: 0.8556 - 107ms/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "26/26 - 0s - loss: 0.3535 - accuracy: 0.8514 - val_loss: 0.3210 - val_accuracy: 0.8667 - 102ms/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "26/26 - 0s - loss: 0.3493 - accuracy: 0.8502 - val_loss: 0.3243 - val_accuracy: 0.8889 - 113ms/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "26/26 - 0s - loss: 0.3486 - accuracy: 0.8527 - val_loss: 0.3269 - val_accuracy: 0.8778 - 106ms/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "26/26 - 0s - loss: 0.3444 - accuracy: 0.8564 - val_loss: 0.3220 - val_accuracy: 0.8778 - 102ms/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "26/26 - 0s - loss: 0.3312 - accuracy: 0.8527 - val_loss: 0.3210 - val_accuracy: 0.8667 - 103ms/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "26/26 - 0s - loss: 0.3421 - accuracy: 0.8502 - val_loss: 0.3180 - val_accuracy: 0.8889 - 97ms/epoch - 4ms/step\n",
      "Epoch 118/250\n",
      "26/26 - 0s - loss: 0.3519 - accuracy: 0.8527 - val_loss: 0.3266 - val_accuracy: 0.8889 - 93ms/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "26/26 - 0s - loss: 0.3445 - accuracy: 0.8564 - val_loss: 0.3155 - val_accuracy: 0.9111 - 95ms/epoch - 4ms/step\n",
      "Epoch 120/250\n",
      "26/26 - 0s - loss: 0.3585 - accuracy: 0.8452 - val_loss: 0.3208 - val_accuracy: 0.8889 - 99ms/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "26/26 - 0s - loss: 0.3478 - accuracy: 0.8614 - val_loss: 0.3177 - val_accuracy: 0.8889 - 102ms/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "26/26 - 0s - loss: 0.3418 - accuracy: 0.8677 - val_loss: 0.3252 - val_accuracy: 0.8778 - 108ms/epoch - 4ms/step\n",
      "Epoch 123/250\n",
      "26/26 - 0s - loss: 0.3524 - accuracy: 0.8514 - val_loss: 0.3222 - val_accuracy: 0.8778 - 102ms/epoch - 4ms/step\n",
      "Epoch 124/250\n",
      "26/26 - 0s - loss: 0.3497 - accuracy: 0.8577 - val_loss: 0.3191 - val_accuracy: 0.8889 - 111ms/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "26/26 - 0s - loss: 0.3363 - accuracy: 0.8739 - val_loss: 0.3269 - val_accuracy: 0.8778 - 105ms/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "26/26 - 0s - loss: 0.3484 - accuracy: 0.8602 - val_loss: 0.3243 - val_accuracy: 0.8556 - 97ms/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "26/26 - 0s - loss: 0.3389 - accuracy: 0.8552 - val_loss: 0.3279 - val_accuracy: 0.8778 - 104ms/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "26/26 - 0s - loss: 0.3514 - accuracy: 0.8514 - val_loss: 0.3218 - val_accuracy: 0.8556 - 102ms/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "26/26 - 0s - loss: 0.3545 - accuracy: 0.8602 - val_loss: 0.3213 - val_accuracy: 0.8889 - 99ms/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "26/26 - 0s - loss: 0.3447 - accuracy: 0.8639 - val_loss: 0.3206 - val_accuracy: 0.9000 - 95ms/epoch - 4ms/step\n",
      "Epoch 131/250\n",
      "26/26 - 0s - loss: 0.3480 - accuracy: 0.8564 - val_loss: 0.3266 - val_accuracy: 0.8667 - 96ms/epoch - 4ms/step\n",
      "Epoch 132/250\n",
      "26/26 - 0s - loss: 0.3423 - accuracy: 0.8577 - val_loss: 0.3253 - val_accuracy: 0.8556 - 93ms/epoch - 4ms/step\n",
      "Epoch 133/250\n",
      "26/26 - 0s - loss: 0.3433 - accuracy: 0.8602 - val_loss: 0.3250 - val_accuracy: 0.8778 - 91ms/epoch - 4ms/step\n",
      "Epoch 134/250\n",
      "26/26 - 0s - loss: 0.3434 - accuracy: 0.8639 - val_loss: 0.3183 - val_accuracy: 0.8889 - 92ms/epoch - 4ms/step\n",
      "Epoch 135/250\n",
      "26/26 - 0s - loss: 0.3368 - accuracy: 0.8639 - val_loss: 0.3261 - val_accuracy: 0.8778 - 99ms/epoch - 4ms/step\n",
      "Epoch 136/250\n",
      "26/26 - 0s - loss: 0.3399 - accuracy: 0.8702 - val_loss: 0.3296 - val_accuracy: 0.8667 - 91ms/epoch - 3ms/step\n",
      "Epoch 137/250\n",
      "26/26 - 0s - loss: 0.3508 - accuracy: 0.8527 - val_loss: 0.3272 - val_accuracy: 0.8778 - 95ms/epoch - 4ms/step\n",
      "Epoch 138/250\n",
      "26/26 - 0s - loss: 0.3501 - accuracy: 0.8652 - val_loss: 0.3478 - val_accuracy: 0.8333 - 99ms/epoch - 4ms/step\n",
      "Epoch 139/250\n",
      "26/26 - 0s - loss: 0.3418 - accuracy: 0.8552 - val_loss: 0.3333 - val_accuracy: 0.8778 - 102ms/epoch - 4ms/step\n",
      "Epoch 140/250\n",
      "26/26 - 0s - loss: 0.3343 - accuracy: 0.8664 - val_loss: 0.3334 - val_accuracy: 0.8778 - 99ms/epoch - 4ms/step\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32005709409713745, 0.8731762170791626]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stopping],\n",
    "    epochs=250,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "model.evaluate(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot( history.history['accuracy'] )\n",
    "plt.plot( history.history['loss'] )\n",
    "plt.plot( history.history['val_loss'] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions on training dataset :-\n",
      "778 correct predictions out of 891\n",
      "accuracy = 87.31 %\n"
     ]
    }
   ],
   "source": [
    "# predicting on the testing data\n",
    "\n",
    "predictions = model.predict(train_x)\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(predictions)):\n",
    "    # print(f\"{train_y[i]} predicted --> { (predictions[i][0]*100)//1 } %\")\n",
    "\n",
    "    if predictions[i] > 0.5 and train_y[i] == 1:\n",
    "            correct = correct + 1\n",
    "\n",
    "    if predictions[i] < 0.5 and train_y[i] == 0:\n",
    "            correct = correct + 1\n",
    "\n",
    "print(\"predictions on training dataset :-\")\n",
    "print(f\"{correct} correct predictions out of {len(predictions)}\")\n",
    "print(f\"accuracy = { str((correct / len(predictions)) * 100)[:5] } %\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf6ab032c8d0f1ddf2ea4dd4e609e6e6dfd5e53c8a42a3a69958aaabf5715049"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
